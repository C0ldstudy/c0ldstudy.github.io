<!DOCTYPE html>









<!-- `site.alt_lang` can specify a language different from the UI -->
<html lang="en"
  
>

  <!-- The Head -->

<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <meta name="theme-color" media="(prefers-color-scheme: light)" content="#f7f7f7">
  <meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1b1b1e">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta
    name="viewport"
    content="width=device-width, user-scalable=no initial-scale=1, shrink-to-fit=no, viewport-fit=cover"
  >

  
    

    
  

  

  

  
    <!-- Begin Jekyll SEO tag v2.8.0 -->
<meta name="generator" content="Jekyll v4.3.2" />
<meta property="og:title" content="Reinforcement Learning Course from Hugging Face" />
<meta property="og:locale" content="en" />
<meta name="description" content="I use the blog to record my learning procedures of reinforcement learning course from Hugging Face" />
<meta property="og:description" content="I use the blog to record my learning procedures of reinforcement learning course from Hugging Face" />
<link rel="canonical" href="http://c0ldstudy.github.io/posts/Reinforcement_Learning_Course/" />
<meta property="og:url" content="http://c0ldstudy.github.io/posts/Reinforcement_Learning_Course/" />
<meta property="og:site_name" content="c0ldstudy" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2023-03-11T00:00:00-08:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Reinforcement Learning Course from Hugging Face" />
<meta name="twitter:site" content="@JiacenXu" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2023-06-10T09:51:07-07:00","datePublished":"2023-03-11T00:00:00-08:00","description":"I use the blog to record my learning procedures of reinforcement learning course from Hugging Face","headline":"Reinforcement Learning Course from Hugging Face","mainEntityOfPage":{"@type":"WebPage","@id":"http://c0ldstudy.github.io/posts/Reinforcement_Learning_Course/"},"url":"http://c0ldstudy.github.io/posts/Reinforcement_Learning_Course/"}</script>
<!-- End Jekyll SEO tag -->

  

  <title>Reinforcement Learning Course from Hugging Face | c0ldstudy
  </title>

  <!--
  The Favicons for Web, Android, Microsoft, and iOS (iPhone and iPad) Apps
  Generated by: https://realfavicongenerator.net/
-->



<link rel="apple-touch-icon" sizes="180x180" href="/assets/img/favicons/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="/assets/img/favicons/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="/assets/img/favicons/favicon-16x16.png">
<link rel="manifest" href="/assets/img/favicons/site.webmanifest">
<link rel="shortcut icon" href="/assets/img/favicons/favicon.ico">
<meta name="apple-mobile-web-app-title" content="c0ldstudy">
<meta name="application-name" content="c0ldstudy">
<meta name="msapplication-TileColor" content="#da532c">
<meta name="msapplication-config" content="/assets/img/favicons/browserconfig.xml">
<meta name="theme-color" content="#ffffff">


  
    
      <link rel="preconnect" href="https://fonts.googleapis.com" >
      <link rel="dns-prefetch" href="https://fonts.googleapis.com" >
    
      <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
      <link rel="dns-prefetch" href="https://fonts.gstatic.com" crossorigin>
    
      <link rel="preconnect" href="https://fonts.googleapis.com" >
      <link rel="dns-prefetch" href="https://fonts.googleapis.com" >
    
      <link rel="preconnect" href="https://cdn.jsdelivr.net" >
      <link rel="dns-prefetch" href="https://cdn.jsdelivr.net" >
    

    <link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Lato&family=Source+Sans+Pro:wght@400;600;700;900&display=swap">
  

  <!-- GA -->
  

  <!-- Bootstrap -->
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.2/dist/css/bootstrap.min.css">

  <!-- Font Awesome -->
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.2.1/css/all.min.css">

  <link rel="stylesheet" href="/assets/css/style.css">

  
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/tocbot@4.20.1/dist/tocbot.min.css">
  

  
    <!-- Manific Popup -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/magnific-popup@1.1.0/dist/magnific-popup.min.css">
  

  <!-- JavaScript -->

  <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.1/dist/jquery.min.js"></script>

  
    <!--
  Switch the mode between dark and light.
-->

<script type="text/javascript">
  class ModeToggle {
    static get MODE_KEY() { return "mode"; }
    static get MODE_ATTR() { return "data-mode"; }
    static get DARK_MODE() { return "dark"; }
    static get LIGHT_MODE() { return "light"; }
    static get ID() { return "mode-toggle"; }

    constructor() {
      if (this.hasMode) {
        if (this.isDarkMode) {
          if (!this.isSysDarkPrefer) {
            this.setDark();
          }
        } else {
          if (this.isSysDarkPrefer) {
            this.setLight();
          }
        }
      }

      let self = this;

      /* always follow the system prefers */
      this.sysDarkPrefers.addEventListener('change', () => {
        if (self.hasMode) {
          if (self.isDarkMode) {
            if (!self.isSysDarkPrefer) {
              self.setDark();
            }
          } else {
            if (self.isSysDarkPrefer) {
              self.setLight();
            }
          }

          self.clearMode();
        }

        self.notify();
      });
    } /* constructor() */

    get sysDarkPrefers() { return window.matchMedia("(prefers-color-scheme: dark)"); }

    get isSysDarkPrefer() { return this.sysDarkPrefers.matches; }

    get isDarkMode() { return this.mode === ModeToggle.DARK_MODE; }

    get isLightMode() { return this.mode === ModeToggle.LIGHT_MODE; }

    get hasMode() { return this.mode != null; }

    get mode() { return sessionStorage.getItem(ModeToggle.MODE_KEY); }

    /* get the current mode on screen */
    get modeStatus() {
      if (this.isDarkMode || (!this.hasMode && this.isSysDarkPrefer)) {
        return ModeToggle.DARK_MODE;
      } else {
        return ModeToggle.LIGHT_MODE;
      }
    }

    setDark() {
      $('html').attr(ModeToggle.MODE_ATTR, ModeToggle.DARK_MODE);
      sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.DARK_MODE);
    }

    setLight() {
      $('html').attr(ModeToggle.MODE_ATTR, ModeToggle.LIGHT_MODE);
      sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.LIGHT_MODE);
    }

    clearMode() {
      $('html').removeAttr(ModeToggle.MODE_ATTR);
      sessionStorage.removeItem(ModeToggle.MODE_KEY);
    }

    /* Notify another plugins that the theme mode has changed */
    notify() {
      window.postMessage({
        direction: ModeToggle.ID,
        message: this.modeStatus
      }, "*");
    }

    flipMode() {
      if (this.hasMode) {
        if (this.isSysDarkPrefer) {
          if (this.isLightMode) {
            this.clearMode();
          } else {
            this.setLight();
          }
        } else {
          if (this.isDarkMode) {
            this.clearMode();
          } else {
            this.setDark();
          }
        }
      } else {
        if (this.isSysDarkPrefer) {
          this.setLight();
        } else {
          this.setDark();
        }
      }

      this.notify();
    } /* flipMode() */
  } /* ModeToggle */

  const modeToggle = new ModeToggle();
</script>

  
</head>


  <body data-topbar-visible="true">

    <!--
  The Side Bar
-->

<div id="sidebar" class="d-flex flex-column align-items-end">
  <div class="profile-wrapper text-center">
    <div id="avatar">
      <a href="/" class="mx-auto">
        
          
          <img src="/commons/avatar.png" alt="avatar" onerror="this.style.display='none'">
        
      </a>
    </div>

    <div class="site-title">
      <a href="/">c0ldstudy</a>
    </div>
    <div class="site-subtitle font-italic">Absorb what is useful. Reject what is useless. And add what is essentially your own. --- Bruce Lee</div>

  </div><!-- .profile-wrapper -->

  <ul class="w-100">

    <!-- home -->
    <li class="nav-item">
      <a href="/" class="nav-link">
        <i class="fa-fw fas fa-home ml-xl-3 mr-xl-3 unloaded"></i>
        <span>HOME</span>
      </a>
    </li>
    <!-- the real tabs -->
    
    <li class="nav-item">
      <a href="/categories/" class="nav-link">
        <i class="fa-fw fas fa-stream ml-xl-3 mr-xl-3 unloaded"></i>
        

        <span>CATEGORIES</span>
      </a>
    </li> <!-- .nav-item -->
    
    <li class="nav-item">
      <a href="/tags/" class="nav-link">
        <i class="fa-fw fas fa-tag ml-xl-3 mr-xl-3 unloaded"></i>
        

        <span>TAGS</span>
      </a>
    </li> <!-- .nav-item -->
    
    <li class="nav-item">
      <a href="/archives/" class="nav-link">
        <i class="fa-fw fas fa-archive ml-xl-3 mr-xl-3 unloaded"></i>
        

        <span>ARCHIVES</span>
      </a>
    </li> <!-- .nav-item -->
    
    <li class="nav-item">
      <a href="/about/" class="nav-link">
        <i class="fa-fw fas fa-info-circle ml-xl-3 mr-xl-3 unloaded"></i>
        

        <span>ABOUT</span>
      </a>
    </li> <!-- .nav-item -->
    

  </ul> <!-- ul.nav.flex-column -->

  <div class="sidebar-bottom mt-auto d-flex flex-wrap justify-content-center align-items-center">

    
      <button class="mode-toggle btn" aria-label="Switch Mode">
        <i class="fas fa-adjust"></i>
      </button>

      
        <span class="icon-border"></span>
      
    

    
      

      
      <a href="https://github.com/c0ldstudy" aria-label="github"
        

        
          target="_blank"
          
        

        

        rel="noopener noreferrer">

        <i class="fab fa-github"></i>
      </a>
      

    
      

      
      <a href="https://twitter.com/JiacenXu" aria-label="twitter"
        

        
          target="_blank"
          
        

        

        rel="noopener noreferrer">

        <i class="fab fa-twitter"></i>
      </a>
      

    
      

      
      <a href="javascript:location.href = 'mailto:' + ['jiacenx','uci.edu'].join('@')" aria-label="email"
        

        

        

        >

        <i class="fas fa-envelope"></i>
      </a>
      

    
      

      
      <a href="/feed.xml" aria-label="rss"
        

        

        

        >

        <i class="fas fa-rss"></i>
      </a>
      

    
      

      
      <a href="https://www.linkedin.com/in/jiacen-xu-021536105/" aria-label="linkedin"
        

        
          target="_blank"
          
        

        

        rel="noopener noreferrer">

        <i class="fab fa-linkedin"></i>
      </a>
      

    

  </div> <!-- .sidebar-bottom -->

</div><!-- #sidebar -->


    <!--
  The Top Bar
-->

<div id="topbar-wrapper">
  <div id="topbar" class="container d-flex align-items-center justify-content-between h-100 pl-3 pr-3 pl-md-4 pr-md-4">
    <span id="breadcrumb">

    

    

      

        
          <span>
            <a href="/">
              Home
            </a>
          </span>

        

      

        

      

        

          
            <span>Reinforcement Learning Course from Hugging Face</span>
          

        

      

    

    </span><!-- endof #breadcrumb -->

    <i id="sidebar-trigger" class="fas fa-bars fa-fw"></i>

    <div id="topbar-title">
      Post
    </div>

    <i id="search-trigger" class="fas fa-search fa-fw"></i>
    <span id="search-wrapper" class="align-items-center">
      <i class="fas fa-search fa-fw"></i>
      <input class="form-control" id="search-input" type="search"
        aria-label="search" autocomplete="off" placeholder="Search...">
    </span>
    <span id="search-cancel" >Cancel</span>
  </div>

</div>


    <div id="main-wrapper" class="d-flex justify-content-center">
      <div id="main" class="container pl-xl-4 pr-xl-4">
        





<div class="row">

  <!-- core -->
  <div id="core-wrapper" class="col-12 col-lg-11 col-xl-9 pr-xl-4">
    <div class="post pl-1 pr-1 pl-md-2 pr-md-2">

    

    
      
      
        <!--
  Refactor the HTML structure.
-->



<!--
  In order to allow a wide table to scroll horizontally,
  we suround the markdown table with `<div class="table-wrapper">` and `</div>`
-->



<!--
  Fixed kramdown code highlight rendering:
  https://github.com/penibelst/jekyll-compress-html/issues/101
  https://github.com/penibelst/jekyll-compress-html/issues/71#issuecomment-188144901
-->



<!-- Change the icon of checkbox -->


<!-- images -->





<!-- Add header for code snippets -->



<!-- Create heading anchors -->





  
  

  
    
    

    
      
        
        
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    

    

  

  
  

  

  
  

  
    
    

    
      
        
        
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    

    

  

  
  

  




<!-- return -->

<h1 data-toc-skip>Reinforcement Learning Course from Hugging Face</h1>

<div class="post-meta text-muted">
    <!-- published date -->
    <span>
      Posted
      <!--
  Date format snippet
  See: ${JS_ROOT}/utils/locale-dateime.js
-->





<em class=""
    data-ts="1678521600"
    data-df="ll"
    data-toggle="tooltip" data-placement="bottom">
  Mar 11, 2023
</em>

    </span>

    <!-- lastmod date -->
    
    <span>
      Updated
      <!--
  Date format snippet
  See: ${JS_ROOT}/utils/locale-dateime.js
-->





<em class=""
    data-ts="1686415867"
    data-df="ll"
    data-toggle="tooltip" data-placement="bottom">
  Jun 10, 2023
</em>

    </span>
    

  

  <div class="d-flex justify-content-between">
    <!-- author(s) -->
    <span>
      

      By

      <em>
      
        <a href="https://twitter.com/JiacenXu">Jiacen (Jason) Xu</a>
      
      </em>
    </span>

    <div>
      <!-- page views -->
      

      <!-- read time -->
      <!--
  Calculate the post's reading time, and display the word count in tooltip
 -->



<!-- words per minute  -->










<!-- return element -->
<span class="readtime" data-toggle="tooltip" data-placement="bottom"
  title="1467 words">
  <em>8 min</em> read</span>

    </div>

  </div> <!-- .d-flex -->

</div> <!-- .post-meta -->

<div class="post-content">
  <p>I use the blog to record my learning procedures of reinforcement learning course from <a href="[https://huggingface.co/deep-rl-course/communication/certification](https://huggingface.co/deep-rl-course/communication/certification)">Hugging Face</a></p>

<h2 id="unit-1-introduction-to-deep-reinforcement-learning"><span class="mr-2">Unit 1: Introduction to Deep Reinforcement Learning</span><a href="#unit-1-introduction-to-deep-reinforcement-learning" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2>

<p><strong>Concepts</strong>:</p>
<ul>
  <li>Reinforcement Learning is a computational approach of learning from action. An agent is designed based on the environment interactions with trail and error and receving rewards(+/-) as feedback.</li>
  <li>The objective function is to maximize the expected cumulative reward.</li>
  <li>The RL process is a sequence of state, action, reward, and next state.</li>
  <li>The rewards can be discounted: the early rewards are more probable and predictable then long term future rewards.</li>
  <li>The optimal policy is necessary to solve an RL problem which decide the action to take given a state. One example is to maximize the expected return.
    <ul>
      <li>Policy-based methods: Training the plicy directly.</li>
      <li>Value-based methods: Training the policy by a value function.</li>
    </ul>
  </li>
</ul>

<p><strong>Related Glossary</strong>:</p>
<ul>
  <li>Markov Property</li>
  <li>Observations: Partial description of the state of the environment.</li>
  <li>State: Complete description of the state of the world.</li>
  <li>Actions: Discrete/Continuous Actions.</li>
  <li>Tasks: Episodic/Continuous.</li>
</ul>

<p><strong>Solution</strong>:</p>
<div class="language-python highlighter-rouge"><div class="code-header">
        <span data-label-text="Python"><i class="fas fa-code small"></i></span>
      <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
</pre></td><td class="rouge-code"><pre><span class="kn">from</span> <span class="n">pyvirtualdisplay</span> <span class="kn">import</span> <span class="n">Display</span>
<span class="n">virtual_display</span> <span class="o">=</span> <span class="nc">Display</span><span class="p">(</span><span class="n">visible</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">1400</span><span class="p">,</span> <span class="mi">900</span><span class="p">))</span>
<span class="n">virtual_display</span><span class="p">.</span><span class="nf">start</span><span class="p">()</span>

<span class="kn">import</span> <span class="n">gym</span>
<span class="kn">from</span> <span class="n">huggingface_sb3</span> <span class="kn">import</span> <span class="n">load_from_hub</span><span class="p">,</span> <span class="n">package_to_hub</span><span class="p">,</span> <span class="n">push_to_hub</span>
<span class="kn">from</span> <span class="n">huggingface_hub</span> <span class="kn">import</span> <span class="n">notebook_login</span> <span class="c1"># To log to our Hugging Face account to be able to upload models to the Hub.
</span><span class="kn">from</span> <span class="n">stable_baselines3</span> <span class="kn">import</span> <span class="n">PPO</span>
<span class="kn">from</span> <span class="n">stable_baselines3.common.evaluation</span> <span class="kn">import</span> <span class="n">evaluate_policy</span>
<span class="kn">from</span> <span class="n">stable_baselines3.common.env_util</span> <span class="kn">import</span> <span class="n">make_vec_env</span>

<span class="c1"># Create the environment
</span><span class="n">env</span> <span class="o">=</span> <span class="nf">make_vec_env</span><span class="p">(</span><span class="s">'LunarLander-v2'</span><span class="p">,</span> <span class="n">n_envs</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span>
<span class="c1"># We added some parameters to accelerate the training
</span><span class="n">model</span> <span class="o">=</span> <span class="nc">PPO</span><span class="p">(</span>
    <span class="n">policy</span> <span class="o">=</span> <span class="s">'MlpPolicy'</span><span class="p">,</span>
    <span class="n">env</span> <span class="o">=</span> <span class="n">env</span><span class="p">,</span>
    <span class="n">n_steps</span> <span class="o">=</span> <span class="mi">1024</span><span class="p">,</span>
    <span class="n">batch_size</span> <span class="o">=</span> <span class="mi">64</span><span class="p">,</span>
    <span class="n">n_epochs</span> <span class="o">=</span> <span class="mi">4</span><span class="p">,</span>
    <span class="n">gamma</span> <span class="o">=</span> <span class="mf">0.999</span><span class="p">,</span>
    <span class="n">gae_lambda</span> <span class="o">=</span> <span class="mf">0.98</span><span class="p">,</span>
    <span class="n">ent_coef</span> <span class="o">=</span> <span class="mf">0.01</span><span class="p">,</span>
    <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="c1"># Train it for 1,000,000 timesteps
</span><span class="n">model</span><span class="p">.</span><span class="nf">learn</span><span class="p">(</span><span class="n">total_timesteps</span><span class="o">=</span><span class="mi">1000000</span><span class="p">,</span> <span class="n">progress_bar</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">log_interval</span><span class="o">=</span><span class="mi">100000</span><span class="p">)</span>
<span class="c1"># Save the model
</span><span class="n">model_name</span> <span class="o">=</span> <span class="s">"LunarLander-v2"</span>
<span class="n">model</span><span class="p">.</span><span class="nf">save</span><span class="p">(</span><span class="n">model_name</span><span class="p">)</span>

<span class="n">eval_env</span> <span class="o">=</span> <span class="n">gym</span><span class="p">.</span><span class="nf">make</span><span class="p">(</span><span class="s">"LunarLander-v2"</span><span class="p">)</span>
<span class="n">mean_reward</span><span class="p">,</span> <span class="n">std_reward</span> <span class="o">=</span> <span class="nf">evaluate_policy</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">eval_env</span><span class="p">,</span> <span class="n">n_eval_episodes</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">deterministic</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"mean_reward=</span><span class="si">{</span><span class="n">mean_reward</span><span class="si">:</span><span class="p">.</span><span class="mi">2</span><span class="n">f</span><span class="si">}</span><span class="s"> +/- </span><span class="si">{</span><span class="n">std_reward</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>

<span class="kn">import</span> <span class="n">gym</span>
<span class="kn">from</span> <span class="n">stable_baselines3.common.vec_env</span> <span class="kn">import</span> <span class="n">DummyVecEnv</span>
<span class="kn">from</span> <span class="n">stable_baselines3.common.env_util</span> <span class="kn">import</span> <span class="n">make_vec_env</span>

<span class="kn">from</span> <span class="n">huggingface_sb3</span> <span class="kn">import</span> <span class="n">package_to_hub</span>



<span class="c1">## repo_id is the id of the model repository from the Hugging Face Hub (repo_id = {organization}/{repo_name} for instance ThomasSimonini/ppo-LunarLander-v2
</span><span class="n">repo_id</span> <span class="o">=</span> <span class="s">""</span> <span class="c1"># Need revise
</span>
<span class="c1"># TODO: Define the name of the environment
</span><span class="n">env_id</span> <span class="o">=</span> <span class="s">"LunarLander-v2"</span>

<span class="c1"># Create the evaluation env
</span><span class="n">eval_env</span> <span class="o">=</span> <span class="nc">DummyVecEnv</span><span class="p">([</span><span class="k">lambda</span><span class="p">:</span> <span class="n">gym</span><span class="p">.</span><span class="nf">make</span><span class="p">(</span><span class="n">env_id</span><span class="p">)])</span>


<span class="c1"># TODO: Define the model architecture we used
</span><span class="n">model_architecture</span> <span class="o">=</span> <span class="s">"PPO"</span>

<span class="c1">## TODO: Define the commit message
</span><span class="n">commit_message</span> <span class="o">=</span> <span class="s">"initialization"</span>

<span class="c1"># method save, evaluate, generate a model card and record a replay video of your agent before pushing the repo to the hub
</span><span class="nf">package_to_hub</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span> <span class="c1"># Our trained model
</span>               <span class="n">model_name</span><span class="o">=</span><span class="n">model_name</span><span class="p">,</span> <span class="c1"># The name of our trained model
</span>               <span class="n">model_architecture</span><span class="o">=</span><span class="n">model_architecture</span><span class="p">,</span> <span class="c1"># The model architecture we used: in our case PPO
</span>               <span class="n">env_id</span><span class="o">=</span><span class="n">env_id</span><span class="p">,</span> <span class="c1"># Name of the environment
</span>               <span class="n">eval_env</span><span class="o">=</span><span class="n">eval_env</span><span class="p">,</span> <span class="c1"># Evaluation Environment
</span>               <span class="n">repo_id</span><span class="o">=</span><span class="n">repo_id</span><span class="p">,</span> <span class="c1"># id of the model repository from the Hugging Face Hub (repo_id = {organization}/{repo_name} for instance ThomasSimonini/ppo-LunarLander-v2
</span>               <span class="n">commit_message</span><span class="o">=</span><span class="n">commit_message</span><span class="p">)</span>

<span class="c1"># Note: if after running the package_to_hub function and it gives an issue of rebasing, please run the following code
# cd &lt;path_to_repo&gt; &amp;&amp; git add . &amp;&amp; git commit -m "Add message" &amp;&amp; git pull
# And don't forget to do a "git push" at the end to push the change to the hub.
</span>
</pre></td></tr></tbody></table></code></div></div>

<h2 id="unit-2-introduction-to-q-learning"><span class="mr-2">Unit 2: Introduction to Q-Learning</span><a href="#unit-2-introduction-to-q-learning" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2>
<p>To solve the RL problems, a policy is required. There are two ways to get it:</p>
<ul>
  <li>Policy-based: training the policy directly.</li>
  <li>Value-based: Find an optimal value function.
    <ul>
      <li>Most of the time, an Epsilon-Greedy Policy is used to handle the exploration/exploitation trade-off.
        <ul>
          <li>The state-value function.</li>
          <li>The action-value function.</li>
        </ul>
      </li>
      <li>The return valud is the expected return.
One way to simplify the value estimation is Bellman Equation. It is similar to Bellman-Ford algorithm to me. The main idea is to calculate the value as the sum of immediate reward plus the discounted value of the state that follows.</li>
    </ul>
  </li>
</ul>

<h4 id="two-learning-strategies"><span class="mr-2">Two learning strategies:</span><a href="#two-learning-strategies" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h4>
<ul>
  <li>Monte Carlo: randomly generate a sequence of state, action, rewardâ€¦ and calculate the the return at the end of the episode and use it as a target for updating.</li>
  <li>Temporal Difference Learning: update the value function from a step.</li>
</ul>

<h4 id="q-learning"><span class="mr-2">Q-Learning</span><a href="#q-learning" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h4>
<p>An off-policy value-based method that uses a Temporal Difference approach to train its action-value function.
The epsilon-greedy policy: Instead local optimal action, use epsilon as the possibility to take random action or greedy action.</p>

<h2 id="unit-3-deep-q-learning-with-atari-games--using-rl-baselines3-zoo"><span class="mr-2">Unit 3: Deep Q-Learning with Atari Games ðŸ‘¾ using RL Baselines3 Zoo</span><a href="#unit-3-deep-q-learning-with-atari-games--using-rl-baselines3-zoo" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2>
<p>Use Neural Network to take a state and approximate Q-values.</p>

<h4 id="the-deep-q-network-dqn"><span class="mr-2">The Deep Q-Network: DQN</span><a href="#the-deep-q-network-dqn" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h4>
<p>Input: several frames of games
Output: a vector of Q-values for each possible action at that state.</p>

<h4 id="the-deep-q-algorithm"><span class="mr-2">The Deep Q Algorithm</span><a href="#the-deep-q-algorithm" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h4>
<p>It uses a deep neural network to approximate the different Q-values for each possible action at a state (value-function estimation).
It has two phases:</p>
<ul>
  <li>Sampling: Store the observed experience tuples in a replay memory.</li>
  <li>Training: Select a small batch of tuples randomly and learn from this batch using a gradient descent update step.
One main problem of Deep Q-Learning is instability. There are three solutions:</li>
  <li>Experience Replay to make more efficient use of experiences.
    <ul>
      <li>Make more efficient use of the experiences during the training.</li>
      <li>Avoid forgetting previous experiences and reduce the correlation between experiences.</li>
    </ul>
  </li>
  <li>Fixed Q-Target to stabilize the training.
    <ul>
      <li>Use a separate network with fixed parameters for estimating the TD Target.</li>
      <li>Copy the parameters from our Deep Q-Network every C steps to update the target network.</li>
    </ul>
  </li>
  <li>Double Deep Q-Learning, to handle the problem of the overestimation of Q-values.
    <ul>
      <li>Use the DQN Network to select the best action to take for the next state.</li>
      <li>Use the Target network to calculate the target Q-value of taking that action at the next state.</li>
    </ul>
  </li>
</ul>

<h2 id="bonus-unit-2-automatic-hyperparameter-tuning-with-optuna"><span class="mr-2">Bonus Unit 2: Automatic Hyperparameter Tuning with Optuna</span><a href="#bonus-unit-2-automatic-hyperparameter-tuning-with-optuna" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2>

<p><a href="https://github.com/optuna/optuna">Optuna</a> is a library to search for the best hyperparameters automatically.</p>

<h2 id="unit-4-policy-gradient-with-pytorch"><span class="mr-2">Unit 4: Policy Gradient with Pytorch</span><a href="#unit-4-policy-gradient-with-pytorch" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2>
<p>The policy-based method:</p>
<ul>
  <li>The idea is to parameterize the policy and maximize the performance of the parameterized policy using gradient ascent.</li>
  <li>The policy-gradient method is a subclass of the policy-based method.</li>
</ul>

<h4 id="the-advantages-and-disadvantages-of-policy-gradient-methods"><span class="mr-2">The advantages and disadvantages of policy-gradient methods</span><a href="#the-advantages-and-disadvantages-of-policy-gradient-methods" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h4>
<p>Adv:</p>
<ul>
  <li>The simplicity of integration.</li>
  <li>Policy-gradient methods can learn a stochastic policy.</li>
  <li>Policy-gradient methods are more effective in high-dimensional action spaces and continuous actions spaces.</li>
  <li>Policy-gradient methods ahve better convergence properties.
Dis:</li>
  <li>It converges to a local maximum instead of a global optimum.</li>
  <li>It goes slow: inefficient.</li>
  <li>It has high variance.</li>
</ul>

<h2 id="unit-5-introduction-to-unity-ml-agents"><span class="mr-2">Unit 5: Introduction to Unity ML-Agents</span><a href="#unit-5-introduction-to-unity-ml-agents" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2>
<p><a href="https://github.com/Unity-Technologies/ml-agents">Unity ML-Agent</a> is a toolkit for the game engine Unity to create environments to train the agents.</p>

<h2 id="unit-6-actor-critic-methods-with-robotics-environments"><span class="mr-2">Unit 6: Actor Critic Methods with Robotics Environments</span><a href="#unit-6-actor-critic-methods-with-robotics-environments" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2>
<p>Policy-gradient methods estimate the weights of the optimal policy using Gradient Ascent which means it chooses the steepest increase in return.</p>
<h4 id="actor-critic-methods"><span class="mr-2">Actor-Critic methods</span><a href="#actor-critic-methods" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h4>
<p>A hybrid architecture combing Value-based and Policy-based methods to stabilize the training by reducing the variance.</p>
<ul>
  <li>An actor to control how the agent behaves.</li>
  <li>A critic to measure how good the action is.
So there are two function approximations:</li>
  <li>A policy that control how our agent acts: $\pi_\theta(s)$.</li>
  <li>A value function to assist the policy update by measuring how good the action taken is: $q_w(s,a)$</li>
</ul>

<h2 id="unit-7-introduction-to-multi-agents-and-ai-vs-ai"><span class="mr-2">Unit 7: Introduction to Multi-Agents And AI vs AI</span><a href="#unit-7-introduction-to-multi-agents-and-ai-vs-ai" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2>
<p>Decentralized approach:</p>
<ul>
  <li>Treat all agents independently without considering the existence of the other agents.</li>
  <li>All agents consider others agents as part of the environment.</li>
  <li>No guarantee of convergence.
Centralized approach:</li>
  <li>A single policy is learned from all the agents.</li>
  <li>Takes as input the present state of an environment and the policy outputs joint actions.</li>
  <li>The reward is global.</li>
</ul>

<h2 id="unit-8-proximal-policy-optimization-with-doom"><span class="mr-2">Unit 8: Proximal Policy Optimization /with Doom</span><a href="#unit-8-proximal-policy-optimization-with-doom" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2>

<p>Proximal Policy Optimization (PPO): An architecture that improves the agentâ€™s training stability by avoiding large policy updates.
Two reasons that we avoid large policy update:</p>
<ul>
  <li>Small update is more likely to converge to an optimal solution.</li>
  <li>Big step can result in <em>off the cliff</em> and take a long time to recover.</li>
</ul>

<h4 id="clipped-surrogate-objective-function"><span class="mr-2">Clipped Surrogate Objective Function</span><a href="#clipped-surrogate-objective-function" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h4>
<p>\(L^{CLIP}(\theta)=E_t[min(r_t(\theta)A_t, clip(r_t(\theta), 1-\epsilon, 1+\epsilon)A)_t)]\)
where $r_t(\theta)$ denotes the probability ratio between old and current policy.</p>

<h2 id="bonus-unit-3-advanced-topics-in-reinforcement-learning"><span class="mr-2">Bonus Unit 3: Advanced Topics In Reinforcement Learning</span><a href="#bonus-unit-3-advanced-topics-in-reinforcement-learning" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2>

<ol>
  <li>
    <p><strong>Model-based Reinforcement Learning</strong>: <strong>learning a model of said environment</strong>, and then leveraging the model for control (making decisions).</p>
  </li>
  <li>
    <p><strong>Offline vs Online Reinforcement Learning</strong></p>
  </li>
  <li><strong>Reinforcement Learning from Human Feedback</strong> (RLHF): It aÂ methodology for integrating human data labels into a RL-based optimization process. It is motivated by theÂ <strong>challenge of modeling human preferences</strong>.
     - Useful link: https://huggingface.co/blog/rlhf</li>
  <li><strong>Decision Transformers</strong>: instead of training a policy using RL methods, such as fitting a value function, that will tell us what action to take to maximize the return (cumulative reward),Â <strong>we use a sequence modeling algorithm (Transformer) that, given a desired return, past states, and actions, will generate future actions to achieve this desired return</strong>.</li>
  <li><strong>Language models in RL</strong>:</li>
  <li>Curriculum Learning for RL</li>
</ol>


</div>

<div class="post-tail-wrapper text-muted">

  <!-- categories -->
  
  <div class="post-meta mb-3">
    <i class="far fa-folder-open fa-fw mr-1"></i>
    
      <a href='/categories/blogging/'>Blogging</a>,
      <a href='/categories/rl/'>RL</a>
  </div>
  

  <!-- tags -->
  
  <div class="post-tags">
    <i class="fa fa-tags fa-fw mr-1"></i>
      
      <a href="/tags/note/"
          class="post-tag no-text-decoration" >Note</a>
      
  </div>
  

  <div class="post-tail-bottom
    d-flex justify-content-between align-items-center mt-3 pt-5 pb-2">
    <div class="license-wrapper">

      

        

        This post is licensed under 
        <a href="https://creativecommons.org/licenses/by/4.0/">
          CC BY 4.0
        </a>
         by the author.

      
    </div>

    <!--
 Post sharing snippet
-->

<div class="share-wrapper">
  <span class="share-label text-muted mr-1">Share</span>
  <span class="share-icons">
    
    
    

    
      
        <a href="https://twitter.com/intent/tweet?text=Reinforcement%20Learning%20Course%20from%20Hugging%20Face%20-%20c0ldstudy&url=http%3A%2F%2Fc0ldstudy.github.io%2Fposts%2FReinforcement_Learning_Course%2F" data-toggle="tooltip" data-placement="top"
          title="Twitter" target="_blank" rel="noopener" aria-label="Twitter">
          <i class="fa-fw fab fa-twitter"></i>
        </a>
    
      
        <a href="https://www.facebook.com/sharer/sharer.php?title=Reinforcement%20Learning%20Course%20from%20Hugging%20Face%20-%20c0ldstudy&u=http%3A%2F%2Fc0ldstudy.github.io%2Fposts%2FReinforcement_Learning_Course%2F" data-toggle="tooltip" data-placement="top"
          title="Facebook" target="_blank" rel="noopener" aria-label="Facebook">
          <i class="fa-fw fab fa-facebook-square"></i>
        </a>
    
      
        <a href="https://t.me/share/url?url=http%3A%2F%2Fc0ldstudy.github.io%2Fposts%2FReinforcement_Learning_Course%2F&text=Reinforcement%20Learning%20Course%20from%20Hugging%20Face%20-%20c0ldstudy" data-toggle="tooltip" data-placement="top"
          title="Telegram" target="_blank" rel="noopener" aria-label="Telegram">
          <i class="fa-fw fab fa-telegram"></i>
        </a>
    

    <i id="copy-link" class="fa-fw fas fa-link small"
        data-toggle="tooltip" data-placement="top"
        title="Copy link"
        data-title-succeed="Link copied successfully!">
    </i>

  </span>
</div>


  </div><!-- .post-tail-bottom -->

</div><!-- div.post-tail-wrapper -->


      
    
    

    </div>
  </div> <!-- #core-wrapper -->

  <!-- panel -->
  <div id="panel-wrapper" class="col-xl-3 pl-2 text-muted">

    <div class="access">
      















  <div id="access-lastmod" class="post">
    <div class="panel-heading">Recently Updated</div>
    <ul class="post-content pl-0 pb-1 ml-1 mt-2">
      
        
        
        
      <li><a href="/posts/Paper_Summary_2023/">Paper Summary 2023</a></li>
      
        
        
        
      <li><a href="/posts/Reinforcement_Learning_Course/">Reinforcement Learning Course from Hugging Face</a></li>
      
        
        
        
      <li><a href="/posts/ChatGPT_Prompt/">ChatGPT Prompt Course Note</a></li>
      
        
        
        
      <li><a href="/posts/Coding_Interview/">Coding Interview</a></li>
      
        
        
        
      <li><a href="/posts/PC_attack/">[DSN2023] On Adversarial Robustness of Point Cloud Semantic Segmentation</a></li>
      
    </ul>
  </div> <!-- #access-lastmod -->



      















  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
      
        
        

  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        



  <div id="access-tags">
    <div class="panel-heading">Trending Tags</div>
    <div class="d-flex flex-wrap mt-3 mb-1 mr-3">

    
      
      <a class="post-tag" href="/tags/phd/">PhD</a>
    
      
      <a class="post-tag" href="/tags/security/">Security</a>
    
      
      <a class="post-tag" href="/tags/machine-learning/">Machine Learning</a>
    
      
      <a class="post-tag" href="/tags/website/">Website</a>
    
      
      <a class="post-tag" href="/tags/system/">System</a>
    
      
      <a class="post-tag" href="/tags/note/">Note</a>
    
      
      <a class="post-tag" href="/tags/ctf/">CTF</a>
    
      
      <a class="post-tag" href="/tags/conferences/">Conferences</a>
    
      
      <a class="post-tag" href="/tags/design/">Design</a>
    
      
      <a class="post-tag" href="/tags/network/">Network</a>
    

    </div>
  </div>


    </div>

    
      
      



  <div id="toc-wrapper" class="pl-0 pr-4 mb-5">
    <div class="panel-heading pl-3 pt-2 mb-2">Contents</div>
    <nav id="toc"></nav>
  </div>

  <!-- toc.js will be loaded at medium priority -->
  <script src="https://cdn.jsdelivr.net/npm/tocbot@4.20.1/dist/tocbot.min.js"></script>


    
  </div>

</div>

<!-- tail -->

<div class="row">
  <div id="tail-wrapper" class="col-12 col-lg-11 col-xl-9 pl-3 pr-3 pr-xl-4 mt-5">
    
      
      <!--
 Recommend the other 3 posts according to the tags and categories of the current post,
 if the number is not enough, use the other latest posts to supplement.
-->

<!-- The total size of related posts  -->


<!-- An random integer that bigger than 0  -->


<!-- Equals to TAG_SCORE / {max_categories_hierarchy}  -->








  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  
    
  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  








<!-- Fill with the other newlest posts  -->





  <div id="related-posts" class="mb-2 mb-sm-4">
    <h3 class="pt-2 mb-4 ml-1"
      data-toc-skip>Further Reading</h3>
    <div class="card-deck mb-4">
    
      
      
      <div class="card">
        <a href="/posts/Paper_Summary_2023/">
          <div class="card-body">
            <!--
  Date format snippet
  See: ${JS_ROOT}/utils/locale-dateime.js
-->





<em class="small"
    data-ts="1675238400"
    data-df="ll"
    >
  Feb  1, 2023
</em>

            <h3 class="pt-0 mt-1 mb-3" data-toc-skip>Paper Summary 2023</h3>
            <div class="text-muted small">
              <p>
                





                1. GPT-GNN: Generative Pre-Training of Graph Neural Networks
Paper/Code

Main Idea
The paper considers the generative pretrained model (GPT) and combine it with Graph Neural Network (GNN) to introd...
              </p>
            </div>
          </div>
        </a>
      </div>
    
      
      
      <div class="card">
        <a href="/posts/ChatGPT_Prompt/">
          <div class="card-body">
            <!--
  Date format snippet
  See: ${JS_ROOT}/utils/locale-dateime.js
-->





<em class="small"
    data-ts="1682406000"
    data-df="ll"
    >
  Apr 25, 2023
</em>

            <h3 class="pt-0 mt-1 mb-3" data-toc-skip>ChatGPT Prompt Course Note</h3>
            <div class="text-muted small">
              <p>
                





                The note is for the course: DeepLearning.AI ChatGPT Prompt Engineering Course.

ChatGPT Prompt Engineering for Developers
Course link: https://learn.deeplearning.ai/chatgpt-prompt-eng/lesson/1/intr...
              </p>
            </div>
          </div>
        </a>
      </div>
    
      
      
      <div class="card">
        <a href="/posts/Transformer_Related_Implementation/">
          <div class="card-body">
            <!--
  Date format snippet
  See: ${JS_ROOT}/utils/locale-dateime.js
-->





<em class="small"
    data-ts="1684566000"
    data-df="ll"
    >
  May 20, 2023
</em>

            <h3 class="pt-0 mt-1 mb-3" data-toc-skip>Transformer Related Implementation</h3>
            <div class="text-muted small">
              <p>
                





                1. Transformer[1]

I start it by following the video[1] from Andrej Karpathy and check the code from the repo. In the video, he shows how to build a GPT by oneself step by step which also shows the...
              </p>
            </div>
          </div>
        </a>
      </div>
    
    </div> <!-- .card-deck -->
  </div> <!-- #related-posts -->


    
      
      <!--
  Navigation buttons at the bottom of the post.
-->

<div class="post-navigation d-flex justify-content-between">
  
  <a href="/posts/Paper_Summary_2023/" class="btn btn-outline-primary"
    prompt="Older">
    <p>Paper Summary 2023</p>
  </a>
  

  
  <a href="/posts/PC_attack/" class="btn btn-outline-primary"
    prompt="Newer">
    <p>[DSN2023] On Adversarial Robustness of Point Cloud Semantic Segmentation</p>
  </a>
  

</div>

    
      
      <!--  The comments switcher -->

  
  <!-- https://giscus.app/ -->
<script type="text/javascript">
  $(function () {
    const origin = "https://giscus.app";
    const iframe = "iframe.giscus-frame";
    const lightTheme = "light";
    const darkTheme = "dark_dimmed";
    let initTheme = lightTheme;

    if ($("html[data-mode=dark]").length > 0
        || ($("html[data-mode]").length == 0
            && window.matchMedia("(prefers-color-scheme: dark)").matches)) {
      initTheme = darkTheme;
    }

    let giscusAttributes = {
      "src": "https://giscus.app/client.js",
      "data-repo": "C0ldstudy/c0ldstudy.github.io",
      "data-repo-id": "MDEwOlJlcG9zaXRvcnkyMzgxNzM1ODU=",
      "data-category": "Announcements",
      "data-category-id": "DIC_kwDODjI9kc4CV58d",
      "data-mapping": "pathname",
      "data-reactions-enabled": "1",
      "data-emit-metadata": "0",
      "data-theme": initTheme,
      "data-input-position": "bottom",
      "data-lang": "",
      "crossorigin": "anonymous",
      "async": ""
    };

    let giscusScript = document.createElement("script");
    Object.entries(giscusAttributes).forEach(([key, value]) => giscusScript.setAttribute(key, value));
    document.getElementById("tail-wrapper").appendChild(giscusScript);

    addEventListener("message", (event) => {
      if (event.source === window && event.data &&
            event.data.direction === ModeToggle.ID) {
        /* global theme mode changed */
        const mode = event.data.message;
        const theme = (mode === ModeToggle.DARK_MODE ? darkTheme : lightTheme);

        const message = {
          setConfig: {
            theme: theme
          }
        };

        const giscus = document.querySelector(iframe).contentWindow;
        giscus.postMessage({ giscus: message }, origin);
      }

    });

  });
</script>



    
  </div>
</div>


      </div>

      <!--
  The Search results
-->
<div id="search-result-wrapper" class="d-flex justify-content-center unloaded">
  <div class="col-12 col-sm-11 post-content">
    <div id="search-hints">
      















  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
      
        
        

  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        



  <div id="access-tags">
    <div class="panel-heading">Trending Tags</div>
    <div class="d-flex flex-wrap mt-3 mb-1 mr-3">

    
      
      <a class="post-tag" href="/tags/phd/">PhD</a>
    
      
      <a class="post-tag" href="/tags/security/">Security</a>
    
      
      <a class="post-tag" href="/tags/machine-learning/">Machine Learning</a>
    
      
      <a class="post-tag" href="/tags/website/">Website</a>
    
      
      <a class="post-tag" href="/tags/system/">System</a>
    
      
      <a class="post-tag" href="/tags/note/">Note</a>
    
      
      <a class="post-tag" href="/tags/ctf/">CTF</a>
    
      
      <a class="post-tag" href="/tags/conferences/">Conferences</a>
    
      
      <a class="post-tag" href="/tags/design/">Design</a>
    
      
      <a class="post-tag" href="/tags/network/">Network</a>
    

    </div>
  </div>


    </div>
    <div id="search-results" class="d-flex flex-wrap justify-content-center text-muted mt-3"></div>
  </div>
</div>


    </div> <!-- #main-wrapper -->

    <!-- The Footer -->

<footer>
    <div class="container pl-lg-4 pr-lg-4">
      <div hidden>
        <div class="github_chart">
          <img src="http://ghchart.rshah.org/409ba5/C0ldstudy" alt="C0ldstudy's Blue Github chart"/>
          <script type='text/javascript' id='clustrmaps' src='//cdn.clustrmaps.com/map_v2.js?cl=ffffff&w=300&t=tt&d=PWaejm3rz2TG6HOtwcekX2kM9kPWz2aP6GYhuOVoNpA'></script>
        </div>
      </div>

        <div class="d-flex justify-content-between align-items-center text-muted ml-md-3 mr-md-3">
        <div class="footer-left">
          <p class="mb-0">
            Â© 2023
            <a href="https://twitter.com/JiacenXu">Jiacen (Jason) Xu</a>.
            
            <span data-toggle="tooltip" data-placement="top"
              title="Except where otherwise noted, the blog posts on this site are licensed under the Creative Commons Attribution 4.0 International (CC BY 4.0) License by the author.">Some rights reserved.</span>
            
          </p>
        </div>

        <!-- <script  type="text/javascript" id="clustrmaps" src="//clustrmaps.com/map_v2.js?d=PWaejm3rz2TG6HOtwcekX2kM9kPWz2aP6GYhuOVoNpA&cl=ffffff&w=a"></script> -->
        <div class="footer-right">
          <p class="mb-0"><!-- Using the <a href="https://jekyllrb.com" target="_blank" rel="noopener">Jekyll</a> theme <a href="https://github.com/cotes2020/jekyll-theme-chirpy" target="_blank" rel="noopener">Chirpy</a>. -->
          </p>
        </div>
      </div>
    </div>
  </footer>


    
      <!--
  mermaid-js loader
-->

<script src="https://cdn.jsdelivr.net/npm/mermaid@9.2.2/dist/mermaid.min.js"></script>

<script>
  (function () {

    function updateMermaid(event) {
      if (event.source === window && event.data &&
        event.data.direction === ModeToggle.ID) {

        const mode = event.data.message;

        if (typeof mermaid === "undefined") {
          return;
        }

        let expectedTheme = (mode === ModeToggle.DARK_MODE ? "dark" : "default");
        let config = {theme: expectedTheme};

        /* Re-render the SVG â€º <https://github.com/mermaid-js/mermaid/issues/311#issuecomment-332557344> */
        $(".mermaid").each(function () {
          let svgCode = $(this).prev().children().html();
          $(this).removeAttr("data-processed");
          $(this).html(svgCode);
        });

        mermaid.initialize(config);
        mermaid.init(undefined, ".mermaid");
      }
    }

    let initTheme = "default";

    if ($("html[data-mode=dark]").length > 0
      || ($("html[data-mode]").length == 0
        && window.matchMedia("(prefers-color-scheme: dark)").matches)) {
      initTheme = "dark";
    }

    let mermaidConf = {
      theme: initTheme  /* <default|dark|forest|neutral> */
    };

    /* Create mermaid tag */
    $("pre").has("code.language-mermaid").each(function () {
      let svgCode = $(this).children().html();
      $(this).addClass("unloaded");
      $(this).after(`<pre class=\"mermaid\">${svgCode}</pre>`);
    });

    mermaid.initialize(mermaidConf);

    window.addEventListener("message", updateMermaid);
  })();

</script>

    

    <div id="mask"></div>

    <a id="back-to-top" href="#" aria-label="back-to-top" class="btn btn-lg btn-box-shadow" role="button">
      <i class="fas fa-angle-up"></i>
    </a>

    
      <div id="notification" class="toast" role="alert" aria-live="assertive" aria-atomic="true"
        data-animation="true" data-autohide="false">
        <div class="toast-header">
          <button type="button" class="ml-2 ml-auto close" data-dismiss="toast" aria-label="Close">
            <span aria-hidden="true">&times;</span>
          </button>
        </div>
        <div class="toast-body text-center pt-0">
          <p class="pl-2 pr-2 mb-3">A new version of content is available.</p>
          <button type="button" class="btn btn-primary" aria-label="Update">
            Update
          </button>
        </div>
      </div>
    

    <!--
  Jekyll Simple Search loader
  See: <https://github.com/christian-fei/Simple-Jekyll-Search>
-->





<script src="https://cdn.jsdelivr.net/npm/simple-jekyll-search@1.10.0/dest/simple-jekyll-search.min.js"></script>

<script>
SimpleJekyllSearch({
  searchInput: document.getElementById('search-input'),
  resultsContainer: document.getElementById('search-results'),
  json: '/assets/js/data/search.json',
  searchResultTemplate: '<div class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-lg-4 pr-lg-4 pl-xl-0 pr-xl-0">  <a href="{url}">{title}</a>  <div class="post-meta d-flex flex-column flex-sm-row text-muted mt-1 mb-1">    {categories}    {tags}  </div>  <p>{snippet}</p></div>',
  noResultsText: '<p class="mt-5">Oops! No results found.</p>',
  templateMiddleware: function(prop, value, template) {
    if (prop === 'categories') {
      if (value === '') {
        return `${value}`;
      } else {
        return `<div class="mr-sm-4"><i class="far fa-folder fa-fw"></i>${value}</div>`;
      }
    }

    if (prop === 'tags') {
      if (value === '') {
        return `${value}`;
      } else {
        return `<div><i class="fa fa-tag fa-fw"></i>${value}</div>`;
      }
    }
  }
});
</script>


    <!-- JS selector for site. -->

<!-- layout specified -->


  



  <!-- image lazy-loading & popup & clipboard -->
  

  







  
    

    

  



  
    

    

  



  
    

    

  




  <script src="https://cdn.jsdelivr.net/combine/npm/magnific-popup@1.1.0/dist/jquery.magnific-popup.min.js,npm/lazysizes@5.3.2/lazysizes.min.js,npm/clipboard@2.0.11/dist/clipboard.min.js"></script>





  

  

  







  
    

    

  



  
    

    

  



  
    

    

  



  
    

    

  




  <script src="https://cdn.jsdelivr.net/combine/npm/dayjs@1.11.6/dayjs.min.js,npm/dayjs@1.11.6/locale/en.min.js,npm/dayjs@1.11.6/plugin/relativeTime.min.js,npm/dayjs@1.11.6/plugin/localizedFormat.min.js"></script>







<script defer src="/assets/js/dist/post.min.js"></script>


  <!-- MathJax -->
  <script>
    /* see: <https://docs.mathjax.org/en/latest/options/input/tex.html#tex-options> */
    MathJax = {
      tex: {
        /* start/end delimiter pairs for in-line math */
        inlineMath: [
          ['$', '$'],
          ['\\(', '\\)']
        ],
        /* start/end delimiter pairs for display math */
        displayMath: [
          ['$$', '$$'],
          ['\\[', '\\]']
        ]
      }
    };
  </script>
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-chtml.js"></script>


<!-- commons -->

<script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.2/dist/js/bootstrap.bundle.min.js"></script>




  </body>

</html>

